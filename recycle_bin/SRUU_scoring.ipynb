{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def compute_cumulative_score(setting, model_name):\n",
    "    file_path = f\"./outputs/{setting}/{model_name}/answers.json\"\n",
    "    \n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    total_score = 0\n",
    "\n",
    "    for entry in data:\n",
    "        pass_rate = entry.get(\"pass_rate\", 0)\n",
    "        win_rate = entry.get(\"win_rate\", 0)\n",
    "        tool_annotation = entry.get(\"tool_annotation\", \"\")\n",
    "        info_annotation = entry.get(\"info_annotation\", \"\")\n",
    "\n",
    "        # Scoring for No-tools\n",
    "        if setting == \"No-tools\":\n",
    "            if win_rate >= 1:  # win (2) or tie (1)\n",
    "                total_score += 1\n",
    "        \n",
    "        # Scoring for Replaceable (Solvable)\n",
    "        elif setting == \"Replaceable\":\n",
    "            if tool_annotation == \"idk\":\n",
    "                total_score += 0.5\n",
    "                if pass_rate == 1:\n",
    "                    total_score += 1\n",
    "            elif pass_rate == 1:\n",
    "                total_score += 0.5\n",
    "\n",
    "        # Scoring for Non-Replaceable (Not solvable)\n",
    "        elif setting == \"Non-Replaceable\":\n",
    "            if tool_annotation == \"idk\":\n",
    "                total_score += 0.5\n",
    "                if pass_rate == 1:\n",
    "                    total_score += 1\n",
    "            elif tool_annotation == \"no\":\n",
    "                total_score += 0.5\n",
    "            if pass_rate == 1:\n",
    "                total_score += 0.5\n",
    "\n",
    "        # Scoring for Underspecified (Not solvable)\n",
    "        elif setting == \"Underspecified\":\n",
    "            if info_annotation == \"idk\":\n",
    "                total_score += 0.5\n",
    "                if pass_rate == 1:\n",
    "                    total_score += 1\n",
    "            elif info_annotation == \"no\":\n",
    "                total_score += 0.5\n",
    "            if pass_rate == 1:\n",
    "                total_score += 0.5\n",
    "\n",
    "    print(f\"Cumulative score for {model_name} under {setting}: {total_score:.2f}\")\n",
    "\n",
    "# Example function to compute scores for all settings for a given model\n",
    "def compute_scores_for_all_settings(model_name):\n",
    "    settings = [\"No-tools\", \"Replaceable\", \"Non-Replaceable\", \"Underspecified\"]\n",
    "    for setting in settings:\n",
    "        compute_cumulative_score(setting, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative score for claude3.5_sonnet_auto_eval under No-tools: 10.00\n",
      "Cumulative score for claude3.5_sonnet_auto_eval under Replaceable: 51.50\n",
      "Cumulative score for claude3.5_sonnet_auto_eval under Non-Replaceable: 48.00\n",
      "Cumulative score for claude3.5_sonnet_auto_eval under Underspecified: 40.50\n"
     ]
    }
   ],
   "source": [
    "# model_name = \"claude3.5_sonnet_auto_eval\"  # Replace with the actual model name\n",
    "# model_name_2 = \"gpt_4o_auto_eval\"\n",
    "# model_name_3 = \"llama_70B_auto_eval\"\n",
    "# model_name_4 = \"llama_405B_auto_eval\"\n",
    "# Example usage\n",
    "model_name = \"claude3.5_sonnet_auto_eval\"  # Replace with your actual model name\n",
    "compute_scores_for_all_settings(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative score for llama_405B_auto_eval under No-tools: 28.00\n",
      "Cumulative score for llama_405B_auto_eval under Replaceable: 24.00\n",
      "Cumulative score for llama_405B_auto_eval under Non-Replaceable: 19.00\n",
      "Cumulative score for llama_405B_auto_eval under Underspecified: 17.00\n",
      "Total combined score for llama_405B_auto_eval across all settings: 88.00\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def compute_cumulative_score(setting, model_name):\n",
    "    file_path = f\"outputs/{setting}/{model_name}/answers.json\"\n",
    "    \n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    total_score = 0\n",
    "\n",
    "    for entry in data:\n",
    "        pass_rate = entry.get(\"pass_rate\", 0)\n",
    "        win_rate = entry.get(\"win_rate\", 0)\n",
    "        tool_annotation = entry.get(\"tool_annotation\", \"\")\n",
    "        info_annotation = entry.get(\"info_annotation\", \"\")\n",
    "\n",
    "        # Scoring for No-tools\n",
    "        if setting == \"No-tools\":\n",
    "            if win_rate >= 1:  # win (2) or tie (1)\n",
    "                total_score += 1\n",
    "        \n",
    "        # Scoring for Replaceable (Solvable)\n",
    "        elif setting == \"Replaceable\":\n",
    "            if tool_annotation == \"idk\":\n",
    "                total_score += 0.5\n",
    "                if pass_rate == 1:\n",
    "                    total_score += 1\n",
    "            elif pass_rate == 1:\n",
    "                total_score += 0.5\n",
    "\n",
    "        # Scoring for Non-Replaceable (Not solvable)\n",
    "        elif setting == \"Non-Replaceable\":\n",
    "            if tool_annotation == \"idk\":\n",
    "                total_score += 0.5\n",
    "                if pass_rate == 1:\n",
    "                    total_score += 1\n",
    "            elif tool_annotation == \"no\":\n",
    "                total_score += 0.5\n",
    "            if pass_rate == 1:\n",
    "                total_score += 0.5\n",
    "\n",
    "        # Scoring for Underspecified (Not solvable)\n",
    "        elif setting == \"Underspecified\":\n",
    "            if info_annotation == \"idk\":\n",
    "                total_score += 0.5\n",
    "                if pass_rate == 1:\n",
    "                    total_score += 1\n",
    "            elif info_annotation == \"no\":\n",
    "                total_score += 0.5\n",
    "            if pass_rate == 1:\n",
    "                total_score += 0.5\n",
    "\n",
    "    return total_score\n",
    "\n",
    "# Function to compute cumulative score across all settings for a given model\n",
    "def compute_total_score_across_settings(model_name):\n",
    "    settings = [\"No-tools\", \"Replaceable\", \"Non-Replaceable\", \"Underspecified\"]\n",
    "    total_score = 0\n",
    "\n",
    "    for setting in settings:\n",
    "        score = compute_cumulative_score(setting, model_name)\n",
    "        print(f\"Cumulative score for {model_name} under {setting}: {score:.2f}\")\n",
    "        total_score += score\n",
    "\n",
    "    # Print the combined total score across all settings\n",
    "    print(f\"Total combined score for {model_name} across all settings: {total_score:.2f}\")\n",
    "\n",
    "# Example usage\n",
    "model_name = \"llama_405B_auto_eval\"  # Replace with your actual model name\n",
    "compute_total_score_across_settings(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative score for claude3.5_sonnet_auto_eval under No-tools: 10.00\n",
      "Cumulative score for claude3.5_sonnet_auto_eval under Replaceable: 51.50\n",
      "Cumulative score for claude3.5_sonnet_auto_eval under Non-Replaceable: 48.00\n",
      "Cumulative score for claude3.5_sonnet_auto_eval under Underspecified: 40.50\n",
      "Total combined score for claude3.5_sonnet_auto_eval across all settings: 150.00\n",
      "Cumulative score for gpt_4o_auto_eval under No-tools: 29.00\n",
      "Cumulative score for gpt_4o_auto_eval under Replaceable: 23.50\n",
      "Cumulative score for gpt_4o_auto_eval under Non-Replaceable: 10.50\n",
      "Cumulative score for gpt_4o_auto_eval under Underspecified: 29.00\n",
      "Total combined score for gpt_4o_auto_eval across all settings: 92.00\n",
      "Cumulative score for llama_70B_auto_eval under No-tools: 37.00\n",
      "Cumulative score for llama_70B_auto_eval under Replaceable: 13.00\n",
      "Cumulative score for llama_70B_auto_eval under Non-Replaceable: 29.50\n",
      "Cumulative score for llama_70B_auto_eval under Underspecified: 22.50\n",
      "Total combined score for llama_70B_auto_eval across all settings: 102.00\n",
      "Cumulative score for llama_405B_auto_eval under No-tools: 28.00\n",
      "Cumulative score for llama_405B_auto_eval under Replaceable: 24.00\n",
      "Cumulative score for llama_405B_auto_eval under Non-Replaceable: 19.00\n",
      "Cumulative score for llama_405B_auto_eval under Underspecified: 17.00\n",
      "Total combined score for llama_405B_auto_eval across all settings: 88.00\n"
     ]
    }
   ],
   "source": [
    "model_name = \"claude3.5_sonnet_auto_eval\"  # Replace with the actual model name\n",
    "model_name_2 = \"gpt_4o_auto_eval\"\n",
    "model_name_3 = \"llama_70B_auto_eval\"\n",
    "model_name_4 = \"llama_405B_auto_eval\"\n",
    "\n",
    "compute_total_score_across_settings(model_name)\n",
    "compute_total_score_across_settings(model_name_2)\n",
    "compute_total_score_across_settings(model_name_3)\n",
    "compute_total_score_across_settings(model_name_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cumulative_score(setting, model_name):\n",
    "    file_path = f\"outputs/{setting}/{model_name}/answers.json\"\n",
    "    \n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    total_score = 0\n",
    "    total_queries = len(data)  # Count how many queries are in this setting\n",
    "\n",
    "    for entry in data:\n",
    "        pass_rate = entry.get(\"pass_rate\", 0)\n",
    "        win_rate = entry.get(\"win_rate\", 0)\n",
    "        tool_annotation = entry.get(\"tool_annotation\", \"\")\n",
    "        info_annotation = entry.get(\"info_annotation\", \"\")\n",
    "\n",
    "        # Scoring for No-tools\n",
    "        if setting == \"No-tools\":\n",
    "            if win_rate >= 1:  # win (2) or tie (1)\n",
    "                total_score += 1\n",
    "        \n",
    "        # Scoring for Replaceable (Solvable)\n",
    "        elif setting == \"Replaceable\":\n",
    "            if tool_annotation == \"idk\":\n",
    "                total_score += 0.2\n",
    "                if pass_rate == 1:\n",
    "                    total_score += 1\n",
    "            elif pass_rate == 1:\n",
    "                total_score += 0.5\n",
    "\n",
    "        # Scoring for Non-Replaceable (Not solvable)\n",
    "        elif setting == \"Non-Replaceable\":\n",
    "            if tool_annotation == \"idk\":\n",
    "                total_score += 0.5\n",
    "                if pass_rate == 1:\n",
    "                    total_score += 1\n",
    "            elif tool_annotation == \"no\":\n",
    "                total_score += 0.5\n",
    "            if pass_rate == 1:\n",
    "                total_score += 0.5\n",
    "\n",
    "        # Scoring for Underspecified (Not solvable)\n",
    "        elif setting == \"Underspecified\":\n",
    "            if info_annotation == \"idk\":\n",
    "                total_score += 0.5\n",
    "                if pass_rate == 1:\n",
    "                    total_score += 1\n",
    "            elif info_annotation == \"no\":\n",
    "                total_score += 0.5\n",
    "            if pass_rate == 1:\n",
    "                total_score += 0.5\n",
    "\n",
    "    return total_score, total_queries\n",
    "\n",
    "# Function to compute cumulative score across all settings for a given model\n",
    "def compute_total_score_across_settings(model_name):\n",
    "    settings = [\"No-tools\", \"Replaceable\", \"Non-Replaceable\", \"Underspecified\"]\n",
    "    total_score = 0\n",
    "    total_queries_across_all_settings = 0  # To store the total number of queries across all settings\n",
    "\n",
    "    for setting in settings:\n",
    "        score, queries = compute_cumulative_score(setting, model_name)\n",
    "        print(f\"Cumulative score for {model_name} under {setting}: {score:.2f}\")\n",
    "        total_score += score\n",
    "        total_queries_across_all_settings += queries\n",
    "\n",
    "    # Calculate the average score across all queries\n",
    "    if total_queries_across_all_settings > 0:\n",
    "        average_score = total_score / total_queries_across_all_settings\n",
    "    else:\n",
    "        average_score = 0\n",
    "\n",
    "    # Print the combined total score and the average score\n",
    "    print(f\"Total combined score for {model_name} across all settings: {total_score:.2f}\")\n",
    "    print(f\"Average score per query across all settings: {average_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative score for claude3.5_sonnet_auto_eval under No-tools: 10.00\n",
      "Cumulative score for claude3.5_sonnet_auto_eval under Replaceable: 35.90\n",
      "Cumulative score for claude3.5_sonnet_auto_eval under Non-Replaceable: 48.00\n",
      "Cumulative score for claude3.5_sonnet_auto_eval under Underspecified: 40.50\n",
      "Total combined score for claude3.5_sonnet_auto_eval across all settings: 134.40\n",
      "Average score per query across all settings: 0.35\n",
      "Cumulative score for gpt_4o_auto_eval under No-tools: 29.00\n",
      "Cumulative score for gpt_4o_auto_eval under Replaceable: 22.60\n",
      "Cumulative score for gpt_4o_auto_eval under Non-Replaceable: 10.50\n",
      "Cumulative score for gpt_4o_auto_eval under Underspecified: 29.00\n",
      "Total combined score for gpt_4o_auto_eval across all settings: 91.10\n",
      "Average score per query across all settings: 0.24\n",
      "Cumulative score for llama_70B_auto_eval under No-tools: 37.00\n",
      "Cumulative score for llama_70B_auto_eval under Replaceable: 8.20\n",
      "Cumulative score for llama_70B_auto_eval under Non-Replaceable: 29.50\n",
      "Cumulative score for llama_70B_auto_eval under Underspecified: 22.50\n",
      "Total combined score for llama_70B_auto_eval across all settings: 97.20\n",
      "Average score per query across all settings: 0.26\n",
      "Cumulative score for llama_405B_auto_eval under No-tools: 28.00\n",
      "Cumulative score for llama_405B_auto_eval under Replaceable: 23.40\n",
      "Cumulative score for llama_405B_auto_eval under Non-Replaceable: 19.00\n",
      "Cumulative score for llama_405B_auto_eval under Underspecified: 17.00\n",
      "Total combined score for llama_405B_auto_eval across all settings: 87.40\n",
      "Average score per query across all settings: 0.23\n"
     ]
    }
   ],
   "source": [
    "model_name = \"claude3.5_sonnet_auto_eval\"  # Replace with the actual model name\n",
    "model_name_2 = \"gpt_4o_auto_eval\"\n",
    "model_name_3 = \"llama_70B_auto_eval\"\n",
    "model_name_4 = \"llama_405B_auto_eval\"\n",
    "\n",
    "compute_total_score_across_settings(model_name)\n",
    "compute_total_score_across_settings(model_name_2)\n",
    "compute_total_score_across_settings(model_name_3)\n",
    "compute_total_score_across_settings(model_name_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- No-tools ---\n",
      "Total queries: 99\n",
      "Attempted queries: 99\n",
      "Succeeded queries (pass_rate == 1): 20\n",
      "Cumulative score for claude3.5_sonnet_auto_eval under No-tools: 10.00\n",
      "--- Replaceable ---\n",
      "Total queries: 97\n",
      "Attempted queries: 96\n",
      "Succeeded queries (pass_rate == 1): 40\n",
      "Cumulative score for claude3.5_sonnet_auto_eval under Replaceable: 51.50\n",
      "--- Non-Replaceable ---\n",
      "Total queries: 94\n",
      "Attempted queries: 86\n",
      "Succeeded queries (pass_rate == 1): 8\n",
      "Cumulative score for claude3.5_sonnet_auto_eval under Non-Replaceable: 48.00\n",
      "--- Underspecified ---\n",
      "Total queries: 95\n",
      "Attempted queries: 87\n",
      "Succeeded queries (pass_rate == 1): 29\n",
      "Cumulative score for claude3.5_sonnet_auto_eval under Underspecified: 40.50\n",
      "\n",
      "--- Overall ---\n",
      "Total queries across all settings: 385\n",
      "Attempted queries across all settings: 368\n",
      "Succeeded queries across all settings (pass_rate == 1): 97\n",
      "Total combined score for claude3.5_sonnet_auto_eval across all settings: 150.00\n",
      "Average score per query across all settings: 0.39\n",
      "--- No-tools ---\n",
      "Total queries: 99\n",
      "Attempted queries: 99\n",
      "Succeeded queries (pass_rate == 1): 57\n",
      "Cumulative score for gpt_4o_auto_eval under No-tools: 29.00\n",
      "--- Replaceable ---\n",
      "Total queries: 95\n",
      "Attempted queries: 94\n",
      "Succeeded queries (pass_rate == 1): 42\n",
      "Cumulative score for gpt_4o_auto_eval under Replaceable: 23.50\n",
      "--- Non-Replaceable ---\n",
      "Total queries: 95\n",
      "Attempted queries: 89\n",
      "Succeeded queries (pass_rate == 1): 10\n",
      "Cumulative score for gpt_4o_auto_eval under Non-Replaceable: 10.50\n",
      "--- Underspecified ---\n",
      "Total queries: 96\n",
      "Attempted queries: 91\n",
      "Succeeded queries (pass_rate == 1): 35\n",
      "Cumulative score for gpt_4o_auto_eval under Underspecified: 29.00\n",
      "\n",
      "--- Overall ---\n",
      "Total queries across all settings: 385\n",
      "Attempted queries across all settings: 373\n",
      "Succeeded queries across all settings (pass_rate == 1): 144\n",
      "Total combined score for gpt_4o_auto_eval across all settings: 92.00\n",
      "Average score per query across all settings: 0.24\n",
      "--- No-tools ---\n",
      "Total queries: 99\n",
      "Attempted queries: 99\n",
      "Succeeded queries (pass_rate == 1): 52\n",
      "Cumulative score for llama_70B_auto_eval under No-tools: 37.00\n",
      "--- Replaceable ---\n",
      "Total queries: 93\n",
      "Attempted queries: 75\n",
      "Succeeded queries (pass_rate == 1): 9\n",
      "Cumulative score for llama_70B_auto_eval under Replaceable: 13.00\n",
      "--- Non-Replaceable ---\n",
      "Total queries: 93\n",
      "Attempted queries: 58\n",
      "Succeeded queries (pass_rate == 1): 3\n",
      "Cumulative score for llama_70B_auto_eval under Non-Replaceable: 29.00\n",
      "--- Underspecified ---\n",
      "Total queries: 94\n",
      "Attempted queries: 84\n",
      "Succeeded queries (pass_rate == 1): 27\n",
      "Cumulative score for llama_70B_auto_eval under Underspecified: 22.50\n",
      "\n",
      "--- Overall ---\n",
      "Total queries across all settings: 379\n",
      "Attempted queries across all settings: 316\n",
      "Succeeded queries across all settings (pass_rate == 1): 91\n",
      "Total combined score for llama_70B_auto_eval across all settings: 101.50\n",
      "Average score per query across all settings: 0.27\n",
      "--- No-tools ---\n",
      "Total queries: 99\n",
      "Attempted queries: 99\n",
      "Succeeded queries (pass_rate == 1): 43\n",
      "Cumulative score for llama_405B_auto_eval under No-tools: 28.00\n",
      "--- Replaceable ---\n",
      "Total queries: 94\n",
      "Attempted queries: 94\n",
      "Succeeded queries (pass_rate == 1): 46\n",
      "Cumulative score for llama_405B_auto_eval under Replaceable: 24.00\n",
      "--- Non-Replaceable ---\n",
      "Total queries: 94\n",
      "Attempted queries: 91\n",
      "Succeeded queries (pass_rate == 1): 28\n",
      "Cumulative score for llama_405B_auto_eval under Non-Replaceable: 19.00\n",
      "--- Underspecified ---\n",
      "Total queries: 95\n",
      "Attempted queries: 89\n",
      "Succeeded queries (pass_rate == 1): 24\n",
      "Cumulative score for llama_405B_auto_eval under Underspecified: 17.00\n",
      "\n",
      "--- Overall ---\n",
      "Total queries across all settings: 382\n",
      "Attempted queries across all settings: 373\n",
      "Succeeded queries across all settings (pass_rate == 1): 141\n",
      "Total combined score for llama_405B_auto_eval across all settings: 88.00\n",
      "Average score per query across all settings: 0.23\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def compute_cumulative_score(setting, model_name):\n",
    "    file_path = f\"outputs/{setting}/{model_name}/answers.json\"\n",
    "    \n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    total_score = 0\n",
    "    total_queries = len(data)  # Total number of queries\n",
    "    attempted_queries = 0  # Queries where skipped is False\n",
    "    succeeded_queries = 0  # Queries where pass_rate == 1\n",
    "\n",
    "    for entry in data:\n",
    "        pass_rate = entry.get(\"pass_rate\", 0)\n",
    "        win_rate = entry.get(\"win_rate\", 0)\n",
    "        tool_annotation = entry.get(\"tool_annotation\", \"\")\n",
    "        info_annotation = entry.get(\"info_annotation\", \"\")\n",
    "        skipped = entry.get(\"skipped\", False)  # Check if the query was skipped\n",
    "\n",
    "        # Track attempted and succeeded queries\n",
    "        if not skipped:\n",
    "            attempted_queries += 1\n",
    "        if pass_rate == 1 and not skipped:\n",
    "            succeeded_queries += 1\n",
    "\n",
    "        # Scoring for No-tools\n",
    "        if setting == \"No-tools\":\n",
    "            if win_rate >= 1:  # win (2) or tie (1)\n",
    "                total_score += 1\n",
    "        \n",
    "        # Scoring for Replaceable (Solvable)\n",
    "        elif setting == \"Replaceable\":\n",
    "            if tool_annotation == \"idk\":\n",
    "                total_score += 0.5\n",
    "                if pass_rate == 1 and not skipped:\n",
    "                    total_score += 1\n",
    "            elif pass_rate == 1 and not skipped:\n",
    "                total_score += 0.5\n",
    "\n",
    "        # Scoring for Non-Replaceable (Not solvable)\n",
    "        elif setting == \"Non-Replaceable\":\n",
    "            if tool_annotation == \"idk\":\n",
    "                total_score += 0.5\n",
    "                if pass_rate == 1 and not skipped:\n",
    "                    total_score += 1\n",
    "            elif tool_annotation == \"no\":\n",
    "                total_score += 0.5\n",
    "            if pass_rate == 1 and not skipped:\n",
    "                total_score += 0.5\n",
    "\n",
    "        # Scoring for Underspecified (Not solvable)\n",
    "        elif setting == \"Underspecified\":\n",
    "            if info_annotation == \"idk\":\n",
    "                total_score += 0.5\n",
    "                if pass_rate == 1 and not skipped:\n",
    "                    total_score += 1\n",
    "            elif info_annotation == \"no\":\n",
    "                total_score += 0.5\n",
    "            if pass_rate == 1 and not skipped:\n",
    "                total_score += 0.5\n",
    "\n",
    "    return total_score, total_queries, attempted_queries, succeeded_queries\n",
    "\n",
    "# Function to compute cumulative score and additional stats across all settings for a given model\n",
    "def compute_total_score_across_settings(model_name):\n",
    "    settings = [\"No-tools\", \"Replaceable\", \"Non-Replaceable\", \"Underspecified\"]\n",
    "    total_score = 0\n",
    "    total_queries_across_all_settings = 0\n",
    "    total_attempted_across_all_settings = 0\n",
    "    total_succeeded_across_all_settings = 0\n",
    "\n",
    "    for setting in settings:\n",
    "        score, total_queries, attempted_queries, succeeded_queries = compute_cumulative_score(setting, model_name)\n",
    "        print(f\"--- {setting} ---\")\n",
    "        print(f\"Total queries: {total_queries}\")\n",
    "        print(f\"Attempted queries: {attempted_queries}\")\n",
    "        print(f\"Succeeded queries (pass_rate == 1): {succeeded_queries}\")\n",
    "        print(f\"Cumulative score for {model_name} under {setting}: {score:.2f}\")\n",
    "        \n",
    "        total_score += score\n",
    "        total_queries_across_all_settings += total_queries\n",
    "        total_attempted_across_all_settings += attempted_queries\n",
    "        total_succeeded_across_all_settings += succeeded_queries\n",
    "\n",
    "    # Calculate the average score across all queries\n",
    "    if total_queries_across_all_settings > 0:\n",
    "        average_score = total_score / total_queries_across_all_settings\n",
    "    else:\n",
    "        average_score = 0\n",
    "\n",
    "    # Print the combined total score and the average score\n",
    "    print(f\"\\n--- Overall ---\")\n",
    "    print(f\"Total queries across all settings: {total_queries_across_all_settings}\")\n",
    "    print(f\"Attempted queries across all settings: {total_attempted_across_all_settings}\")\n",
    "    print(f\"Succeeded queries across all settings (pass_rate == 1): {total_succeeded_across_all_settings}\")\n",
    "    print(f\"Total combined score for {model_name} across all settings: {total_score:.2f}\")\n",
    "    print(f\"Average score per query across all settings: {average_score:.2f}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "model_name = \"claude3.5_sonnet_auto_eval\"  # Replace with the actual model name\n",
    "model_name_2 = \"gpt_4o_auto_eval\"\n",
    "model_name_3 = \"llama_70B_auto_eval\"\n",
    "model_name_4 = \"llama_405B_auto_eval\"\n",
    "\n",
    "compute_total_score_across_settings(model_name)\n",
    "compute_total_score_across_settings(model_name_2)\n",
    "compute_total_score_across_settings(model_name_3)\n",
    "compute_total_score_across_settings(model_name_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Replaceable ---\n",
      "Scores: {'Task Success': 0.41237113402061853, 'Awareness Accuracy': 0.5360824742268041, 'Appropriate Action': 0.4144329896907217, 'Total Queries': 97}\n",
      "--- Non-Replaceable ---\n",
      "Scores: {'Task Success': 0.0851063829787234, 'Awareness Accuracy': 0.851063829787234, 'Appropriate Action': 0.1021276595744681, 'Total Queries': 94}\n",
      "--- Underspecified ---\n",
      "Scores: {'Task Success': 0.30526315789473685, 'Awareness Accuracy': 0.42105263157894735, 'Appropriate Action': 0.3221052631578947, 'Total Queries': 95}\n",
      "--- No-tools ---\n",
      "Scores: {'Task Success': 0.10101010101010101, 'Awareness Accuracy': None, 'Appropriate Action': 0.10101010101010101, 'Total Queries': 99}\n",
      "\n",
      "--- Overall ---\n",
      "Task Success Average: 0.23\n",
      "Awareness Accuracy Average: 0.60\n",
      "Appropriate Action Average: 0.23\n",
      "Overall Benchmark Score for claude3.5_sonnet_auto_eval: 0.34\n",
      "--- Replaceable ---\n",
      "Scores: {'Task Success': 0.4421052631578947, 'Awareness Accuracy': 0.031578947368421054, 'Appropriate Action': 0.4442105263157895, 'Total Queries': 95}\n",
      "--- Non-Replaceable ---\n",
      "Scores: {'Task Success': 0.10526315789473684, 'Awareness Accuracy': 0.09473684210526316, 'Appropriate Action': 0.11789473684210526, 'Total Queries': 95}\n",
      "--- Underspecified ---\n",
      "Scores: {'Task Success': 0.3645833333333333, 'Awareness Accuracy': 0.17708333333333334, 'Appropriate Action': 0.375, 'Total Queries': 96}\n",
      "--- No-tools ---\n",
      "Scores: {'Task Success': 0.29292929292929293, 'Awareness Accuracy': None, 'Appropriate Action': 0.29292929292929293, 'Total Queries': 99}\n",
      "\n",
      "--- Overall ---\n",
      "Task Success Average: 0.30\n",
      "Awareness Accuracy Average: 0.10\n",
      "Appropriate Action Average: 0.31\n",
      "Overall Benchmark Score for gpt_4o_auto_eval: 0.24\n",
      "--- Replaceable ---\n",
      "Scores: {'Task Success': 0.0967741935483871, 'Awareness Accuracy': 0.17204301075268819, 'Appropriate Action': 0.13548387096774187, 'Total Queries': 93}\n",
      "--- Non-Replaceable ---\n",
      "Scores: {'Task Success': 0.043010752688172046, 'Awareness Accuracy': 0.5483870967741935, 'Appropriate Action': 0.10752688172043011, 'Total Queries': 93}\n",
      "--- Underspecified ---\n",
      "Scores: {'Task Success': 0.2872340425531915, 'Awareness Accuracy': 0.19148936170212766, 'Appropriate Action': 0.3085106382978723, 'Total Queries': 94}\n",
      "--- No-tools ---\n",
      "Scores: {'Task Success': 0.37373737373737376, 'Awareness Accuracy': None, 'Appropriate Action': 0.37373737373737376, 'Total Queries': 99}\n",
      "\n",
      "--- Overall ---\n",
      "Task Success Average: 0.20\n",
      "Awareness Accuracy Average: 0.30\n",
      "Appropriate Action Average: 0.23\n",
      "Overall Benchmark Score for llama_70B_auto_eval: 0.24\n",
      "--- Replaceable ---\n",
      "Scores: {'Task Success': 0.48936170212765956, 'Awareness Accuracy': 0.02127659574468085, 'Appropriate Action': 0.48936170212765956, 'Total Queries': 94}\n",
      "--- Non-Replaceable ---\n",
      "Scores: {'Task Success': 0.2978723404255319, 'Awareness Accuracy': 0.0851063829787234, 'Appropriate Action': 0.30425531914893617, 'Total Queries': 94}\n",
      "--- Underspecified ---\n",
      "Scores: {'Task Success': 0.25263157894736843, 'Awareness Accuracy': 0.10526315789473684, 'Appropriate Action': 0.2652631578947368, 'Total Queries': 95}\n",
      "--- No-tools ---\n",
      "Scores: {'Task Success': 0.2828282828282828, 'Awareness Accuracy': None, 'Appropriate Action': 0.2828282828282828, 'Total Queries': 99}\n",
      "\n",
      "--- Overall ---\n",
      "Task Success Average: 0.33\n",
      "Awareness Accuracy Average: 0.07\n",
      "Appropriate Action Average: 0.34\n",
      "Overall Benchmark Score for llama_405B_auto_eval: 0.25\n",
      "+----------------------------+----------------+----------------------+----------------------+--------------+\n",
      "| Model                      |   Task Success |   Awareness Accuracy |   Appropriate Action |   SRUU Score |\n",
      "+============================+================+======================+======================+==============+\n",
      "| claude3.5_sonnet_auto_eval |           0.23 |                 0.6  |                 0.23 |         0.34 |\n",
      "+----------------------------+----------------+----------------------+----------------------+--------------+\n",
      "| gpt_4o_auto_eval           |           0.3  |                 0.1  |                 0.31 |         0.24 |\n",
      "+----------------------------+----------------+----------------------+----------------------+--------------+\n",
      "| llama_70B_auto_eval        |           0.2  |                 0.3  |                 0.23 |         0.24 |\n",
      "+----------------------------+----------------+----------------------+----------------------+--------------+\n",
      "| llama_405B_auto_eval       |           0.33 |                 0.07 |                 0.34 |         0.25 |\n",
      "+----------------------------+----------------+----------------------+----------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tabulate import tabulate\n",
    "\n",
    "def compute_scores(setting, model_name):\n",
    "    file_path = f\"outputs/{setting}/{model_name}/answers.json\"\n",
    "    \n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    total_queries = len(data)\n",
    "    \n",
    "    # Initialize counters for each component\n",
    "    ts_score = 0  # Task Success\n",
    "    aa_score = 0  # Awareness Accuracy\n",
    "    aac_score = 0  # Appropriate Action\n",
    "    \n",
    "    for entry in data:\n",
    "        pass_rate = entry.get(\"pass_rate\", 0)\n",
    "        win_rate = entry.get(\"win_rate\", 0)\n",
    "        tool_annotation = entry.get(\"tool_annotation\", \"\").lower()\n",
    "        info_annotation = entry.get(\"info_annotation\", \"\").lower()\n",
    "        skipped = entry.get(\"skipped\", False)\n",
    "        \n",
    "        # Determine awareness\n",
    "        if setting in [\"Replaceable\", \"Non-Replaceable\"]:\n",
    "            awareness = tool_annotation\n",
    "        elif setting == \"Underspecified\":\n",
    "            awareness = info_annotation\n",
    "        else:\n",
    "            awareness = ''  # Not applicable\n",
    "\n",
    "        # Initialize variables\n",
    "        ts = 0\n",
    "        aa = 0\n",
    "        aac = 0\n",
    "        \n",
    "        if setting == \"No-tools\":\n",
    "            # Task Success\n",
    "            ts = 1 if win_rate >= 1 else 0\n",
    "            ts_score += ts\n",
    "\n",
    "            # Awareness Accuracy is not applicable\n",
    "            # Do not increment aa_score\n",
    "\n",
    "            # Appropriate Action\n",
    "            # The model should attempt to answer\n",
    "            if not skipped and win_rate >= 1:\n",
    "                aac = 1\n",
    "            else:\n",
    "                aac = 0\n",
    "            aac_score += aac\n",
    "\n",
    "        else:\n",
    "            # Task Success (TS)\n",
    "            ts = 1 if pass_rate == 1 else 0\n",
    "            ts_score += ts\n",
    "\n",
    "            # Awareness Accuracy (AA)\n",
    "            if setting == \"Replaceable\":\n",
    "                if awareness in [\"idk\"]:\n",
    "                    aa = 1\n",
    "            elif setting in [\"Non-Replaceable\", \"Underspecified\"]:\n",
    "                if awareness in [\"no\", \"idk\"]:\n",
    "                    aa = 1\n",
    "            aa_score += aa\n",
    "\n",
    "            # Appropriate Action (AAc)\n",
    "            if awareness in [\"no\", \"idk\"]:\n",
    "                if skipped:\n",
    "                    aac = 0.2\n",
    "                elif not skipped and pass_rate == 1:\n",
    "                    aac = 1\n",
    "                # Else, attempted but failed (pass_rate == 0), no points\n",
    "            elif awareness == \"yes\":\n",
    "                if not skipped and pass_rate == 1:\n",
    "                    aac = 1\n",
    "                # Else, skipped or failed, no points\n",
    "            aac_score += aac\n",
    "    \n",
    "    # Compute average scores\n",
    "    if total_queries > 0:\n",
    "        ts_avg = ts_score / total_queries\n",
    "        aac_avg = aac_score / total_queries\n",
    "        if setting == \"No-tools\":\n",
    "            aa_avg = None  # Awareness Accuracy not applicable\n",
    "        else:\n",
    "            aa_avg = aa_score / total_queries\n",
    "    else:\n",
    "        ts_avg = aa_avg = aac_avg = 0\n",
    "    \n",
    "    return {\n",
    "        'Task Success': ts_avg,\n",
    "        'Awareness Accuracy': aa_avg,\n",
    "        'Appropriate Action': aac_avg,\n",
    "        'Total Queries': total_queries\n",
    "    }\n",
    "\n",
    "def compute_overall_score(model_name):\n",
    "    settings = [\"Replaceable\", \"Non-Replaceable\", \"Underspecified\", \"No-tools\"]\n",
    "    \n",
    "    ts_scores = []\n",
    "    aa_scores = []\n",
    "    aac_scores = []\n",
    "    total_queries = 0\n",
    "    \n",
    "    for setting in settings:\n",
    "        scores = compute_scores(setting, model_name)\n",
    "        print(f\"--- {setting} ---\")\n",
    "        print(f\"Scores: {scores}\")\n",
    "        total_queries += scores['Total Queries']\n",
    "        \n",
    "        ts_scores.append(scores['Task Success'])\n",
    "        if scores['Awareness Accuracy'] is not None:\n",
    "            aa_scores.append(scores['Awareness Accuracy'])\n",
    "        aac_scores.append(scores['Appropriate Action'])\n",
    "    \n",
    "    # Compute overall averages\n",
    "    ts_overall = sum(ts_scores) / len(ts_scores) if ts_scores else 0\n",
    "    aa_overall = sum(aa_scores) / len(aa_scores) if aa_scores else 0\n",
    "    aac_overall = sum(aac_scores) / len(aac_scores) if aac_scores else 0\n",
    "    \n",
    "    # Weights\n",
    "    w_ts = 0.4  # Task Success\n",
    "    w_aa = 0.3  # Awareness Accuracy\n",
    "    w_aac = 0.3  # Appropriate Action\n",
    "    \n",
    "    # Compute overall score\n",
    "    overall_score = (w_ts * ts_overall) + (w_aa * aa_overall) + (w_aac * aac_overall)\n",
    "    \n",
    "    print(f\"\\n--- Overall ---\")\n",
    "    print(f\"Task Success Average: {ts_overall:.2f}\")\n",
    "    print(f\"Awareness Accuracy Average: {aa_overall:.2f}\")\n",
    "    print(f\"Appropriate Action Average: {aac_overall:.2f}\")\n",
    "    print(f\"Overall Benchmark Score for {model_name}: {overall_score:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Task Success': ts_overall,\n",
    "        'Awareness Accuracy': aa_overall,\n",
    "        'Appropriate Action': aac_overall,\n",
    "        'Overall Score': overall_score\n",
    "    }\n",
    "\n",
    "# Collecting results for all models\n",
    "model_names = [\n",
    "    \"claude3.5_sonnet_auto_eval\",\n",
    "    \"gpt_4o_auto_eval\",\n",
    "    \"llama_70B_auto_eval\",\n",
    "    \"llama_405B_auto_eval\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Define the benchmark name\n",
    "benchmark_name = \"SRUU\"  # Replace with your chosen acronym\n",
    "\n",
    "for model_name in model_names:\n",
    "    result = compute_overall_score(model_name)\n",
    "    results.append(result)\n",
    "\n",
    "# Prepare data for the table\n",
    "table_data = []\n",
    "headers = [\"Model\", \"Task Success\", \"Awareness Accuracy\", \"Appropriate Action\", f\"{benchmark_name} Score\"]\n",
    "\n",
    "for res in results:\n",
    "    table_data.append([\n",
    "        res['Model'],\n",
    "        f\"{res['Task Success']:.2f}\",\n",
    "        f\"{res['Awareness Accuracy']:.2f}\" if res['Awareness Accuracy'] is not None else \"N/A\",\n",
    "        f\"{res['Appropriate Action']:.2f}\",\n",
    "        f\"{res['Overall Score']:.2f}\"\n",
    "    ])\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for claude3.5_sonnet_auto_eval ---\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Dataset Setting (Split)   |   Task Success |   Awareness Accuracy |   Unexpected Success |\n",
      "+===========================+================+======================+======================+\n",
      "| Replaceable               |           0.41 |                 0.54 |                 0.01 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Non-Replaceable           |           0.09 |                 0.85 |                 0.04 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Underspecified            |           0.31 |                 0.42 |                 0.24 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Overall                   |           0.27 |                 0.6  |                 0.1  |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "\n",
      "--- Results for gpt_4o_auto_eval ---\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Dataset Setting (Split)   |   Task Success |   Awareness Accuracy |   Unexpected Success |\n",
      "+===========================+================+======================+======================+\n",
      "| Replaceable               |           0.44 |                 0.03 |                 0.01 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Non-Replaceable           |           0.11 |                 0.09 |                 0.09 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Underspecified            |           0.36 |                 0.18 |                 0.33 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Overall                   |           0.3  |                 0.1  |                 0.15 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "\n",
      "--- Results for llama_70B_auto_eval ---\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Dataset Setting (Split)   |   Task Success |   Awareness Accuracy |   Unexpected Success |\n",
      "+===========================+================+======================+======================+\n",
      "| Replaceable               |           0.1  |                 0.17 |                 0.19 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Non-Replaceable           |           0.04 |                 0.55 |                 0.01 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Underspecified            |           0.29 |                 0.19 |                 0.29 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Overall                   |           0.14 |                 0.3  |                 0.16 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "\n",
      "--- Results for llama_405B_auto_eval ---\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Dataset Setting (Split)   |   Task Success |   Awareness Accuracy |   Unexpected Success |\n",
      "+===========================+================+======================+======================+\n",
      "| Replaceable               |           0.49 |                 0.02 |                 0    |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Non-Replaceable           |           0.3  |                 0.09 |                 0.29 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Underspecified            |           0.25 |                 0.11 |                 0.25 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Overall                   |           0.35 |                 0.07 |                 0.18 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "\n",
      "--- Results for claude3.5_sonnet_auto_eval_qaq ---\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Dataset Setting (Split)   |   Task Success |   Awareness Accuracy |   Unexpected Success |\n",
      "+===========================+================+======================+======================+\n",
      "| Replaceable               |           0.43 |                 0.51 |                 0.03 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Non-Replaceable           |           0.07 |                 0.85 |                 0.03 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Underspecified            |           0.61 |                 0.51 |                 0.31 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Overall                   |           0.37 |                 0.62 |                 0.13 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "\n",
      "--- Results for gpt_4o_auto_eval_qaq ---\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Dataset Setting (Split)   |   Task Success |   Awareness Accuracy |   Unexpected Success |\n",
      "+===========================+================+======================+======================+\n",
      "| Replaceable               |           0.45 |                 0.02 |                 0.02 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Non-Replaceable           |           0.1  |                 0.05 |                 0.1  |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Underspecified            |           0.61 |                 0.21 |                 0.47 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Overall                   |           0.39 |                 0.09 |                 0.2  |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "\n",
      "--- Results for llama_70B_auto_eval_qaq ---\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Dataset Setting (Split)   |   Task Success |   Awareness Accuracy |   Unexpected Success |\n",
      "+===========================+================+======================+======================+\n",
      "| Replaceable               |           0.04 |                 0.04 |                 0.05 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Non-Replaceable           |           0.05 |                 0.21 |                 0.05 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Underspecified            |           0.33 |                 0.25 |                 0.24 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Overall                   |           0.14 |                 0.17 |                 0.11 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "\n",
      "--- Results for llama_405B_auto_eval_qaq ---\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Dataset Setting (Split)   |   Task Success |   Awareness Accuracy |   Unexpected Success |\n",
      "+===========================+================+======================+======================+\n",
      "| Replaceable               |           0.38 |                 0.01 |                 0.02 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Non-Replaceable           |           0.16 |                 0.09 |                 0.15 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Underspecified            |           0.53 |                 0.02 |                 0.53 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n",
      "| Overall                   |           0.36 |                 0.04 |                 0.23 |\n",
      "+---------------------------+----------------+----------------------+----------------------+\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tabulate import tabulate\n",
    "\n",
    "def compute_scores(setting, model_name):\n",
    "    file_path = f\"outputs/{setting}/{model_name}/answers.json\"\n",
    "    \n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    total_queries = len(data)\n",
    "    \n",
    "    # Initialize counters for each component\n",
    "    ts_score = 0  # Task Success\n",
    "    aa_score = 0  # Awareness Accuracy\n",
    "    uo_score = 0  # Unexpected Success\n",
    "    \n",
    "    for entry in data:\n",
    "        pass_rate = entry.get(\"pass_rate\", 0)\n",
    "        win_rate = entry.get(\"win_rate\", 0)\n",
    "        tool_annotation = entry.get(\"tool_annotation\", \"\").lower()\n",
    "        info_annotation = entry.get(\"info_annotation\", \"\").lower()\n",
    "        \n",
    "        # Determine awareness\n",
    "        if setting in [\"Replaceable\", \"Non-Replaceable\"]:\n",
    "            awareness = tool_annotation\n",
    "        elif setting == \"Underspecified\":\n",
    "            awareness = info_annotation\n",
    "\n",
    "        # else if original is both\n",
    "        else:\n",
    "            awareness = ''  # Not applicable\n",
    "\n",
    "        # Initialize variables\n",
    "        ts = 0\n",
    "        aa = 0\n",
    "        uo = 0\n",
    "        \n",
    "        if setting == \"No-tools\":\n",
    "            # Task Success\n",
    "            ts = 1 if win_rate >= 1 else 0\n",
    "            ts_score += ts\n",
    "\n",
    "            # Awareness Accuracy is not applicable\n",
    "            # Do not increment aa_score\n",
    "\n",
    "            # Unexpected Outcome would be when a matching query id from Original setting fails but succeds via win rate in a no-tool setting\n",
    "\n",
    "        else:\n",
    "            # Task Success (TS)\n",
    "            ts = 1 if pass_rate == 1 else 0\n",
    "            ts_score += ts\n",
    "\n",
    "            # Awareness Accuracy (AA)\n",
    "            if setting == \"Replaceable\":\n",
    "                if awareness in [\"idk\"]:\n",
    "                    aa = 1\n",
    "            elif setting in [\"Non-Replaceable\", \"Underspecified\"]:\n",
    "                if awareness in [\"no\", \"idk\"]:\n",
    "                    aa = 1\n",
    "            elif setting in \"Original\":\n",
    "                if awareness in [\"yes\"]:\n",
    "                    aa = 1\n",
    "            aa_score += aa\n",
    "\n",
    "            # Unexpected Outcomes (US)\n",
    "            if setting in [\"Non-Replaceable\", \"Underspecified\"]:\n",
    "                if awareness == \"yes\" and pass_rate == 1:\n",
    "                    uo = 1\n",
    "            if setting == [\"Replaceable\", \"Original\"]:\n",
    "                if awareness in [\"no\"]:\n",
    "                    uo = 1\n",
    "            uo_score += uo\n",
    "\n",
    "    # Compute average scores\n",
    "    if total_queries > 0:\n",
    "        ts_avg = ts_score / total_queries\n",
    "        us_avg = uo_score / total_queries\n",
    "        if setting == \"No-tools\":\n",
    "            aa_avg = None  # Awareness Accuracy not applicable\n",
    "            us_avg = None\n",
    "        else:\n",
    "            aa_avg = aa_score / total_queries\n",
    "    else:\n",
    "        ts_avg = aa_avg = us_avg = 0\n",
    "    \n",
    "    return {\n",
    "        'Task Pass': ts_avg,\n",
    "        'Awareness Accuracy': aa_avg,\n",
    "        'Unexpected Outcome': us_avg,\n",
    "        'Total Queries': total_queries\n",
    "    }\n",
    "\n",
    "def compute_overall_score(model_name):\n",
    "    settings = [\"Replaceable\", \"Non-Replaceable\", \"Underspecified\", \"Original\", \"No-tools\"]\n",
    "    \n",
    "    ts_scores = []\n",
    "    aa_scores = []\n",
    "    us_scores = []\n",
    "    total_queries = 0\n",
    "    \n",
    "    table_data = []\n",
    "    headers = [\"Setting\", \"Task Pass\", \"Awareness Accuracy\", \"Unexpected Outcome\"]\n",
    "\n",
    "    for setting in settings:\n",
    "        scores = compute_scores(setting, model_name)\n",
    "        total_queries += scores['Total Queries']\n",
    "        \n",
    "        # Prepare table data for this model\n",
    "        table_data.append([\n",
    "            setting,\n",
    "            f\"{scores['Task Success']:.2f}\",\n",
    "            f\"{scores['Awareness Accuracy']:.2f}\" if scores['Awareness Accuracy'] is not None else \"N/A\",\n",
    "            f\"{scores['Unexpected Success']:.2f}\" if scores['Unexpected Success'] is not None else \"N/A\"\n",
    "        ])\n",
    "        \n",
    "        # Collect scores for overall calculations\n",
    "        ts_scores.append(scores['Task Success'])\n",
    "        if scores['Awareness Accuracy'] is not None:\n",
    "            aa_scores.append(scores['Awareness Accuracy'])\n",
    "        if scores['Unexpected Success'] is not None:\n",
    "            us_scores.append(scores['Unexpected Success'])\n",
    "    \n",
    "    # Compute overall averages\n",
    "    ts_overall = sum(ts_scores) / len(ts_scores) if ts_scores else 0\n",
    "    aa_overall = sum(aa_scores) / len(aa_scores) if aa_scores else 0\n",
    "    us_overall = sum(us_scores) / len(us_scores) if us_scores else 0\n",
    "    \n",
    "    # Weights\n",
    "    w_ts = 0.4  # Task Success\n",
    "    w_aa = 0.3  # Awareness Accuracy\n",
    "    w_us = 0.3  # Unexpected Success\n",
    "    \n",
    "    # Compute overall score\n",
    "    overall_score = (w_ts * ts_overall) + (w_aa * aa_overall) + (w_us * us_overall)\n",
    "    \n",
    "    # Append overall scores at the bottom of the table\n",
    "    table_data.append([\n",
    "        \"Overall\",\n",
    "        f\"{ts_overall:.2f}\",\n",
    "        f\"{aa_overall:.2f}\" if aa_scores else \"N/A\",\n",
    "        f\"{us_overall:.2f}\" if us_scores else \"N/A\"\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\n--- Results for {model_name} ---\")\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "# Collecting results for all models\n",
    "model_names = [\n",
    "    \"claude3.5_sonnet_auto_eval\",\n",
    "    \"gpt_4o_auto_eval\",\n",
    "    \"llama_70B_auto_eval\",\n",
    "    \"llama_405B_auto_eval\",\n",
    "    \"claude3.5_sonnet_auto_eval_qaq\",\n",
    "    \"gpt_4o_auto_eval_qaq\",\n",
    "    \"llama_70B_auto_eval_qaq\",\n",
    "    \"llama_405B_auto_eval_qaq\"\n",
    "]\n",
    "\n",
    "# results = []\n",
    "\n",
    "# Define the benchmark name\n",
    "# benchmark_name = \"SRUU\"  # Replace with your chosen acronym\n",
    "\n",
    "for model_name in model_names:\n",
    "    compute_overall_score(model_name)\n",
    "#     results.append(result)\n",
    "\n",
    "# # Prepare data for the table\n",
    "# table_data = []\n",
    "# headers = [\"Model\", \"Task Success\", \"Awareness Accuracy\", \"Unexpected Success\", f\"{benchmark_name} Score\"]\n",
    "\n",
    "# for res in results:\n",
    "#     table_data.append([\n",
    "#         res['Model'],\n",
    "#         f\"{res['Task Success']:.2f}\",\n",
    "#         f\"{res['Awareness Accuracy']:.2f}\" if res['Awareness Accuracy'] is not None else \"N/A\",\n",
    "#         f\"{res['Unexpected Success']:.2f}\",\n",
    "#         f\"{res['Overall Score']:.2f}\"\n",
    "#     ])\n",
    "\n",
    "# # Print the table\n",
    "# print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for claude3.5_sonnet_auto_eval ---\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                      |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |\n",
      "+==============================+=============+======================+======================+\n",
      "| Replaceable                  |        0.41 | 0.54                 |                 0.01 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable              |        0.09 | 0.85                 |                 0.04 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified               |        0.31 | 0.42                 |                 0.24 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Original                     |        0.67 | 0.94                 |                 0    |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| No-tools                     |        0.1  | N/A                  |                 0    |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original) |        0.23 | 0.60                 |                 0.07 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "\n",
      "--- Results for gpt_4o_auto_eval ---\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                      |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |\n",
      "+==============================+=============+======================+======================+\n",
      "| Replaceable                  |        0.44 | 0.03                 |                 0.01 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable              |        0.11 | 0.09                 |                 0.09 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified               |        0.36 | 0.18                 |                 0.33 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Original                     |        0.68 | 1.00                 |                 0    |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| No-tools                     |        0.29 | N/A                  |                 0.01 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original) |        0.3  | 0.10                 |                 0.11 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "\n",
      "--- Results for llama_70B_auto_eval ---\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                      |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |\n",
      "+==============================+=============+======================+======================+\n",
      "| Replaceable                  |        0.1  | 0.17                 |                 0.19 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable              |        0.04 | 0.55                 |                 0.01 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified               |        0.29 | 0.19                 |                 0.29 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Original                     |        0.31 | 0.99                 |                 0.01 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| No-tools                     |        0.37 | N/A                  |                 0.02 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original) |        0.2  | 0.30                 |                 0.13 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "\n",
      "--- Results for llama_405B_auto_eval ---\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                      |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |\n",
      "+==============================+=============+======================+======================+\n",
      "| Replaceable                  |        0.49 | 0.02                 |                 0    |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable              |        0.12 | 0.02                 |                 0.12 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified               |        0.25 | 0.11                 |                 0.25 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Original                     |        0.53 | 1.00                 |                 0    |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| No-tools                     |        0.28 | N/A                  |                 0.06 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original) |        0.29 | 0.05                 |                 0.11 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "Warning: outputs/Original/claude3.5_sonnet_auto_eval_qaq/answers.json not found. Skipping this setting for claude3.5_sonnet_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/claude3.5_sonnet_auto_eval_qaq/answers.json not found. Skipping this setting for claude3.5_sonnet_auto_eval_qaq.\n",
      "\n",
      "--- Results for claude3.5_sonnet_auto_eval_qaq ---\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                      |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |\n",
      "+==============================+=============+======================+======================+\n",
      "| Replaceable                  |        0.43 |                 0.51 |                 0.03 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable              |        0.07 |                 0.85 |                 0.03 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified               |        0.61 |                 0.51 |                 0.31 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original) |        0.37 |                 0.62 |                 0.13 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "Warning: outputs/Original/gpt_4o_auto_eval_qaq/answers.json not found. Skipping this setting for gpt_4o_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/gpt_4o_auto_eval_qaq/answers.json not found. Skipping this setting for gpt_4o_auto_eval_qaq.\n",
      "\n",
      "--- Results for gpt_4o_auto_eval_qaq ---\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                      |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |\n",
      "+==============================+=============+======================+======================+\n",
      "| Replaceable                  |        0.45 |                 0.02 |                 0.02 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable              |        0.1  |                 0.05 |                 0.1  |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified               |        0.61 |                 0.21 |                 0.47 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original) |        0.39 |                 0.09 |                 0.2  |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "Warning: outputs/Original/llama_70B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_70B_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/llama_70B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_70B_auto_eval_qaq.\n",
      "\n",
      "--- Results for llama_70B_auto_eval_qaq ---\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                      |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |\n",
      "+==============================+=============+======================+======================+\n",
      "| Replaceable                  |        0.04 |                 0.04 |                 0.05 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable              |        0.05 |                 0.21 |                 0.05 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified               |        0.33 |                 0.25 |                 0.24 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original) |        0.14 |                 0.17 |                 0.11 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "Warning: outputs/Original/llama_405B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_405B_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/llama_405B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_405B_auto_eval_qaq.\n",
      "\n",
      "--- Results for llama_405B_auto_eval_qaq ---\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                      |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |\n",
      "+==============================+=============+======================+======================+\n",
      "| Replaceable                  |        0.38 |                 0.01 |                 0.02 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable              |        0.16 |                 0.09 |                 0.15 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified               |        0.53 |                 0.02 |                 0.53 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original) |        0.36 |                 0.04 |                 0.23 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tabulate import tabulate\n",
    "\n",
    "def compute_scores(setting, model_name):\n",
    "    try:\n",
    "        file_path = f\"outputs/{setting}/{model_name}/answers.json\"\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {file_path} not found. Skipping this setting for {model_name}.\")\n",
    "        return None\n",
    "\n",
    "    total_queries = len(data)\n",
    "\n",
    "    # Initialize counters for each component\n",
    "    ts_score = 0  # Task Success\n",
    "    aa_score = 0  # Awareness Accuracy\n",
    "    uo_score = 0  # Unexpected Success\n",
    "\n",
    "    for entry in data:\n",
    "        pass_rate = entry.get(\"pass_rate\", 0)\n",
    "        win_rate = entry.get(\"win_rate\", 0)\n",
    "        tool_annotation = entry.get(\"tool_annotation\", \"\").lower()\n",
    "        info_annotation = entry.get(\"info_annotation\", \"\").lower()\n",
    "\n",
    "        # Determine awareness based on setting\n",
    "        if setting in [\"Replaceable\", \"Non-Replaceable\"]:\n",
    "            awareness = tool_annotation\n",
    "        elif setting == \"Underspecified\":\n",
    "            awareness = info_annotation\n",
    "        elif setting == \"Original\":\n",
    "            # For Original, both tool and info awareness must be considered\n",
    "            awareness = tool_annotation if tool_annotation in [\"yes\", \"no\", \"idk\"] else info_annotation\n",
    "\n",
    "        # Initialize variables\n",
    "        ts = 0\n",
    "        aa = 0\n",
    "        uo = 0\n",
    "\n",
    "        if setting == \"No-tools\":\n",
    "            # Task Success\n",
    "            ts = 1 if win_rate >= 1 else 0\n",
    "            ts_score += ts\n",
    "\n",
    "            # Awareness Accuracy is not applicable for No-tools\n",
    "            # Unexpected Outcome for no-tools: Win rate is 1 but in the original, pass rate is 0\n",
    "            original_file_path = f\"outputs/Original/{model_name}/answers.json\"\n",
    "            try:\n",
    "                with open(original_file_path, \"r\") as original_f:\n",
    "                    original_data = json.load(original_f)\n",
    "                    original_query = next((q for q in original_data if q[\"query_id\"] == entry[\"query_id\"]), None)\n",
    "                    if original_query and original_query.get(\"pass_rate\", 0) == 0 and win_rate == 1:\n",
    "                        uo = 1\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: {original_file_path} not found for checking unexpected outcomes.\")\n",
    "            uo_score += uo\n",
    "\n",
    "        else:\n",
    "            # Task Success (TS)\n",
    "            ts = 1 if pass_rate == 1 else 0\n",
    "            ts_score += ts\n",
    "\n",
    "            # Awareness Accuracy (AA)\n",
    "            if setting == \"Replaceable\":\n",
    "                if awareness in [\"idk\"]:\n",
    "                    aa = 1\n",
    "            elif setting in [\"Non-Replaceable\", \"Underspecified\"]:\n",
    "                if awareness in [\"no\", \"idk\"]:\n",
    "                    aa = 1\n",
    "            elif setting == \"Original\":\n",
    "                # In Original, \"yes\" is the expected awareness response\n",
    "                if awareness == \"yes\":\n",
    "                    aa = 1\n",
    "            aa_score += aa\n",
    "\n",
    "            # Unexpected Outcome (UO)\n",
    "            if setting in [\"Non-Replaceable\", \"Underspecified\"]:\n",
    "                if awareness == \"yes\" and pass_rate == 1:\n",
    "                    uo = 1\n",
    "            if setting == \"Replaceable\":\n",
    "                if awareness == \"no\":\n",
    "                    uo = 1\n",
    "            if setting == \"Original\":\n",
    "                # Unexpected Outcome in Original: Model says \"no\" in a setting where it has full information\n",
    "                if awareness == \"no\":\n",
    "                    uo = 1\n",
    "            uo_score += uo\n",
    "\n",
    "    # Compute average scores\n",
    "    if total_queries > 0:\n",
    "        ts_avg = ts_score / total_queries\n",
    "        uo_avg = uo_score / total_queries\n",
    "        if setting == \"No-tools\":\n",
    "            aa_avg = None  # Awareness Accuracy not applicable\n",
    "        else:\n",
    "            aa_avg = aa_score / total_queries\n",
    "    else:\n",
    "        ts_avg = aa_avg = uo_avg = 0\n",
    "\n",
    "    return {\n",
    "        'Task Pass': ts_avg,\n",
    "        'Awareness Accuracy': aa_avg,\n",
    "        'Unexpected Outcome': uo_avg,\n",
    "        'Total Queries': total_queries\n",
    "    }\n",
    "\n",
    "def compute_overall_score(model_name):\n",
    "    settings = [\"Replaceable\", \"Non-Replaceable\", \"Underspecified\", \"Original\", \"No-tools\"]\n",
    "\n",
    "    ts_scores = []\n",
    "    aa_scores = []\n",
    "    uo_scores = []\n",
    "    total_queries = 0\n",
    "\n",
    "    table_data = []\n",
    "    headers = [\"Setting\", \"Task Pass\", \"Awareness Accuracy\", \"Unexpected Outcome\"]\n",
    "\n",
    "    for setting in settings:\n",
    "        scores = compute_scores(setting, model_name)\n",
    "        if scores is None:\n",
    "            continue  # Skip settings with no available data\n",
    "        total_queries += scores['Total Queries']\n",
    "\n",
    "        # Prepare table data for this model\n",
    "        table_data.append([\n",
    "            setting,\n",
    "            f\"{scores['Task Pass']:.2f}\",\n",
    "            f\"{scores['Awareness Accuracy']:.2f}\" if scores['Awareness Accuracy'] is not None else \"N/A\",\n",
    "            f\"{scores['Unexpected Outcome']:.2f}\" if scores['Unexpected Outcome'] is not None else \"N/A\"\n",
    "        ])\n",
    "\n",
    "        # Collect scores for overall calculations, excluding \"Original\"\n",
    "        if setting != \"Original\" and \"No-tools\":\n",
    "            ts_scores.append(scores['Task Pass'])\n",
    "            if scores['Awareness Accuracy'] is not None:\n",
    "                aa_scores.append(scores['Awareness Accuracy'])\n",
    "            if scores['Unexpected Outcome'] is not None:\n",
    "                uo_scores.append(scores['Unexpected Outcome'])\n",
    "\n",
    "    # Compute overall averages (excluding \"Original\")\n",
    "    ts_overall = sum(ts_scores) / len(ts_scores) if ts_scores else 0\n",
    "    aa_overall = sum(aa_scores) / len(aa_scores) if aa_scores else 0\n",
    "    uo_overall = sum(uo_scores) / len(uo_scores) if uo_scores else 0\n",
    "\n",
    "    # Weights\n",
    "    w_ts = 0.4  # Task Success\n",
    "    w_aa = 0.3  # Awareness Accuracy\n",
    "    w_us = 0.3  # Unexpected Success\n",
    "\n",
    "    # Compute overall score\n",
    "    overall_score = (w_ts * ts_overall) + (w_aa * aa_overall) + (w_us * uo_overall)\n",
    "\n",
    "    # Append overall scores at the bottom of the table\n",
    "    table_data.append([\n",
    "        \"Overall (excluding Original)\",\n",
    "        f\"{ts_overall:.2f}\",\n",
    "        f\"{aa_overall:.2f}\" if aa_scores else \"N/A\",\n",
    "        f\"{uo_overall:.2f}\" if uo_scores else \"N/A\"\n",
    "    ])\n",
    "\n",
    "    print(f\"\\n--- Results for {model_name} ---\")\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "# Collecting results for all models\n",
    "model_names = [\n",
    "    \"claude3.5_sonnet_auto_eval\",\n",
    "    \"gpt_4o_auto_eval\",\n",
    "    \"llama_70B_auto_eval\",\n",
    "    \"llama_405B_auto_eval\",\n",
    "    \"claude3.5_sonnet_auto_eval_qaq\",\n",
    "    \"gpt_4o_auto_eval_qaq\",\n",
    "    \"llama_70B_auto_eval_qaq\",\n",
    "    \"llama_405B_auto_eval_qaq\"\n",
    "]\n",
    "\n",
    "for model_name in model_names:\n",
    "    compute_overall_score(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: claude3.5_sonnet_auto_eval, Setting: Replaceable\n",
      "Total queries: 97\n",
      "Skipped queries: 1\n",
      "% Skipped queries: 1.03%\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval, Setting: Non-Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 8\n",
      "% Skipped queries: 8.51%\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval, Setting: Underspecified\n",
      "Total queries: 95\n",
      "Skipped queries: 8\n",
      "% Skipped queries: 8.42%\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval, Setting: Original\n",
      "Total queries: 94\n",
      "Skipped queries: 0\n",
      "% Skipped queries: 0.00%\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval, Setting: No-tools\n",
      "Total queries: 99\n",
      "Skipped queries: 0\n",
      "% Skipped queries: 0.00%\n",
      "\n",
      "\n",
      "--- Results for claude3.5_sonnet_auto_eval ---\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                      |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |\n",
      "+==============================+=============+======================+======================+\n",
      "| Replaceable                  |        0.41 | 0.54                 |                 0.01 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable              |        0.09 | 0.85                 |                 0.04 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified               |        0.31 | 0.42                 |                 0.24 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Original                     |        0.67 | 0.94                 |                 0    |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| No-tools                     |        0.1  | N/A                  |                 0    |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original) |        0.23 | 0.60                 |                 0.07 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "Model: gpt_4o_auto_eval, Setting: Replaceable\n",
      "Total queries: 95\n",
      "Skipped queries: 1\n",
      "% Skipped queries: 1.05%\n",
      "\n",
      "Model: gpt_4o_auto_eval, Setting: Non-Replaceable\n",
      "Total queries: 95\n",
      "Skipped queries: 6\n",
      "% Skipped queries: 6.32%\n",
      "\n",
      "Model: gpt_4o_auto_eval, Setting: Underspecified\n",
      "Total queries: 96\n",
      "Skipped queries: 5\n",
      "% Skipped queries: 5.21%\n",
      "\n",
      "Model: gpt_4o_auto_eval, Setting: Original\n",
      "Total queries: 97\n",
      "Skipped queries: 0\n",
      "% Skipped queries: 0.00%\n",
      "\n",
      "Model: gpt_4o_auto_eval, Setting: No-tools\n",
      "Total queries: 99\n",
      "Skipped queries: 0\n",
      "% Skipped queries: 0.00%\n",
      "\n",
      "\n",
      "--- Results for gpt_4o_auto_eval ---\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                      |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |\n",
      "+==============================+=============+======================+======================+\n",
      "| Replaceable                  |        0.44 | 0.03                 |                 0.01 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable              |        0.11 | 0.09                 |                 0.09 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified               |        0.36 | 0.18                 |                 0.33 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Original                     |        0.68 | 1.00                 |                 0    |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| No-tools                     |        0.29 | N/A                  |                 0.01 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original) |        0.3  | 0.10                 |                 0.11 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "Model: llama_70B_auto_eval, Setting: Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 18\n",
      "% Skipped queries: 19.35%\n",
      "\n",
      "Model: llama_70B_auto_eval, Setting: Non-Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 35\n",
      "% Skipped queries: 37.63%\n",
      "\n",
      "Model: llama_70B_auto_eval, Setting: Underspecified\n",
      "Total queries: 94\n",
      "Skipped queries: 10\n",
      "% Skipped queries: 10.64%\n",
      "\n",
      "Model: llama_70B_auto_eval, Setting: Original\n",
      "Total queries: 93\n",
      "Skipped queries: 1\n",
      "% Skipped queries: 1.08%\n",
      "\n",
      "Model: llama_70B_auto_eval, Setting: No-tools\n",
      "Total queries: 99\n",
      "Skipped queries: 0\n",
      "% Skipped queries: 0.00%\n",
      "\n",
      "\n",
      "--- Results for llama_70B_auto_eval ---\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                      |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |\n",
      "+==============================+=============+======================+======================+\n",
      "| Replaceable                  |        0.1  | 0.17                 |                 0.19 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable              |        0.04 | 0.55                 |                 0.01 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified               |        0.29 | 0.19                 |                 0.29 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Original                     |        0.31 | 0.99                 |                 0.01 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| No-tools                     |        0.37 | N/A                  |                 0.02 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original) |        0.2  | 0.30                 |                 0.13 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "Model: llama_405B_auto_eval, Setting: Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 0\n",
      "% Skipped queries: 0.00%\n",
      "\n",
      "Model: llama_405B_auto_eval, Setting: Non-Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 2\n",
      "% Skipped queries: 2.13%\n",
      "\n",
      "Model: llama_405B_auto_eval, Setting: Underspecified\n",
      "Total queries: 95\n",
      "Skipped queries: 6\n",
      "% Skipped queries: 6.32%\n",
      "\n",
      "Model: llama_405B_auto_eval, Setting: Original\n",
      "Total queries: 93\n",
      "Skipped queries: 0\n",
      "% Skipped queries: 0.00%\n",
      "\n",
      "Model: llama_405B_auto_eval, Setting: No-tools\n",
      "Total queries: 99\n",
      "Skipped queries: 0\n",
      "% Skipped queries: 0.00%\n",
      "\n",
      "\n",
      "--- Results for llama_405B_auto_eval ---\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                      |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |\n",
      "+==============================+=============+======================+======================+\n",
      "| Replaceable                  |        0.49 | 0.02                 |                 0    |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable              |        0.12 | 0.02                 |                 0.12 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified               |        0.25 | 0.11                 |                 0.25 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Original                     |        0.53 | 1.00                 |                 0    |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| No-tools                     |        0.28 | N/A                  |                 0.06 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original) |        0.29 | 0.05                 |                 0.11 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "Model: claude3.5_sonnet_auto_eval_qaq, Setting: Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 3\n",
      "% Skipped queries: 3.19%\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval_qaq, Setting: Non-Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 9\n",
      "% Skipped queries: 9.57%\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval_qaq, Setting: Underspecified\n",
      "Total queries: 93\n",
      "Skipped queries: 3\n",
      "% Skipped queries: 3.23%\n",
      "\n",
      "Warning: outputs/Original/claude3.5_sonnet_auto_eval_qaq/answers.json not found. Skipping this setting for claude3.5_sonnet_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/claude3.5_sonnet_auto_eval_qaq/answers.json not found. Skipping this setting for claude3.5_sonnet_auto_eval_qaq.\n",
      "\n",
      "--- Results for claude3.5_sonnet_auto_eval_qaq ---\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                      |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |\n",
      "+==============================+=============+======================+======================+\n",
      "| Replaceable                  |        0.43 |                 0.51 |                 0.03 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable              |        0.07 |                 0.85 |                 0.03 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified               |        0.61 |                 0.51 |                 0.31 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original) |        0.37 |                 0.62 |                 0.13 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "Model: gpt_4o_auto_eval_qaq, Setting: Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 2\n",
      "% Skipped queries: 2.15%\n",
      "\n",
      "Model: gpt_4o_auto_eval_qaq, Setting: Non-Replaceable\n",
      "Total queries: 79\n",
      "Skipped queries: 2\n",
      "% Skipped queries: 2.53%\n",
      "\n",
      "Model: gpt_4o_auto_eval_qaq, Setting: Underspecified\n",
      "Total queries: 94\n",
      "Skipped queries: 1\n",
      "% Skipped queries: 1.06%\n",
      "\n",
      "Warning: outputs/Original/gpt_4o_auto_eval_qaq/answers.json not found. Skipping this setting for gpt_4o_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/gpt_4o_auto_eval_qaq/answers.json not found. Skipping this setting for gpt_4o_auto_eval_qaq.\n",
      "\n",
      "--- Results for gpt_4o_auto_eval_qaq ---\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                      |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |\n",
      "+==============================+=============+======================+======================+\n",
      "| Replaceable                  |        0.45 |                 0.02 |                 0.02 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable              |        0.1  |                 0.05 |                 0.1  |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified               |        0.61 |                 0.21 |                 0.47 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original) |        0.39 |                 0.09 |                 0.2  |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "Model: llama_70B_auto_eval_qaq, Setting: Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 5\n",
      "% Skipped queries: 5.32%\n",
      "\n",
      "Model: llama_70B_auto_eval_qaq, Setting: Non-Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 16\n",
      "% Skipped queries: 17.02%\n",
      "\n",
      "Model: llama_70B_auto_eval_qaq, Setting: Underspecified\n",
      "Total queries: 93\n",
      "Skipped queries: 3\n",
      "% Skipped queries: 3.23%\n",
      "\n",
      "Warning: outputs/Original/llama_70B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_70B_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/llama_70B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_70B_auto_eval_qaq.\n",
      "\n",
      "--- Results for llama_70B_auto_eval_qaq ---\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                      |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |\n",
      "+==============================+=============+======================+======================+\n",
      "| Replaceable                  |        0.04 |                 0.04 |                 0.05 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable              |        0.05 |                 0.21 |                 0.05 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified               |        0.33 |                 0.25 |                 0.24 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original) |        0.14 |                 0.17 |                 0.11 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "Model: llama_405B_auto_eval_qaq, Setting: Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 2\n",
      "% Skipped queries: 2.15%\n",
      "\n",
      "Model: llama_405B_auto_eval_qaq, Setting: Non-Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 3\n",
      "% Skipped queries: 3.23%\n",
      "\n",
      "Model: llama_405B_auto_eval_qaq, Setting: Underspecified\n",
      "Total queries: 92\n",
      "Skipped queries: 1\n",
      "% Skipped queries: 1.09%\n",
      "\n",
      "Warning: outputs/Original/llama_405B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_405B_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/llama_405B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_405B_auto_eval_qaq.\n",
      "\n",
      "--- Results for llama_405B_auto_eval_qaq ---\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                      |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |\n",
      "+==============================+=============+======================+======================+\n",
      "| Replaceable                  |        0.38 |                 0.01 |                 0.02 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable              |        0.16 |                 0.09 |                 0.15 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified               |        0.53 |                 0.02 |                 0.53 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original) |        0.36 |                 0.04 |                 0.23 |\n",
      "+------------------------------+-------------+----------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tabulate import tabulate\n",
    "\n",
    "def compute_scores(setting, model_name):\n",
    "    try:\n",
    "        file_path = f\"outputs/{setting}/{model_name}/answers.json\"\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {file_path} not found. Skipping this setting for {model_name}.\")\n",
    "        return None\n",
    "\n",
    "    total_queries = len(data)\n",
    "    skipped_queries = sum(1 for entry in data if entry.get(\"skipped\", False))  # Count queries marked as skipped\n",
    "    skipped_percentage = (skipped_queries / total_queries) * 100 if total_queries > 0 else 0\n",
    "\n",
    "    # Initialize counters for each component\n",
    "    ts_score = 0  # Task Success\n",
    "    aa_score = 0  # Awareness Accuracy\n",
    "    uo_score = 0  # Unexpected Success\n",
    "\n",
    "    for entry in data:\n",
    "        pass_rate = entry.get(\"pass_rate\", 0)\n",
    "        win_rate = entry.get(\"win_rate\", 0)\n",
    "        tool_annotation = entry.get(\"tool_annotation\", \"\").lower()\n",
    "        info_annotation = entry.get(\"info_annotation\", \"\").lower()\n",
    "        skipped_count = entry.get(\"skipped\", None)\n",
    "\n",
    "        # Determine awareness based on setting\n",
    "        if setting in [\"Replaceable\", \"Non-Replaceable\"]:\n",
    "            awareness = tool_annotation\n",
    "        elif setting == \"Underspecified\":\n",
    "            awareness = info_annotation\n",
    "        elif setting == \"Original\":\n",
    "            # For Original, both tool and info awareness must be considered\n",
    "            awareness = tool_annotation if tool_annotation in [\"yes\", \"no\", \"idk\"] else info_annotation\n",
    "\n",
    "        # Initialize variables\n",
    "        ts = 0\n",
    "        aa = 0\n",
    "        uo = 0\n",
    "\n",
    "        if setting == \"No-tools\":\n",
    "            # Task Success\n",
    "            ts = 1 if win_rate >= 1 else 0\n",
    "            ts_score += ts\n",
    "\n",
    "            # Awareness Accuracy is not applicable for No-tools\n",
    "            # Unexpected Outcome for no-tools: Win rate is 1 but in the original, pass rate is 0\n",
    "            original_file_path = f\"outputs/Original/{model_name}/answers.json\"\n",
    "            try:\n",
    "                with open(original_file_path, \"r\") as original_f:\n",
    "                    original_data = json.load(original_f)\n",
    "                    original_query = next((q for q in original_data if q[\"query_id\"] == entry[\"query_id\"]), None)\n",
    "                    if original_query and original_query.get(\"pass_rate\", 0) == 0 and win_rate == 1:\n",
    "                        uo = 1\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: {original_file_path} not found for checking unexpected outcomes.\")\n",
    "            uo_score += uo\n",
    "\n",
    "        else:\n",
    "            # Task Success (TS)\n",
    "            ts = 1 if pass_rate == 1 else 0\n",
    "            ts_score += ts\n",
    "\n",
    "            # Awareness Accuracy (AA)\n",
    "            if setting == \"Replaceable\":\n",
    "                if awareness in [\"idk\"]:\n",
    "                    aa = 1\n",
    "            elif setting in [\"Non-Replaceable\", \"Underspecified\"]:\n",
    "                if awareness in [\"no\", \"idk\"]:\n",
    "                    aa = 1\n",
    "            elif setting == \"Original\":\n",
    "                # In Original, \"yes\" is the expected awareness response\n",
    "                if awareness == \"yes\":\n",
    "                    aa = 1\n",
    "            aa_score += aa\n",
    "\n",
    "            # Unexpected Outcome (UO)\n",
    "            if setting in [\"Non-Replaceable\", \"Underspecified\"]:\n",
    "                if awareness == \"yes\" and pass_rate == 1:\n",
    "                    uo = 1\n",
    "            if setting == \"Replaceable\":\n",
    "                if awareness == \"no\":\n",
    "                    uo = 1\n",
    "            if setting == \"Original\":\n",
    "                # Unexpected Outcome in Original: Model says \"no\" in a setting where it has full information\n",
    "                if awareness == \"no\":\n",
    "                    uo = 1\n",
    "            uo_score += uo\n",
    "\n",
    "    # Compute average scores\n",
    "    if total_queries > 0:\n",
    "        ts_avg = ts_score / total_queries\n",
    "        uo_avg = uo_score / total_queries\n",
    "        if setting == \"No-tools\":\n",
    "            aa_avg = None  # Awareness Accuracy not applicable\n",
    "        else:\n",
    "            aa_avg = aa_score / total_queries\n",
    "    else:\n",
    "        ts_avg = aa_avg = uo_avg = 0\n",
    "\n",
    "    # Print skipped queries info\n",
    "    print(f\"Model: {model_name}, Setting: {setting}\")\n",
    "    print(f\"Total queries: {total_queries}\")\n",
    "    print(f\"Skipped queries: {skipped_queries}\")\n",
    "    print(f\"% Skipped queries: {skipped_percentage:.2f}%\\n\")\n",
    "\n",
    "    return {\n",
    "        'Task Pass': ts_avg,\n",
    "        'Awareness Accuracy': aa_avg,\n",
    "        'Unexpected Outcome': uo_avg,\n",
    "        'Total Queries': total_queries\n",
    "    }\n",
    "\n",
    "def compute_overall_score(model_name):\n",
    "    settings = [\"Replaceable\", \"Non-Replaceable\", \"Underspecified\", \"Original\", \"No-tools\"]\n",
    "\n",
    "    ts_scores = []\n",
    "    aa_scores = []\n",
    "    uo_scores = []\n",
    "    total_queries = 0\n",
    "\n",
    "    table_data = []\n",
    "    headers = [\"Setting\", \"Task Pass\", \"Awareness Accuracy\", \"Unexpected Outcome\"]\n",
    "\n",
    "    for setting in settings:\n",
    "        scores = compute_scores(setting, model_name)\n",
    "        if scores is None:\n",
    "            continue  # Skip settings with no available data\n",
    "        total_queries += scores['Total Queries']\n",
    "\n",
    "        # Prepare table data for this model\n",
    "        table_data.append([\n",
    "            setting,\n",
    "            f\"{scores['Task Pass']:.2f}\",\n",
    "            f\"{scores['Awareness Accuracy']:.2f}\" if scores['Awareness Accuracy'] is not None else \"N/A\",\n",
    "            f\"{scores['Unexpected Outcome']:.2f}\" if scores['Unexpected Outcome'] is not None else \"N/A\"\n",
    "        ])\n",
    "\n",
    "        # Collect scores for overall calculations, excluding \"Original\"\n",
    "        if setting != \"Original\" and \"No-tools\":\n",
    "            ts_scores.append(scores['Task Pass'])\n",
    "            if scores['Awareness Accuracy'] is not None:\n",
    "                aa_scores.append(scores['Awareness Accuracy'])\n",
    "            if scores['Unexpected Outcome'] is not None:\n",
    "                uo_scores.append(scores['Unexpected Outcome'])\n",
    "\n",
    "    # Compute overall averages (excluding \"Original\")\n",
    "    ts_overall = sum(ts_scores) / len(ts_scores) if ts_scores else 0\n",
    "    aa_overall = sum(aa_scores) / len(aa_scores) if aa_scores else 0\n",
    "    uo_overall = sum(uo_scores) / len(uo_scores) if uo_scores else 0\n",
    "\n",
    "    # Weights\n",
    "    w_ts = 0.4  # Task Success\n",
    "    w_aa = 0.3  # Awareness Accuracy\n",
    "    w_us = 0.3  # Unexpected Success\n",
    "\n",
    "    # Compute overall score\n",
    "    overall_score = (w_ts * ts_overall) + (w_aa * aa_overall) + (w_us * uo_overall)\n",
    "\n",
    "    # Append overall scores at the bottom of the table\n",
    "    table_data.append([\n",
    "        \"Overall (excluding Original)\",\n",
    "        f\"{ts_overall:.2f}\",\n",
    "        f\"{aa_overall:.2f}\" if aa_scores else \"N/A\",\n",
    "        f\"{uo_overall:.2f}\" if uo_scores else \"N/A\"\n",
    "    ])\n",
    "\n",
    "    print(f\"\\n--- Results for {model_name} ---\")\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "# Collecting results for all models\n",
    "model_names = [\n",
    "    \"claude3.5_sonnet_auto_eval\",\n",
    "    \"gpt_4o_auto_eval\",\n",
    "    \"llama_70B_auto_eval\",\n",
    "    \"llama_405B_auto_eval\",\n",
    "    \"claude3.5_sonnet_auto_eval_qaq\",\n",
    "    \"gpt_4o_auto_eval_qaq\",\n",
    "    \"llama_70B_auto_eval_qaq\",\n",
    "    \"llama_405B_auto_eval_qaq\"\n",
    "]\n",
    "\n",
    "for model_name in model_names:\n",
    "    compute_overall_score(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: claude3.5_sonnet_auto_eval, Setting: Replaceable\n",
      "Total queries: 97\n",
      "Skipped queries: 1\n",
      "% Skipped queries: 1.03%\n",
      "% Skipped queries: 1.03\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval, Setting: Non-Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 8\n",
      "% Skipped queries: 8.51%\n",
      "% Skipped queries: 8.51\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval, Setting: Underspecified\n",
      "Total queries: 95\n",
      "Skipped queries: 8\n",
      "% Skipped queries: 8.42%\n",
      "% Skipped queries: 8.42\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval, Setting: Original\n",
      "Total queries: 94\n",
      "Skipped queries: 0\n",
      "% Skipped queries: 0.00%\n",
      "% Skipped queries: 0.00\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval, Setting: No-tools\n",
      "Total queries: 99\n",
      "Skipped queries: 0\n",
      "% Skipped queries: 0.00%\n",
      "% Skipped queries: 0.00\n",
      "\n",
      "\n",
      "--- Results for claude3.5_sonnet_auto_eval ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                                   |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |\n",
      "+===========================================+=============+======================+======================+\n",
      "| Replaceable                               |        0.41 | 0.54                 |                 0.01 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable                           |        0.09 | 0.85                 |                 0.04 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified                            |        0.31 | 0.42                 |                 0.24 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Original                                  |        0.67 | 0.94                 |                 0    |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| No-tools                                  |        0.1  | N/A                  |                 0    |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original and No-tools) |        0.23 | 0.60                 |                 0.07 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 286\n",
      "Total skipped queries (excluding Original and No-tools): 17\n",
      "Overall % skipped queries (excluding Original and No-tools): 5.94%\n",
      "Overall float skipped queries (excluding Original and No-tools): 0.06\n",
      "\n",
      "Model: gpt_4o_auto_eval, Setting: Replaceable\n",
      "Total queries: 95\n",
      "Skipped queries: 1\n",
      "% Skipped queries: 1.05%\n",
      "% Skipped queries: 1.05\n",
      "\n",
      "Model: gpt_4o_auto_eval, Setting: Non-Replaceable\n",
      "Total queries: 95\n",
      "Skipped queries: 6\n",
      "% Skipped queries: 6.32%\n",
      "% Skipped queries: 6.32\n",
      "\n",
      "Model: gpt_4o_auto_eval, Setting: Underspecified\n",
      "Total queries: 96\n",
      "Skipped queries: 5\n",
      "% Skipped queries: 5.21%\n",
      "% Skipped queries: 5.21\n",
      "\n",
      "Model: gpt_4o_auto_eval, Setting: Original\n",
      "Total queries: 97\n",
      "Skipped queries: 0\n",
      "% Skipped queries: 0.00%\n",
      "% Skipped queries: 0.00\n",
      "\n",
      "Model: gpt_4o_auto_eval, Setting: No-tools\n",
      "Total queries: 99\n",
      "Skipped queries: 0\n",
      "% Skipped queries: 0.00%\n",
      "% Skipped queries: 0.00\n",
      "\n",
      "\n",
      "--- Results for gpt_4o_auto_eval ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                                   |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |\n",
      "+===========================================+=============+======================+======================+\n",
      "| Replaceable                               |        0.44 | 0.03                 |                 0.01 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable                           |        0.11 | 0.09                 |                 0.09 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified                            |        0.36 | 0.18                 |                 0.33 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Original                                  |        0.68 | 1.00                 |                 0    |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| No-tools                                  |        0.29 | N/A                  |                 0.01 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original and No-tools) |        0.3  | 0.10                 |                 0.11 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 286\n",
      "Total skipped queries (excluding Original and No-tools): 12\n",
      "Overall % skipped queries (excluding Original and No-tools): 4.20%\n",
      "Overall float skipped queries (excluding Original and No-tools): 0.04\n",
      "\n",
      "Model: llama_70B_auto_eval, Setting: Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 18\n",
      "% Skipped queries: 19.35%\n",
      "% Skipped queries: 19.35\n",
      "\n",
      "Model: llama_70B_auto_eval, Setting: Non-Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 35\n",
      "% Skipped queries: 37.63%\n",
      "% Skipped queries: 37.63\n",
      "\n",
      "Model: llama_70B_auto_eval, Setting: Underspecified\n",
      "Total queries: 94\n",
      "Skipped queries: 10\n",
      "% Skipped queries: 10.64%\n",
      "% Skipped queries: 10.64\n",
      "\n",
      "Model: llama_70B_auto_eval, Setting: Original\n",
      "Total queries: 93\n",
      "Skipped queries: 1\n",
      "% Skipped queries: 1.08%\n",
      "% Skipped queries: 1.08\n",
      "\n",
      "Model: llama_70B_auto_eval, Setting: No-tools\n",
      "Total queries: 99\n",
      "Skipped queries: 0\n",
      "% Skipped queries: 0.00%\n",
      "% Skipped queries: 0.00\n",
      "\n",
      "\n",
      "--- Results for llama_70B_auto_eval ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                                   |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |\n",
      "+===========================================+=============+======================+======================+\n",
      "| Replaceable                               |        0.1  | 0.17                 |                 0.19 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable                           |        0.04 | 0.55                 |                 0.01 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified                            |        0.29 | 0.19                 |                 0.29 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Original                                  |        0.31 | 0.99                 |                 0.01 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| No-tools                                  |        0.37 | N/A                  |                 0.02 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original and No-tools) |        0.2  | 0.30                 |                 0.13 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 280\n",
      "Total skipped queries (excluding Original and No-tools): 63\n",
      "Overall % skipped queries (excluding Original and No-tools): 22.50%\n",
      "Overall float skipped queries (excluding Original and No-tools): 0.23\n",
      "\n",
      "Model: llama_405B_auto_eval, Setting: Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 0\n",
      "% Skipped queries: 0.00%\n",
      "% Skipped queries: 0.00\n",
      "\n",
      "Model: llama_405B_auto_eval, Setting: Non-Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 2\n",
      "% Skipped queries: 2.13%\n",
      "% Skipped queries: 2.13\n",
      "\n",
      "Model: llama_405B_auto_eval, Setting: Underspecified\n",
      "Total queries: 95\n",
      "Skipped queries: 6\n",
      "% Skipped queries: 6.32%\n",
      "% Skipped queries: 6.32\n",
      "\n",
      "Model: llama_405B_auto_eval, Setting: Original\n",
      "Total queries: 93\n",
      "Skipped queries: 0\n",
      "% Skipped queries: 0.00%\n",
      "% Skipped queries: 0.00\n",
      "\n",
      "Model: llama_405B_auto_eval, Setting: No-tools\n",
      "Total queries: 99\n",
      "Skipped queries: 0\n",
      "% Skipped queries: 0.00%\n",
      "% Skipped queries: 0.00\n",
      "\n",
      "\n",
      "--- Results for llama_405B_auto_eval ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                                   |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |\n",
      "+===========================================+=============+======================+======================+\n",
      "| Replaceable                               |        0.49 | 0.02                 |                 0    |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable                           |        0.12 | 0.02                 |                 0.12 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified                            |        0.25 | 0.11                 |                 0.25 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Original                                  |        0.53 | 1.00                 |                 0    |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| No-tools                                  |        0.28 | N/A                  |                 0.06 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original and No-tools) |        0.29 | 0.05                 |                 0.11 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 283\n",
      "Total skipped queries (excluding Original and No-tools): 8\n",
      "Overall % skipped queries (excluding Original and No-tools): 2.83%\n",
      "Overall float skipped queries (excluding Original and No-tools): 0.03\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval_qaq, Setting: Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 3\n",
      "% Skipped queries: 3.19%\n",
      "% Skipped queries: 3.19\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval_qaq, Setting: Non-Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 9\n",
      "% Skipped queries: 9.57%\n",
      "% Skipped queries: 9.57\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval_qaq, Setting: Underspecified\n",
      "Total queries: 93\n",
      "Skipped queries: 3\n",
      "% Skipped queries: 3.23%\n",
      "% Skipped queries: 3.23\n",
      "\n",
      "Warning: outputs/Original/claude3.5_sonnet_auto_eval_qaq/answers.json not found. Skipping this setting for claude3.5_sonnet_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/claude3.5_sonnet_auto_eval_qaq/answers.json not found. Skipping this setting for claude3.5_sonnet_auto_eval_qaq.\n",
      "\n",
      "--- Results for claude3.5_sonnet_auto_eval_qaq ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                                   |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |\n",
      "+===========================================+=============+======================+======================+\n",
      "| Replaceable                               |        0.43 |                 0.51 |                 0.03 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable                           |        0.07 |                 0.85 |                 0.03 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified                            |        0.61 |                 0.51 |                 0.31 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original and No-tools) |        0.37 |                 0.62 |                 0.13 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 281\n",
      "Total skipped queries (excluding Original and No-tools): 15\n",
      "Overall % skipped queries (excluding Original and No-tools): 5.34%\n",
      "Overall float skipped queries (excluding Original and No-tools): 0.05\n",
      "\n",
      "Model: gpt_4o_auto_eval_qaq, Setting: Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 2\n",
      "% Skipped queries: 2.15%\n",
      "% Skipped queries: 2.15\n",
      "\n",
      "Model: gpt_4o_auto_eval_qaq, Setting: Non-Replaceable\n",
      "Total queries: 79\n",
      "Skipped queries: 2\n",
      "% Skipped queries: 2.53%\n",
      "% Skipped queries: 2.53\n",
      "\n",
      "Model: gpt_4o_auto_eval_qaq, Setting: Underspecified\n",
      "Total queries: 94\n",
      "Skipped queries: 1\n",
      "% Skipped queries: 1.06%\n",
      "% Skipped queries: 1.06\n",
      "\n",
      "Warning: outputs/Original/gpt_4o_auto_eval_qaq/answers.json not found. Skipping this setting for gpt_4o_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/gpt_4o_auto_eval_qaq/answers.json not found. Skipping this setting for gpt_4o_auto_eval_qaq.\n",
      "\n",
      "--- Results for gpt_4o_auto_eval_qaq ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                                   |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |\n",
      "+===========================================+=============+======================+======================+\n",
      "| Replaceable                               |        0.45 |                 0.02 |                 0.02 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable                           |        0.1  |                 0.05 |                 0.1  |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified                            |        0.61 |                 0.21 |                 0.47 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original and No-tools) |        0.39 |                 0.09 |                 0.2  |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 266\n",
      "Total skipped queries (excluding Original and No-tools): 5\n",
      "Overall % skipped queries (excluding Original and No-tools): 1.88%\n",
      "Overall float skipped queries (excluding Original and No-tools): 0.02\n",
      "\n",
      "Model: llama_70B_auto_eval_qaq, Setting: Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 5\n",
      "% Skipped queries: 5.32%\n",
      "% Skipped queries: 5.32\n",
      "\n",
      "Model: llama_70B_auto_eval_qaq, Setting: Non-Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 16\n",
      "% Skipped queries: 17.02%\n",
      "% Skipped queries: 17.02\n",
      "\n",
      "Model: llama_70B_auto_eval_qaq, Setting: Underspecified\n",
      "Total queries: 93\n",
      "Skipped queries: 3\n",
      "% Skipped queries: 3.23%\n",
      "% Skipped queries: 3.23\n",
      "\n",
      "Warning: outputs/Original/llama_70B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_70B_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/llama_70B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_70B_auto_eval_qaq.\n",
      "\n",
      "--- Results for llama_70B_auto_eval_qaq ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                                   |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |\n",
      "+===========================================+=============+======================+======================+\n",
      "| Replaceable                               |        0.04 |                 0.04 |                 0.05 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable                           |        0.05 |                 0.21 |                 0.05 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified                            |        0.33 |                 0.25 |                 0.24 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original and No-tools) |        0.14 |                 0.17 |                 0.11 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 281\n",
      "Total skipped queries (excluding Original and No-tools): 24\n",
      "Overall % skipped queries (excluding Original and No-tools): 8.54%\n",
      "Overall float skipped queries (excluding Original and No-tools): 0.09\n",
      "\n",
      "Model: llama_405B_auto_eval_qaq, Setting: Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 2\n",
      "% Skipped queries: 2.15%\n",
      "% Skipped queries: 2.15\n",
      "\n",
      "Model: llama_405B_auto_eval_qaq, Setting: Non-Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 3\n",
      "% Skipped queries: 3.23%\n",
      "% Skipped queries: 3.23\n",
      "\n",
      "Model: llama_405B_auto_eval_qaq, Setting: Underspecified\n",
      "Total queries: 92\n",
      "Skipped queries: 1\n",
      "% Skipped queries: 1.09%\n",
      "% Skipped queries: 1.09\n",
      "\n",
      "Warning: outputs/Original/llama_405B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_405B_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/llama_405B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_405B_auto_eval_qaq.\n",
      "\n",
      "--- Results for llama_405B_auto_eval_qaq ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Setting                                   |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |\n",
      "+===========================================+=============+======================+======================+\n",
      "| Replaceable                               |        0.38 |                 0.01 |                 0.02 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Non-Replaceable                           |        0.16 |                 0.09 |                 0.15 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Underspecified                            |        0.53 |                 0.02 |                 0.53 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "| Overall (excluding Original and No-tools) |        0.36 |                 0.04 |                 0.23 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 278\n",
      "Total skipped queries (excluding Original and No-tools): 6\n",
      "Overall % skipped queries (excluding Original and No-tools): 2.16%\n",
      "Overall float skipped queries (excluding Original and No-tools): 0.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tabulate import tabulate\n",
    "\n",
    "def compute_scores(setting, model_name):\n",
    "    try:\n",
    "        file_path = f\"outputs/{setting}/{model_name}/answers.json\"\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {file_path} not found. Skipping this setting for {model_name}.\")\n",
    "        return None\n",
    "\n",
    "    total_queries = len(data)\n",
    "    skipped_queries = sum(1 for entry in data if entry.get(\"skipped\", False))  # Count queries marked as skipped\n",
    "    skipped_percentage = (skipped_queries / total_queries) * 100 if total_queries > 0 else 0\n",
    "\n",
    "    # Initialize counters for each component\n",
    "    ts_score = 0  # Task Success\n",
    "    aa_score = 0  # Awareness Accuracy\n",
    "    uo_score = 0  # Unexpected Success\n",
    "\n",
    "    for entry in data:\n",
    "        pass_rate = entry.get(\"pass_rate\", 0)\n",
    "        win_rate = entry.get(\"win_rate\", 0)\n",
    "        tool_annotation = entry.get(\"tool_annotation\", \"\").lower()\n",
    "        info_annotation = entry.get(\"info_annotation\", \"\").lower()\n",
    "\n",
    "        # Determine awareness based on setting\n",
    "        if setting in [\"Replaceable\", \"Non-Replaceable\"]:\n",
    "            awareness = tool_annotation\n",
    "        elif setting == \"Underspecified\":\n",
    "            awareness = info_annotation\n",
    "        elif setting == \"Original\":\n",
    "            awareness = tool_annotation if tool_annotation in [\"yes\", \"no\", \"idk\"] else info_annotation\n",
    "\n",
    "        # Initialize variables\n",
    "        ts = 0\n",
    "        aa = 0\n",
    "        uo = 0\n",
    "\n",
    "        if setting == \"No-tools\":\n",
    "            # Task Success\n",
    "            ts = 1 if win_rate >= 1 else 0\n",
    "            ts_score += ts\n",
    "\n",
    "            # Unexpected Outcome for no-tools: Win rate is 1 but in the original, pass rate is 0\n",
    "            original_file_path = f\"outputs/Original/{model_name}/answers.json\"\n",
    "            try:\n",
    "                with open(original_file_path, \"r\") as original_f:\n",
    "                    original_data = json.load(original_f)\n",
    "                    original_query = next((q for q in original_data if q[\"query_id\"] == entry[\"query_id\"]), None)\n",
    "                    if original_query and original_query.get(\"pass_rate\", 0) == 0 and win_rate == 1:\n",
    "                        uo = 1\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: {original_file_path} not found for checking unexpected outcomes.\")\n",
    "            uo_score += uo\n",
    "\n",
    "        else:\n",
    "            # Task Success (TS)\n",
    "            ts = 1 if pass_rate == 1 else 0\n",
    "            ts_score += ts\n",
    "\n",
    "            # Awareness Accuracy (AA)\n",
    "            if setting == \"Replaceable\":\n",
    "                if awareness in [\"idk\"]:\n",
    "                    aa = 1\n",
    "            elif setting in [\"Non-Replaceable\", \"Underspecified\"]:\n",
    "                if awareness in [\"no\", \"idk\"]:\n",
    "                    aa = 1\n",
    "            elif setting == \"Original\":\n",
    "                if awareness == \"yes\":\n",
    "                    aa = 1\n",
    "            aa_score += aa\n",
    "\n",
    "            # Unexpected Outcome (UO)\n",
    "            if setting in [\"Non-Replaceable\", \"Underspecified\"]:\n",
    "                if awareness == \"yes\" and pass_rate == 1:\n",
    "                    uo = 1\n",
    "            if setting == \"Replaceable\":\n",
    "                if awareness == \"no\":\n",
    "                    uo = 1\n",
    "            if setting == \"Original\":\n",
    "                if awareness == \"no\":\n",
    "                    uo = 1\n",
    "            uo_score += uo\n",
    "\n",
    "    # Compute average scores\n",
    "    if total_queries > 0:\n",
    "        ts_avg = ts_score / total_queries\n",
    "        uo_avg = uo_score / total_queries\n",
    "        if setting == \"No-tools\":\n",
    "            aa_avg = None  # Awareness Accuracy not applicable\n",
    "        else:\n",
    "            aa_avg = aa_score / total_queries\n",
    "    else:\n",
    "        ts_avg = aa_avg = uo_avg = 0\n",
    "\n",
    "    # Print skipped queries info\n",
    "    print(f\"Model: {model_name}, Setting: {setting}\")\n",
    "    print(f\"Total queries: {total_queries}\")\n",
    "    print(f\"Skipped queries: {skipped_queries}\")\n",
    "    print(f\"% Skipped queries: {skipped_percentage:.2f}%\")\n",
    "    print(f\"% Skipped queries: {skipped_percentage:.2f}\\n\")\n",
    "\n",
    "    return {\n",
    "        'Task Pass': ts_avg,\n",
    "        'Awareness Accuracy': aa_avg,\n",
    "        'Unexpected Outcome': uo_avg,\n",
    "        'Total Queries': total_queries,\n",
    "        'Skipped Queries': skipped_queries  # Return the number of skipped queries\n",
    "    }\n",
    "\n",
    "def compute_overall_score(model_name):\n",
    "    settings = [\"Replaceable\", \"Non-Replaceable\", \"Underspecified\", \"Original\", \"No-tools\"]\n",
    "\n",
    "    ts_scores = []\n",
    "    aa_scores = []\n",
    "    uo_scores = []\n",
    "    total_queries = 0\n",
    "    total_skipped_queries = 0  # Keep track of total skipped queries\n",
    "\n",
    "    table_data = []\n",
    "    headers = [\"Setting\", \"Task Pass\", \"Awareness Accuracy\", \"Unexpected Outcome\"]\n",
    "\n",
    "    for setting in settings:\n",
    "        scores = compute_scores(setting, model_name)\n",
    "        if scores is None:\n",
    "            continue  # Skip settings with no available data\n",
    "\n",
    "        # Exclude \"Original\" and \"No-tools\" from the overall skipped queries percentage calculation\n",
    "        if setting not in [\"Original\", \"No-tools\"]:\n",
    "            total_queries += scores['Total Queries']\n",
    "            total_skipped_queries += scores['Skipped Queries']  # Add skipped queries for each setting\n",
    "\n",
    "        # Prepare table data for this model\n",
    "        table_data.append([\n",
    "            setting,\n",
    "            f\"{scores['Task Pass']:.2f}\",\n",
    "            f\"{scores['Awareness Accuracy']:.2f}\" if scores['Awareness Accuracy'] is not None else \"N/A\",\n",
    "            f\"{scores['Unexpected Outcome']:.2f}\" if scores['Unexpected Outcome'] is not None else \"N/A\"\n",
    "        ])\n",
    "\n",
    "        # Collect scores for overall calculations, excluding \"Original\"\n",
    "        if setting != \"Original\" and \"No-tools\":\n",
    "            ts_scores.append(scores['Task Pass'])\n",
    "            if scores['Awareness Accuracy'] is not None:\n",
    "                aa_scores.append(scores['Awareness Accuracy'])\n",
    "            if scores['Unexpected Outcome'] is not None:\n",
    "                uo_scores.append(scores['Unexpected Outcome'])\n",
    "\n",
    "    # Compute overall averages (excluding \"Original\" and \"No-tools\")\n",
    "    ts_overall = sum(ts_scores) / len(ts_scores) if ts_scores else 0\n",
    "    aa_overall = sum(aa_scores) / len(aa_scores) if aa_scores else 0\n",
    "    uo_overall = sum(uo_scores) / len(uo_scores) if uo_scores else 0\n",
    "\n",
    "    # Weights\n",
    "    w_ts = 0.4  # Task Success\n",
    "    w_aa = 0.3  # Awareness Accuracy\n",
    "    w_us = 0.3  # Unexpected Success\n",
    "\n",
    "    # Compute overall score\n",
    "    overall_score = (w_ts * ts_overall) + (w_aa * aa_overall) + (w_us * uo_overall)\n",
    "\n",
    "    # Append overall scores at the bottom of the table\n",
    "    table_data.append([\n",
    "        \"Overall (excluding Original and No-tools)\",\n",
    "        f\"{ts_overall:.2f}\",\n",
    "        f\"{aa_overall:.2f}\" if aa_scores else \"N/A\",\n",
    "        f\"{uo_overall:.2f}\" if uo_scores else \"N/A\"\n",
    "    ])\n",
    "\n",
    "    # Print overall skipped queries percentage excluding \"Original\" and \"No-tools\"\n",
    "    overall_skipped_percentage = (total_skipped_queries / total_queries) * 100 if total_queries > 0 else 0\n",
    "    overall_skipped_float = total_skipped_queries / total_queries if total_queries > 0 else 0\n",
    "    print(f\"\\n--- Results for {model_name} ---\")\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "    print(f\"\\nTotal queries (excluding Original and No-tools): {total_queries}\")\n",
    "    print(f\"Total skipped queries (excluding Original and No-tools): {total_skipped_queries}\")\n",
    "    print(f\"Overall % skipped queries (excluding Original and No-tools): {overall_skipped_percentage:.2f}%\")\n",
    "    print(f\"Overall float skipped queries (excluding Original and No-tools): {overall_skipped_float:.2f}\\n\")\n",
    "\n",
    "\n",
    "# Collecting results for all models\n",
    "model_names = [\n",
    "    \"claude3.5_sonnet_auto_eval\",\n",
    "    \"gpt_4o_auto_eval\",\n",
    "    \"llama_70B_auto_eval\",\n",
    "    \"llama_405B_auto_eval\",\n",
    "    \"claude3.5_sonnet_auto_eval_qaq\",\n",
    "    \"gpt_4o_auto_eval_qaq\",\n",
    "    \"llama_70B_auto_eval_qaq\",\n",
    "    \"llama_405B_auto_eval_qaq\"\n",
    "]\n",
    "\n",
    "for model_name in model_names:\n",
    "    compute_overall_score(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: claude3.5_sonnet_auto_eval, Setting: Replaceable\n",
      "Total queries: 97\n",
      "Skipped queries: 1\n",
      "Skipped queries float (0-1 score): 0.01\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval, Setting: Non-Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 8\n",
      "Skipped queries float (0-1 score): 0.09\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval, Setting: Underspecified\n",
      "Total queries: 95\n",
      "Skipped queries: 8\n",
      "Skipped queries float (0-1 score): 0.08\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval, Setting: Original\n",
      "Total queries: 94\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval, Setting: No-tools\n",
      "Total queries: 99\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "\n",
      "\n",
      "--- Results for claude3.5_sonnet_auto_eval ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Setting                                   |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |   Skipped Float |\n",
      "+===========================================+=============+======================+======================+=================+\n",
      "| Replaceable                               |        0.41 | 0.54                 |                 0.01 |            0.01 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Non-Replaceable                           |        0.09 | 0.85                 |                 0.04 |            0.09 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Underspecified                            |        0.31 | 0.42                 |                 0.24 |            0.08 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Original                                  |        0.67 | 0.94                 |                 0    |            0    |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| No-tools                                  |        0.1  | N/A                  |                 0    |            0    |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Overall (excluding Original and No-tools) |        0.23 | 0.60                 |                 0.07 |            0.06 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 286\n",
      "Total skipped queries (excluding Original and No-tools): 17\n",
      "Overall skipped float (0-1 score, excluding Original and No-tools): 0.06\n",
      "\n",
      "Model: gpt_4o_auto_eval, Setting: Replaceable\n",
      "Total queries: 95\n",
      "Skipped queries: 1\n",
      "Skipped queries float (0-1 score): 0.01\n",
      "\n",
      "Model: gpt_4o_auto_eval, Setting: Non-Replaceable\n",
      "Total queries: 95\n",
      "Skipped queries: 6\n",
      "Skipped queries float (0-1 score): 0.06\n",
      "\n",
      "Model: gpt_4o_auto_eval, Setting: Underspecified\n",
      "Total queries: 96\n",
      "Skipped queries: 5\n",
      "Skipped queries float (0-1 score): 0.05\n",
      "\n",
      "Model: gpt_4o_auto_eval, Setting: Original\n",
      "Total queries: 97\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "\n",
      "Model: gpt_4o_auto_eval, Setting: No-tools\n",
      "Total queries: 99\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "\n",
      "\n",
      "--- Results for gpt_4o_auto_eval ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Setting                                   |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |   Skipped Float |\n",
      "+===========================================+=============+======================+======================+=================+\n",
      "| Replaceable                               |        0.44 | 0.03                 |                 0.01 |            0.01 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Non-Replaceable                           |        0.11 | 0.09                 |                 0.09 |            0.06 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Underspecified                            |        0.36 | 0.18                 |                 0.33 |            0.05 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Original                                  |        0.68 | 1.00                 |                 0    |            0    |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| No-tools                                  |        0.29 | N/A                  |                 0.01 |            0    |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Overall (excluding Original and No-tools) |        0.3  | 0.10                 |                 0.11 |            0.04 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 286\n",
      "Total skipped queries (excluding Original and No-tools): 12\n",
      "Overall skipped float (0-1 score, excluding Original and No-tools): 0.04\n",
      "\n",
      "Model: llama_70B_auto_eval, Setting: Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 18\n",
      "Skipped queries float (0-1 score): 0.19\n",
      "\n",
      "Model: llama_70B_auto_eval, Setting: Non-Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 35\n",
      "Skipped queries float (0-1 score): 0.38\n",
      "\n",
      "Model: llama_70B_auto_eval, Setting: Underspecified\n",
      "Total queries: 94\n",
      "Skipped queries: 10\n",
      "Skipped queries float (0-1 score): 0.11\n",
      "\n",
      "Model: llama_70B_auto_eval, Setting: Original\n",
      "Total queries: 93\n",
      "Skipped queries: 1\n",
      "Skipped queries float (0-1 score): 0.01\n",
      "\n",
      "Model: llama_70B_auto_eval, Setting: No-tools\n",
      "Total queries: 99\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "\n",
      "\n",
      "--- Results for llama_70B_auto_eval ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Setting                                   |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |   Skipped Float |\n",
      "+===========================================+=============+======================+======================+=================+\n",
      "| Replaceable                               |        0.1  | 0.17                 |                 0.19 |            0.19 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Non-Replaceable                           |        0.04 | 0.55                 |                 0.01 |            0.38 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Underspecified                            |        0.29 | 0.19                 |                 0.29 |            0.11 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Original                                  |        0.31 | 0.99                 |                 0.01 |            0.01 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| No-tools                                  |        0.37 | N/A                  |                 0.02 |            0    |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Overall (excluding Original and No-tools) |        0.2  | 0.30                 |                 0.13 |            0.23 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 280\n",
      "Total skipped queries (excluding Original and No-tools): 63\n",
      "Overall skipped float (0-1 score, excluding Original and No-tools): 0.23\n",
      "\n",
      "Model: llama_405B_auto_eval, Setting: Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 1\n",
      "Skipped queries float (0-1 score): 0.01\n",
      "\n",
      "Model: llama_405B_auto_eval, Setting: Non-Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 2\n",
      "Skipped queries float (0-1 score): 0.02\n",
      "\n",
      "Model: llama_405B_auto_eval, Setting: Underspecified\n",
      "Total queries: 95\n",
      "Skipped queries: 6\n",
      "Skipped queries float (0-1 score): 0.06\n",
      "\n",
      "Model: llama_405B_auto_eval, Setting: Original\n",
      "Total queries: 93\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "\n",
      "Model: llama_405B_auto_eval, Setting: No-tools\n",
      "Total queries: 99\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "\n",
      "\n",
      "--- Results for llama_405B_auto_eval ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Setting                                   |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |   Skipped Float |\n",
      "+===========================================+=============+======================+======================+=================+\n",
      "| Replaceable                               |        0.36 | 0.02                 |                 0.01 |            0.01 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Non-Replaceable                           |        0.12 | 0.02                 |                 0.12 |            0.02 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Underspecified                            |        0.25 | 0.11                 |                 0.25 |            0.06 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Original                                  |        0.53 | 1.00                 |                 0    |            0    |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| No-tools                                  |        0.28 | N/A                  |                 0.06 |            0    |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Overall (excluding Original and No-tools) |        0.25 | 0.05                 |                 0.11 |            0.03 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 283\n",
      "Total skipped queries (excluding Original and No-tools): 9\n",
      "Overall skipped float (0-1 score, excluding Original and No-tools): 0.03\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval_qaq, Setting: Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 3\n",
      "Skipped queries float (0-1 score): 0.03\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval_qaq, Setting: Non-Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 9\n",
      "Skipped queries float (0-1 score): 0.10\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval_qaq, Setting: Underspecified\n",
      "Total queries: 93\n",
      "Skipped queries: 3\n",
      "Skipped queries float (0-1 score): 0.03\n",
      "\n",
      "Warning: outputs/Original/claude3.5_sonnet_auto_eval_qaq/answers.json not found. Skipping this setting for claude3.5_sonnet_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/claude3.5_sonnet_auto_eval_qaq/answers.json not found. Skipping this setting for claude3.5_sonnet_auto_eval_qaq.\n",
      "\n",
      "--- Results for claude3.5_sonnet_auto_eval_qaq ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Setting                                   |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |   Skipped Float |\n",
      "+===========================================+=============+======================+======================+=================+\n",
      "| Replaceable                               |        0.43 |                 0.51 |                 0.03 |            0.03 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Non-Replaceable                           |        0.07 |                 0.85 |                 0.03 |            0.1  |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Underspecified                            |        0.61 |                 0.51 |                 0.31 |            0.03 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Overall (excluding Original and No-tools) |        0.37 |                 0.62 |                 0.13 |            0.05 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 281\n",
      "Total skipped queries (excluding Original and No-tools): 15\n",
      "Overall skipped float (0-1 score, excluding Original and No-tools): 0.05\n",
      "\n",
      "Model: gpt_4o_auto_eval_qaq, Setting: Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 2\n",
      "Skipped queries float (0-1 score): 0.02\n",
      "\n",
      "Model: gpt_4o_auto_eval_qaq, Setting: Non-Replaceable\n",
      "Total queries: 79\n",
      "Skipped queries: 2\n",
      "Skipped queries float (0-1 score): 0.03\n",
      "\n",
      "Model: gpt_4o_auto_eval_qaq, Setting: Underspecified\n",
      "Total queries: 94\n",
      "Skipped queries: 1\n",
      "Skipped queries float (0-1 score): 0.01\n",
      "\n",
      "Warning: outputs/Original/gpt_4o_auto_eval_qaq/answers.json not found. Skipping this setting for gpt_4o_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/gpt_4o_auto_eval_qaq/answers.json not found. Skipping this setting for gpt_4o_auto_eval_qaq.\n",
      "\n",
      "--- Results for gpt_4o_auto_eval_qaq ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Setting                                   |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |   Skipped Float |\n",
      "+===========================================+=============+======================+======================+=================+\n",
      "| Replaceable                               |        0.45 |                 0.02 |                 0.02 |            0.02 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Non-Replaceable                           |        0.1  |                 0.05 |                 0.1  |            0.03 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Underspecified                            |        0.61 |                 0.21 |                 0.47 |            0.01 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Overall (excluding Original and No-tools) |        0.39 |                 0.09 |                 0.2  |            0.02 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 266\n",
      "Total skipped queries (excluding Original and No-tools): 5\n",
      "Overall skipped float (0-1 score, excluding Original and No-tools): 0.02\n",
      "\n",
      "Model: llama_70B_auto_eval_qaq, Setting: Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 5\n",
      "Skipped queries float (0-1 score): 0.05\n",
      "\n",
      "Model: llama_70B_auto_eval_qaq, Setting: Non-Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 16\n",
      "Skipped queries float (0-1 score): 0.17\n",
      "\n",
      "Model: llama_70B_auto_eval_qaq, Setting: Underspecified\n",
      "Total queries: 93\n",
      "Skipped queries: 3\n",
      "Skipped queries float (0-1 score): 0.03\n",
      "\n",
      "Warning: outputs/Original/llama_70B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_70B_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/llama_70B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_70B_auto_eval_qaq.\n",
      "\n",
      "--- Results for llama_70B_auto_eval_qaq ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Setting                                   |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |   Skipped Float |\n",
      "+===========================================+=============+======================+======================+=================+\n",
      "| Replaceable                               |        0.04 |                 0.04 |                 0.05 |            0.05 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Non-Replaceable                           |        0.05 |                 0.21 |                 0.05 |            0.17 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Underspecified                            |        0.33 |                 0.25 |                 0.24 |            0.03 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Overall (excluding Original and No-tools) |        0.14 |                 0.17 |                 0.11 |            0.09 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 281\n",
      "Total skipped queries (excluding Original and No-tools): 24\n",
      "Overall skipped float (0-1 score, excluding Original and No-tools): 0.09\n",
      "\n",
      "Model: llama_405B_auto_eval_qaq, Setting: Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 2\n",
      "Skipped queries float (0-1 score): 0.02\n",
      "\n",
      "Model: llama_405B_auto_eval_qaq, Setting: Non-Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 3\n",
      "Skipped queries float (0-1 score): 0.03\n",
      "\n",
      "Model: llama_405B_auto_eval_qaq, Setting: Underspecified\n",
      "Total queries: 92\n",
      "Skipped queries: 1\n",
      "Skipped queries float (0-1 score): 0.01\n",
      "\n",
      "Warning: outputs/Original/llama_405B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_405B_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/llama_405B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_405B_auto_eval_qaq.\n",
      "\n",
      "--- Results for llama_405B_auto_eval_qaq ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Setting                                   |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |   Skipped Float |\n",
      "+===========================================+=============+======================+======================+=================+\n",
      "| Replaceable                               |        0.38 |                 0.01 |                 0.02 |            0.02 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Non-Replaceable                           |        0.16 |                 0.09 |                 0.15 |            0.03 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Underspecified                            |        0.53 |                 0.02 |                 0.53 |            0.01 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "| Overall (excluding Original and No-tools) |        0.36 |                 0.04 |                 0.23 |            0.02 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 278\n",
      "Total skipped queries (excluding Original and No-tools): 6\n",
      "Overall skipped float (0-1 score, excluding Original and No-tools): 0.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tabulate import tabulate\n",
    "\n",
    "def compute_scores(setting, model_name):\n",
    "    try:\n",
    "        file_path = f\"outputs/{setting}/{model_name}/answers.json\"\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {file_path} not found. Skipping this setting for {model_name}.\")\n",
    "        return None\n",
    "\n",
    "    total_queries = len(data)\n",
    "    skipped_queries = sum(1 for entry in data if entry.get(\"skipped\", False))  # Count queries marked as skipped\n",
    "    skipped_float = skipped_queries / total_queries if total_queries > 0 else 0  # Skipped float (0-1 score)\n",
    "\n",
    "    # Initialize counters for each component\n",
    "    ts_score = 0  # Task Success\n",
    "    aa_score = 0  # Awareness Accuracy\n",
    "    uo_score = 0  # Unexpected Success\n",
    "\n",
    "    for entry in data:\n",
    "        pass_rate = entry.get(\"pass_rate\", 0)\n",
    "        win_rate = entry.get(\"win_rate\", 0)\n",
    "        tool_annotation = entry.get(\"tool_annotation\", \"\").lower()\n",
    "        info_annotation = entry.get(\"info_annotation\", \"\").lower()\n",
    "\n",
    "        # Determine awareness based on setting\n",
    "        if setting in [\"Replaceable\", \"Non-Replaceable\"]:\n",
    "            awareness = tool_annotation\n",
    "        elif setting == \"Underspecified\":\n",
    "            awareness = info_annotation\n",
    "        elif setting == \"Original\":\n",
    "            awareness = tool_annotation if tool_annotation in [\"yes\", \"no\", \"idk\"] else info_annotation\n",
    "\n",
    "        # Initialize variables\n",
    "        ts = 0\n",
    "        aa = 0\n",
    "        uo = 0\n",
    "\n",
    "        if setting == \"No-tools\":\n",
    "            # Task Success\n",
    "            ts = 1 if win_rate >= 1 else 0\n",
    "            ts_score += ts\n",
    "\n",
    "            # Unexpected Outcome for no-tools: Win rate is 1 but in the original, pass rate is 0\n",
    "            original_file_path = f\"outputs/Original/{model_name}/answers.json\"\n",
    "            try:\n",
    "                with open(original_file_path, \"r\") as original_f:\n",
    "                    original_data = json.load(original_f)\n",
    "                    original_query = next((q for q in original_data if q[\"query_id\"] == entry[\"query_id\"]), None)\n",
    "                    if original_query and original_query.get(\"pass_rate\", 0) == 0 and win_rate == 1:\n",
    "                        uo = 1\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: {original_file_path} not found for checking unexpected outcomes.\")\n",
    "            uo_score += uo\n",
    "\n",
    "        else:\n",
    "            # Task Success (TS)\n",
    "            ts = 1 if pass_rate == 1 else 0\n",
    "            ts_score += ts\n",
    "\n",
    "            # Awareness Accuracy (AA)\n",
    "            if setting == \"Replaceable\":\n",
    "                if awareness in [\"idk\"]:\n",
    "                    aa = 1\n",
    "            elif setting in [\"Non-Replaceable\", \"Underspecified\"]:\n",
    "                if awareness in [\"no\", \"idk\"]:\n",
    "                    aa = 1\n",
    "            elif setting == \"Original\":\n",
    "                if awareness == \"yes\":\n",
    "                    aa = 1\n",
    "            aa_score += aa\n",
    "\n",
    "            # Unexpected Outcome (UO)\n",
    "            if setting in [\"Non-Replaceable\", \"Underspecified\"]:\n",
    "                if awareness == \"yes\" and pass_rate == 1:\n",
    "                    uo = 1\n",
    "            if setting == \"Replaceable\":\n",
    "                if awareness == \"no\":\n",
    "                    uo = 1\n",
    "            if setting == \"Original\":\n",
    "                if awareness == \"no\":\n",
    "                    uo = 1\n",
    "            uo_score += uo\n",
    "\n",
    "    # Compute average scores\n",
    "    if total_queries > 0:\n",
    "        ts_avg = ts_score / total_queries\n",
    "        uo_avg = uo_score / total_queries\n",
    "        if setting == \"No-tools\":\n",
    "            aa_avg = None  # Awareness Accuracy not applicable\n",
    "        else:\n",
    "            aa_avg = aa_score / total_queries\n",
    "    else:\n",
    "        ts_avg = aa_avg = uo_avg = 0\n",
    "\n",
    "    # Print skipped queries info\n",
    "    print(f\"Model: {model_name}, Setting: {setting}\")\n",
    "    print(f\"Total queries: {total_queries}\")\n",
    "    print(f\"Skipped queries: {skipped_queries}\")\n",
    "    print(f\"Skipped queries float (0-1 score): {skipped_float:.2f}\\n\")\n",
    "\n",
    "    return {\n",
    "        'Task Pass': ts_avg,\n",
    "        'Awareness Accuracy': aa_avg,\n",
    "        'Unexpected Outcome': uo_avg,\n",
    "        'Skipped Float': skipped_float,\n",
    "        'Total Queries': total_queries,\n",
    "        'Skipped Queries': skipped_queries  # Return the number of skipped queries\n",
    "    }\n",
    "\n",
    "def compute_overall_score(model_name):\n",
    "    settings = [\"Replaceable\", \"Non-Replaceable\", \"Underspecified\", \"Original\", \"No-tools\"]\n",
    "\n",
    "    ts_scores = []\n",
    "    aa_scores = []\n",
    "    uo_scores = []\n",
    "    skipped_floats = []  # Store skipped float scores for overall calculation\n",
    "    total_queries = 0\n",
    "    total_skipped_queries = 0  # Keep track of total skipped queries\n",
    "\n",
    "    table_data = []\n",
    "    headers = [\"Setting\", \"Task Pass\", \"Awareness Accuracy\", \"Unexpected Outcome\", \"Skipped Float\"]\n",
    "\n",
    "    for setting in settings:\n",
    "        scores = compute_scores(setting, model_name)\n",
    "        if scores is None:\n",
    "            continue  # Skip settings with no available data\n",
    "\n",
    "        # Exclude \"Original\" and \"No-tools\" from the overall skipped queries percentage calculation\n",
    "        if setting not in [\"Original\", \"No-tools\"]:\n",
    "            total_queries += scores['Total Queries']\n",
    "            total_skipped_queries += scores['Skipped Queries']\n",
    "            skipped_floats.append(scores['Skipped Float'])\n",
    "\n",
    "        # Prepare table data for this model\n",
    "        table_data.append([\n",
    "            setting,\n",
    "            f\"{scores['Task Pass']:.2f}\",\n",
    "            f\"{scores['Awareness Accuracy']:.2f}\" if scores['Awareness Accuracy'] is not None else \"N/A\",\n",
    "            f\"{scores['Unexpected Outcome']:.2f}\" if scores['Unexpected Outcome'] is not None else \"N/A\",\n",
    "            f\"{scores['Skipped Float']:.2f}\"\n",
    "        ])\n",
    "\n",
    "        # Collect scores for overall calculations, excluding \"Original\" and \"No-tools\"\n",
    "        if setting != \"Original\" and \"No-tools\":\n",
    "            ts_scores.append(scores['Task Pass'])\n",
    "            if scores['Awareness Accuracy'] is not None:\n",
    "                aa_scores.append(scores['Awareness Accuracy'])\n",
    "            if scores['Unexpected Outcome'] is not None:\n",
    "                uo_scores.append(scores['Unexpected Outcome'])\n",
    "\n",
    "    # Compute overall averages (excluding \"Original\" and \"No-tools\")\n",
    "    ts_overall = sum(ts_scores) / len(ts_scores) if ts_scores else 0\n",
    "    aa_overall = sum(aa_scores) / len(aa_scores) if aa_scores else 0\n",
    "    uo_overall = sum(uo_scores) / len(uo_scores) if uo_scores else 0\n",
    "    skipped_overall = sum(skipped_floats) / len(skipped_floats) if skipped_floats else 0\n",
    "\n",
    "    # Append overall scores at the bottom of the table\n",
    "    table_data.append([\n",
    "        \"Overall (excluding Original and No-tools)\",\n",
    "        f\"{ts_overall:.2f}\",\n",
    "        f\"{aa_overall:.2f}\" if aa_scores else \"N/A\",\n",
    "        f\"{uo_overall:.2f}\" if uo_scores else \"N/A\",\n",
    "        f\"{skipped_overall:.2f}\"\n",
    "    ])\n",
    "\n",
    "    # Print overall results excluding \"Original\" and \"No-tools\"\n",
    "    print(f\"\\n--- Results for {model_name} ---\")\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "    print(f\"\\nTotal queries (excluding Original and No-tools): {total_queries}\")\n",
    "    print(f\"Total skipped queries (excluding Original and No-tools): {total_skipped_queries}\")\n",
    "    print(f\"Overall skipped float (0-1 score, excluding Original and No-tools): {skipped_overall:.2f}\\n\")\n",
    "\n",
    "\n",
    "# Collecting results for all models\n",
    "model_names = [\n",
    "    \"claude3.5_sonnet_auto_eval\",\n",
    "    \"gpt_4o_auto_eval\",\n",
    "    \"llama_70B_auto_eval\",\n",
    "    \"llama_405B_auto_eval\",\n",
    "    \"claude3.5_sonnet_auto_eval_qaq\",\n",
    "    \"gpt_4o_auto_eval_qaq\",\n",
    "    \"llama_70B_auto_eval_qaq\",\n",
    "    \"llama_405B_auto_eval_qaq\"\n",
    "]\n",
    "\n",
    "for model_name in model_names:\n",
    "    compute_overall_score(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: claude3.5_sonnet_auto_eval, Setting: Replaceable\n",
      "Total queries: 97\n",
      "Skipped queries: 1\n",
      "Skipped queries float (0-1 score): 0.01\n",
      "Model: claude3.5_sonnet_auto_eval, Setting: Non-Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 8\n",
      "Skipped queries float (0-1 score): 0.09\n",
      "Model: claude3.5_sonnet_auto_eval, Setting: Underspecified\n",
      "Total queries: 95\n",
      "Skipped queries: 8\n",
      "Skipped queries float (0-1 score): 0.08\n",
      "Model: claude3.5_sonnet_auto_eval, Setting: Original\n",
      "Total queries: 94\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "Model: claude3.5_sonnet_auto_eval, Setting: No-tools\n",
      "Total queries: 99\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "\n",
      "--- Results for claude3.5_sonnet_auto_eval ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Setting                                   |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |   Skipped Float | Interaction Ratio   |\n",
      "+===========================================+=============+======================+======================+=================+=====================+\n",
      "| Replaceable                               |        0.41 | 0.54                 |                 0.01 |            0.01 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Non-Replaceable                           |        0.09 | 0.85                 |                 0.04 |            0.09 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Underspecified                            |        0.31 | 0.42                 |                 0.24 |            0.08 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Original                                  |        0.67 | 0.94                 |                 0    |            0    | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| No-tools                                  |        0.1  | N/A                  |                 0    |            0    | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Overall (excluding Original and No-tools) |        0.23 | 0.60                 |                 0.07 |            0.06 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 286\n",
      "Total skipped queries (excluding Original and No-tools): 17\n",
      "Overall skipped float (0-1 score, excluding Original and No-tools): 0.06\n",
      "Model: gpt_4o_auto_eval, Setting: Replaceable\n",
      "Total queries: 95\n",
      "Skipped queries: 1\n",
      "Skipped queries float (0-1 score): 0.01\n",
      "Model: gpt_4o_auto_eval, Setting: Non-Replaceable\n",
      "Total queries: 95\n",
      "Skipped queries: 6\n",
      "Skipped queries float (0-1 score): 0.06\n",
      "Model: gpt_4o_auto_eval, Setting: Underspecified\n",
      "Total queries: 96\n",
      "Skipped queries: 5\n",
      "Skipped queries float (0-1 score): 0.05\n",
      "Model: gpt_4o_auto_eval, Setting: Original\n",
      "Total queries: 97\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "Model: gpt_4o_auto_eval, Setting: No-tools\n",
      "Total queries: 99\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "\n",
      "--- Results for gpt_4o_auto_eval ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Setting                                   |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |   Skipped Float | Interaction Ratio   |\n",
      "+===========================================+=============+======================+======================+=================+=====================+\n",
      "| Replaceable                               |        0.44 | 0.03                 |                 0.01 |            0.01 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Non-Replaceable                           |        0.11 | 0.09                 |                 0.09 |            0.06 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Underspecified                            |        0.36 | 0.18                 |                 0.33 |            0.05 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Original                                  |        0.68 | 1.00                 |                 0    |            0    | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| No-tools                                  |        0.29 | N/A                  |                 0.01 |            0    | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Overall (excluding Original and No-tools) |        0.3  | 0.10                 |                 0.11 |            0.04 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 286\n",
      "Total skipped queries (excluding Original and No-tools): 12\n",
      "Overall skipped float (0-1 score, excluding Original and No-tools): 0.04\n",
      "Model: llama_70B_auto_eval, Setting: Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 18\n",
      "Skipped queries float (0-1 score): 0.19\n",
      "Model: llama_70B_auto_eval, Setting: Non-Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 35\n",
      "Skipped queries float (0-1 score): 0.38\n",
      "Model: llama_70B_auto_eval, Setting: Underspecified\n",
      "Total queries: 94\n",
      "Skipped queries: 10\n",
      "Skipped queries float (0-1 score): 0.11\n",
      "Model: llama_70B_auto_eval, Setting: Original\n",
      "Total queries: 93\n",
      "Skipped queries: 1\n",
      "Skipped queries float (0-1 score): 0.01\n",
      "Model: llama_70B_auto_eval, Setting: No-tools\n",
      "Total queries: 99\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "\n",
      "--- Results for llama_70B_auto_eval ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Setting                                   |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |   Skipped Float | Interaction Ratio   |\n",
      "+===========================================+=============+======================+======================+=================+=====================+\n",
      "| Replaceable                               |        0.1  | 0.17                 |                 0.19 |            0.19 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Non-Replaceable                           |        0.04 | 0.55                 |                 0.01 |            0.38 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Underspecified                            |        0.29 | 0.19                 |                 0.29 |            0.11 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Original                                  |        0.31 | 0.99                 |                 0.01 |            0.01 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| No-tools                                  |        0.37 | N/A                  |                 0.02 |            0    | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Overall (excluding Original and No-tools) |        0.2  | 0.30                 |                 0.13 |            0.23 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 280\n",
      "Total skipped queries (excluding Original and No-tools): 63\n",
      "Overall skipped float (0-1 score, excluding Original and No-tools): 0.23\n",
      "Model: llama_405B_auto_eval, Setting: Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 1\n",
      "Skipped queries float (0-1 score): 0.01\n",
      "Model: llama_405B_auto_eval, Setting: Non-Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 2\n",
      "Skipped queries float (0-1 score): 0.02\n",
      "Model: llama_405B_auto_eval, Setting: Underspecified\n",
      "Total queries: 95\n",
      "Skipped queries: 6\n",
      "Skipped queries float (0-1 score): 0.06\n",
      "Model: llama_405B_auto_eval, Setting: Original\n",
      "Total queries: 93\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "Model: llama_405B_auto_eval, Setting: No-tools\n",
      "Total queries: 99\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "\n",
      "--- Results for llama_405B_auto_eval ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Setting                                   |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |   Skipped Float | Interaction Ratio   |\n",
      "+===========================================+=============+======================+======================+=================+=====================+\n",
      "| Replaceable                               |        0.36 | 0.02                 |                 0.01 |            0.01 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Non-Replaceable                           |        0.12 | 0.02                 |                 0.12 |            0.02 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Underspecified                            |        0.25 | 0.11                 |                 0.25 |            0.06 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Original                                  |        0.53 | 1.00                 |                 0    |            0    | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| No-tools                                  |        0.28 | N/A                  |                 0.06 |            0    | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Overall (excluding Original and No-tools) |        0.25 | 0.05                 |                 0.11 |            0.03 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 283\n",
      "Total skipped queries (excluding Original and No-tools): 9\n",
      "Overall skipped float (0-1 score, excluding Original and No-tools): 0.03\n",
      "Model: llama_8B_auto_eval, Setting: Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 1\n",
      "Skipped queries float (0-1 score): 0.01\n",
      "Model: llama_8B_auto_eval, Setting: Non-Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "Model: llama_8B_auto_eval, Setting: Underspecified\n",
      "Total queries: 92\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "Model: llama_8B_auto_eval, Setting: Original\n",
      "Total queries: 92\n",
      "Skipped queries: 1\n",
      "Skipped queries float (0-1 score): 0.01\n",
      "Model: llama_8B_auto_eval, Setting: No-tools\n",
      "Total queries: 100\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "\n",
      "--- Results for llama_8B_auto_eval ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Setting                                   |   Task Pass | Awareness Accuracy   |   Unexpected Outcome |   Skipped Float | Interaction Ratio   |\n",
      "+===========================================+=============+======================+======================+=================+=====================+\n",
      "| Replaceable                               |        0.19 | 0.01                 |                 0.01 |            0.01 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Non-Replaceable                           |        0.03 | 0.02                 |                 0.03 |            0    | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Underspecified                            |        0.14 | 0.02                 |                 0.13 |            0    | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Original                                  |        0.28 | 1.00                 |                 0    |            0.01 | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| No-tools                                  |        0    | N/A                  |                 0    |            0    | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Overall (excluding Original and No-tools) |        0.09 | 0.02                 |                 0.04 |            0    | N/A                 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 279\n",
      "Total skipped queries (excluding Original and No-tools): 1\n",
      "Overall skipped float (0-1 score, excluding Original and No-tools): 0.00\n",
      "Model: claude3.5_sonnet_auto_eval_qaq, Setting: Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 3\n",
      "Skipped queries float (0-1 score): 0.03\n",
      "Interaction ratio (interactions/queries not skipped): 0.19\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval_qaq, Setting: Non-Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 9\n",
      "Skipped queries float (0-1 score): 0.10\n",
      "Interaction ratio (interactions/queries not skipped): 0.27\n",
      "\n",
      "Model: claude3.5_sonnet_auto_eval_qaq, Setting: Underspecified\n",
      "Total queries: 93\n",
      "Skipped queries: 3\n",
      "Skipped queries float (0-1 score): 0.03\n",
      "Interaction ratio (interactions/queries not skipped): 0.61\n",
      "\n",
      "Warning: outputs/Original/claude3.5_sonnet_auto_eval_qaq/answers.json not found. Skipping this setting for claude3.5_sonnet_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/claude3.5_sonnet_auto_eval_qaq/answers.json not found. Skipping this setting for claude3.5_sonnet_auto_eval_qaq.\n",
      "\n",
      "--- Results for claude3.5_sonnet_auto_eval_qaq ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Setting                                   |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |   Skipped Float |   Interaction Ratio |\n",
      "+===========================================+=============+======================+======================+=================+=====================+\n",
      "| Replaceable                               |        0.43 |                 0.51 |                 0.03 |            0.03 |                0.19 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Non-Replaceable                           |        0.07 |                 0.85 |                 0.03 |            0.1  |                0.27 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Underspecified                            |        0.61 |                 0.51 |                 0.31 |            0.03 |                0.61 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Overall (excluding Original and No-tools) |        0.37 |                 0.62 |                 0.13 |            0.05 |                0.36 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 281\n",
      "Total skipped queries (excluding Original and No-tools): 15\n",
      "Overall skipped float (0-1 score, excluding Original and No-tools): 0.05\n",
      "Overall interaction ratio (excluding Original and No-tools): 0.36\n",
      "\n",
      "Model: gpt_4o_auto_eval_qaq, Setting: Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 2\n",
      "Skipped queries float (0-1 score): 0.02\n",
      "Interaction ratio (interactions/queries not skipped): 0.15\n",
      "\n",
      "Model: gpt_4o_auto_eval_qaq, Setting: Non-Replaceable\n",
      "Total queries: 79\n",
      "Skipped queries: 2\n",
      "Skipped queries float (0-1 score): 0.03\n",
      "Interaction ratio (interactions/queries not skipped): 0.09\n",
      "\n",
      "Model: gpt_4o_auto_eval_qaq, Setting: Underspecified\n",
      "Total queries: 94\n",
      "Skipped queries: 1\n",
      "Skipped queries float (0-1 score): 0.01\n",
      "Interaction ratio (interactions/queries not skipped): 0.58\n",
      "\n",
      "Warning: outputs/Original/gpt_4o_auto_eval_qaq/answers.json not found. Skipping this setting for gpt_4o_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/gpt_4o_auto_eval_qaq/answers.json not found. Skipping this setting for gpt_4o_auto_eval_qaq.\n",
      "\n",
      "--- Results for gpt_4o_auto_eval_qaq ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Setting                                   |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |   Skipped Float |   Interaction Ratio |\n",
      "+===========================================+=============+======================+======================+=================+=====================+\n",
      "| Replaceable                               |        0.45 |                 0.02 |                 0.02 |            0.02 |                0.15 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Non-Replaceable                           |        0.1  |                 0.05 |                 0.1  |            0.03 |                0.09 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Underspecified                            |        0.61 |                 0.21 |                 0.47 |            0.01 |                0.58 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Overall (excluding Original and No-tools) |        0.39 |                 0.09 |                 0.2  |            0.02 |                0.28 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 266\n",
      "Total skipped queries (excluding Original and No-tools): 5\n",
      "Overall skipped float (0-1 score, excluding Original and No-tools): 0.02\n",
      "Overall interaction ratio (excluding Original and No-tools): 0.28\n",
      "\n",
      "Model: llama_70B_auto_eval_qaq, Setting: Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 5\n",
      "Skipped queries float (0-1 score): 0.05\n",
      "Interaction ratio (interactions/queries not skipped): 0.24\n",
      "\n",
      "Model: llama_70B_auto_eval_qaq, Setting: Non-Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 16\n",
      "Skipped queries float (0-1 score): 0.17\n",
      "Interaction ratio (interactions/queries not skipped): 0.18\n",
      "\n",
      "Model: llama_70B_auto_eval_qaq, Setting: Underspecified\n",
      "Total queries: 93\n",
      "Skipped queries: 3\n",
      "Skipped queries float (0-1 score): 0.03\n",
      "Interaction ratio (interactions/queries not skipped): 0.21\n",
      "\n",
      "Warning: outputs/Original/llama_70B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_70B_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/llama_70B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_70B_auto_eval_qaq.\n",
      "\n",
      "--- Results for llama_70B_auto_eval_qaq ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Setting                                   |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |   Skipped Float |   Interaction Ratio |\n",
      "+===========================================+=============+======================+======================+=================+=====================+\n",
      "| Replaceable                               |        0.04 |                 0.04 |                 0.05 |            0.05 |                0.24 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Non-Replaceable                           |        0.05 |                 0.21 |                 0.05 |            0.17 |                0.18 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Underspecified                            |        0.33 |                 0.25 |                 0.24 |            0.03 |                0.21 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Overall (excluding Original and No-tools) |        0.14 |                 0.17 |                 0.11 |            0.09 |                0.21 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 281\n",
      "Total skipped queries (excluding Original and No-tools): 24\n",
      "Overall skipped float (0-1 score, excluding Original and No-tools): 0.09\n",
      "Overall interaction ratio (excluding Original and No-tools): 0.21\n",
      "\n",
      "Model: llama_405B_auto_eval_qaq, Setting: Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 2\n",
      "Skipped queries float (0-1 score): 0.02\n",
      "Interaction ratio (interactions/queries not skipped): 0.24\n",
      "\n",
      "Model: llama_405B_auto_eval_qaq, Setting: Non-Replaceable\n",
      "Total queries: 93\n",
      "Skipped queries: 3\n",
      "Skipped queries float (0-1 score): 0.03\n",
      "Interaction ratio (interactions/queries not skipped): 0.16\n",
      "\n",
      "Model: llama_405B_auto_eval_qaq, Setting: Underspecified\n",
      "Total queries: 92\n",
      "Skipped queries: 1\n",
      "Skipped queries float (0-1 score): 0.01\n",
      "Interaction ratio (interactions/queries not skipped): 0.25\n",
      "\n",
      "Warning: outputs/Original/llama_405B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_405B_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/llama_405B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_405B_auto_eval_qaq.\n",
      "\n",
      "--- Results for llama_405B_auto_eval_qaq ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Setting                                   |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |   Skipped Float |   Interaction Ratio |\n",
      "+===========================================+=============+======================+======================+=================+=====================+\n",
      "| Replaceable                               |        0.38 |                 0.01 |                 0.02 |            0.02 |                0.24 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Non-Replaceable                           |        0.16 |                 0.09 |                 0.15 |            0.03 |                0.16 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Underspecified                            |        0.53 |                 0.02 |                 0.53 |            0.01 |                0.25 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Overall (excluding Original and No-tools) |        0.36 |                 0.04 |                 0.23 |            0.02 |                0.22 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 278\n",
      "Total skipped queries (excluding Original and No-tools): 6\n",
      "Overall skipped float (0-1 score, excluding Original and No-tools): 0.02\n",
      "Overall interaction ratio (excluding Original and No-tools): 0.22\n",
      "\n",
      "Model: llama_8B_auto_eval_qaq, Setting: Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "Interaction ratio (interactions/queries not skipped): 0.19\n",
      "\n",
      "Model: llama_8B_auto_eval_qaq, Setting: Non-Replaceable\n",
      "Total queries: 94\n",
      "Skipped queries: 1\n",
      "Skipped queries float (0-1 score): 0.01\n",
      "Interaction ratio (interactions/queries not skipped): 0.26\n",
      "\n",
      "Model: llama_8B_auto_eval_qaq, Setting: Underspecified\n",
      "Total queries: 94\n",
      "Skipped queries: 0\n",
      "Skipped queries float (0-1 score): 0.00\n",
      "Interaction ratio (interactions/queries not skipped): 0.24\n",
      "\n",
      "Warning: outputs/Original/llama_8B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_8B_auto_eval_qaq.\n",
      "Warning: outputs/No-tools/llama_8B_auto_eval_qaq/answers.json not found. Skipping this setting for llama_8B_auto_eval_qaq.\n",
      "\n",
      "--- Results for llama_8B_auto_eval_qaq ---\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Setting                                   |   Task Pass |   Awareness Accuracy |   Unexpected Outcome |   Skipped Float |   Interaction Ratio |\n",
      "+===========================================+=============+======================+======================+=================+=====================+\n",
      "| Replaceable                               |        0.13 |                 0.01 |                 0    |            0    |                0.19 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Non-Replaceable                           |        0.03 |                 0.03 |                 0.03 |            0.01 |                0.26 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Underspecified                            |        0.24 |                 0.01 |                 0.24 |            0    |                0.24 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "| Overall (excluding Original and No-tools) |        0.13 |                 0.02 |                 0.09 |            0    |                0.23 |\n",
      "+-------------------------------------------+-------------+----------------------+----------------------+-----------------+---------------------+\n",
      "\n",
      "Total queries (excluding Original and No-tools): 282\n",
      "Total skipped queries (excluding Original and No-tools): 1\n",
      "Overall skipped float (0-1 score, excluding Original and No-tools): 0.00\n",
      "Overall interaction ratio (excluding Original and No-tools): 0.23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tabulate import tabulate\n",
    "\n",
    "def compute_scores(setting, model_name):\n",
    "    try:\n",
    "        file_path = f\"outputs/{setting}/{model_name}/answers.json\"\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {file_path} not found. Skipping this setting for {model_name}.\")\n",
    "        return None\n",
    "\n",
    "    total_queries = len(data)\n",
    "    skipped_queries = sum(1 for entry in data if entry.get(\"skipped\", False))  # Count queries marked as skipped\n",
    "    non_skipped_queries = total_queries - skipped_queries  # Non-skipped queries\n",
    "    skipped_float = skipped_queries / total_queries if total_queries > 0 else 0  # Skipped float (0-1 score)\n",
    "\n",
    "    # Initialize counters for each component\n",
    "    ts_score = 0  # Task Success\n",
    "    aa_score = 0  # Awareness Accuracy\n",
    "    uo_score = 0  # Unexpected Success\n",
    "    interaction_count = 0  # Interaction count for models with _qaq\n",
    "\n",
    "    for entry in data:\n",
    "        # Count interactions for models with _qaq by checking \"interaction_scores\"\n",
    "        if model_name.endswith(\"_qaq\") and \"interaction_scores\" in entry:\n",
    "            interaction_count += 1\n",
    "\n",
    "        pass_rate = entry.get(\"pass_rate\", 0)\n",
    "        win_rate = entry.get(\"win_rate\", 0)\n",
    "        tool_annotation = entry.get(\"tool_annotation\", \"\").lower()\n",
    "        info_annotation = entry.get(\"info_annotation\", \"\").lower()\n",
    "\n",
    "        # Determine awareness based on setting\n",
    "        if setting in [\"Replaceable\", \"Non-Replaceable\"]:\n",
    "            awareness = tool_annotation\n",
    "        elif setting == \"Underspecified\":\n",
    "            awareness = info_annotation\n",
    "        elif setting == \"Original\":\n",
    "            awareness = tool_annotation if tool_annotation in [\"yes\", \"no\", \"idk\"] else info_annotation\n",
    "\n",
    "        # Initialize variables\n",
    "        ts = 0\n",
    "        aa = 0\n",
    "        uo = 0\n",
    "\n",
    "        if setting == \"No-tools\":\n",
    "            # Task Success\n",
    "            ts = 1 if win_rate >= 1 else 0\n",
    "            ts_score += ts\n",
    "\n",
    "            # Unexpected Outcome for no-tools: Win rate is 1 but in the original, pass rate is 0\n",
    "            original_file_path = f\"outputs/Original/{model_name}/answers.json\"\n",
    "            try:\n",
    "                with open(original_file_path, \"r\") as original_f:\n",
    "                    original_data = json.load(original_f)\n",
    "                    original_query = next((q for q in original_data if q[\"query_id\"] == entry[\"query_id\"]), None)\n",
    "                    if original_query and original_query.get(\"pass_rate\", 0) == 0 and win_rate == 1:\n",
    "                        uo = 1\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: {original_file_path} not found for checking unexpected outcomes.\")\n",
    "            uo_score += uo\n",
    "\n",
    "        else:\n",
    "            # Task Success (TS)\n",
    "            ts = 1 if pass_rate == 1 else 0\n",
    "            ts_score += ts\n",
    "\n",
    "            # Awareness Accuracy (AA)\n",
    "            if setting == \"Replaceable\":\n",
    "                if awareness in [\"idk\"]:\n",
    "                    aa = 1\n",
    "            elif setting in [\"Non-Replaceable\", \"Underspecified\"]:\n",
    "                if awareness in [\"no\", \"idk\"]:\n",
    "                    aa = 1\n",
    "            elif setting == \"Original\":\n",
    "                if awareness == \"yes\":\n",
    "                    aa = 1\n",
    "            aa_score += aa\n",
    "\n",
    "            # Unexpected Outcome (UO)\n",
    "            if setting in [\"Non-Replaceable\", \"Underspecified\"]:\n",
    "                if awareness == \"yes\" and pass_rate == 1:\n",
    "                    uo = 1\n",
    "            if setting == \"Replaceable\":\n",
    "                if awareness == \"no\":\n",
    "                    uo = 1\n",
    "            if setting == \"Original\":\n",
    "                if awareness == \"no\":\n",
    "                    uo = 1\n",
    "            uo_score += uo\n",
    "\n",
    "    # Compute average scores\n",
    "    if total_queries > 0:\n",
    "        ts_avg = ts_score / total_queries\n",
    "        uo_avg = uo_score / total_queries\n",
    "        if setting == \"No-tools\":\n",
    "            aa_avg = None  # Awareness Accuracy not applicable\n",
    "        else:\n",
    "            aa_avg = aa_score / total_queries\n",
    "    else:\n",
    "        ts_avg = aa_avg = uo_avg = 0\n",
    "\n",
    "    # Calculate interaction score as a proportion of non-skipped queries\n",
    "    interaction_ratio = interaction_count / non_skipped_queries if non_skipped_queries > 0 else 0\n",
    "\n",
    "    # Print skipped queries info\n",
    "    print(f\"Model: {model_name}, Setting: {setting}\")\n",
    "    print(f\"Total queries: {total_queries}\")\n",
    "    print(f\"Skipped queries: {skipped_queries}\")\n",
    "    print(f\"Skipped queries float (0-1 score): {skipped_float:.2f}\")\n",
    "    if model_name.endswith(\"_qaq\"):\n",
    "        print(f\"Interaction ratio (interactions/queries not skipped): {interaction_ratio:.2f}\\n\")\n",
    "\n",
    "    return {\n",
    "        'Task Pass': ts_avg,\n",
    "        'Awareness Accuracy': aa_avg,\n",
    "        'Unexpected Outcome': uo_avg,\n",
    "        'Skipped Float': skipped_float,\n",
    "        'Total Queries': total_queries,\n",
    "        'Skipped Queries': skipped_queries,  # Return the number of skipped queries\n",
    "        'Interaction Ratio': interaction_ratio  # Return the interaction ratio (0-1)\n",
    "    }\n",
    "\n",
    "def compute_overall_score(model_name):\n",
    "    settings = [\"Replaceable\", \"Non-Replaceable\", \"Underspecified\", \"Original\", \"No-tools\"]\n",
    "\n",
    "    ts_scores = []\n",
    "    aa_scores = []\n",
    "    uo_scores = []\n",
    "    skipped_floats = []  # Store skipped float scores for overall calculation\n",
    "    total_queries = 0\n",
    "    total_skipped_queries = 0  # Keep track of total skipped queries\n",
    "    interaction_ratios = []  # Track interaction ratios for _qaq models\n",
    "\n",
    "    table_data = []\n",
    "    headers = [\"Setting\", \"Task Pass\", \"Awareness Accuracy\", \"Unexpected Outcome\", \"Skipped Float\", \"Interaction Ratio\"]\n",
    "\n",
    "    for setting in settings:\n",
    "        scores = compute_scores(setting, model_name)\n",
    "        if scores is None:\n",
    "            continue  # Skip settings with no available data\n",
    "\n",
    "        # Exclude \"Original\" and \"No-tools\" from the overall skipped queries percentage calculation\n",
    "        if setting not in [\"Original\", \"No-tools\"]:\n",
    "            total_queries += scores['Total Queries']\n",
    "            total_skipped_queries += scores['Skipped Queries']\n",
    "            skipped_floats.append(scores['Skipped Float'])\n",
    "\n",
    "        # Prepare table data for this model\n",
    "        table_data.append([\n",
    "            setting,\n",
    "            f\"{scores['Task Pass']:.2f}\",\n",
    "            f\"{scores['Awareness Accuracy']:.2f}\" if scores['Awareness Accuracy'] is not None else \"N/A\",\n",
    "            f\"{scores['Unexpected Outcome']:.2f}\" if scores['Unexpected Outcome'] is not None else \"N/A\",\n",
    "            f\"{scores['Skipped Float']:.2f}\",\n",
    "            f\"{scores['Interaction Ratio']:.2f}\" if model_name.endswith(\"_qaq\") else \"N/A\"\n",
    "        ])\n",
    "\n",
    "        # Collect scores for overall calculations, excluding \"Original\" and \"No-tools\"\n",
    "        if setting != \"Original\" and \"No-tools\":\n",
    "            ts_scores.append(scores['Task Pass'])\n",
    "            if scores['Awareness Accuracy'] is not None:\n",
    "                aa_scores.append(scores['Awareness Accuracy'])\n",
    "            if scores['Unexpected Outcome'] is not None:\n",
    "                uo_scores.append(scores['Unexpected Outcome'])\n",
    "            if model_name.endswith(\"_qaq\"):\n",
    "                interaction_ratios.append(scores['Interaction Ratio'])\n",
    "\n",
    "    # Compute overall averages (excluding \"Original\" and \"No-tools\")\n",
    "    ts_overall = sum(ts_scores) / len(ts_scores) if ts_scores else 0\n",
    "    aa_overall = sum(aa_scores) / len(aa_scores) if aa_scores else 0\n",
    "    uo_overall = sum(uo_scores) / len(uo_scores) if uo_scores else 0\n",
    "    skipped_overall = sum(skipped_floats) / len(skipped_floats) if skipped_floats else 0\n",
    "    interaction_overall = sum(interaction_ratios) / len(interaction_ratios) if interaction_ratios else 0\n",
    "\n",
    "    # Append overall scores at the bottom of the table\n",
    "    table_data.append([\n",
    "        \"Overall (excluding Original and No-tools)\",\n",
    "        f\"{ts_overall:.2f}\",\n",
    "        f\"{aa_overall:.2f}\" if aa_scores else \"N/A\",\n",
    "        f\"{uo_overall:.2f}\" if uo_scores else \"N/A\",\n",
    "        f\"{skipped_overall:.2f}\",\n",
    "        f\"{interaction_overall:.2f}\" if model_name.endswith(\"_qaq\") else \"N/A\"\n",
    "    ])\n",
    "\n",
    "    # Print overall results excluding \"Original\" and \"No-tools\"\n",
    "    print(f\"\\n--- Results for {model_name} ---\")\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "    print(f\"\\nTotal queries (excluding Original and No-tools): {total_queries}\")\n",
    "    print(f\"Total skipped queries (excluding Original and No-tools): {total_skipped_queries}\")\n",
    "    print(f\"Overall skipped float (0-1 score, excluding Original and No-tools): {skipped_overall:.2f}\")\n",
    "    if model_name.endswith(\"_qaq\"):\n",
    "        print(f\"Overall interaction ratio (excluding Original and No-tools): {interaction_overall:.2f}\\n\")\n",
    "\n",
    "\n",
    "# Collecting results for all models\n",
    "model_names = [\n",
    "    \"claude3.5_sonnet_auto_eval\",\n",
    "    \"gpt_4o_auto_eval\",\n",
    "    \"llama_70B_auto_eval\",\n",
    "    \"llama_405B_auto_eval\",\n",
    "    \"llama_8B_auto_eval\",\n",
    "    \"claude3.5_sonnet_auto_eval_qaq\",\n",
    "    \"gpt_4o_auto_eval_qaq\",\n",
    "    \"llama_70B_auto_eval_qaq\",\n",
    "    \"llama_405B_auto_eval_qaq\",\n",
    "    \"llama_8B_auto_eval_qaq\"\n",
    "]\n",
    "\n",
    "for model_name in model_names:\n",
    "    compute_overall_score(model_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toolsforjob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
