{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from openai import OpenAI\n",
    "import regex as re\n",
    "\n",
    "# Load the API key from the openaikey.txt file\n",
    "with open(\"openaikey.txt\", \"r\") as file:\n",
    "    api_key = file.read().strip()\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "seed_api_question_example = '''\n",
    "api_list-question example\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"api_list\": [\n",
    "        {\n",
    "            \"category_name\": \"Art\",\n",
    "            \"tool_name\": \"metmuseum\",\n",
    "            \"api_name\": \"search_objects\",\n",
    "            \"api_description\": \"Search for objects in the Met's collection\",\n",
    "            \"required_parameters\": [\n",
    "                {\n",
    "                    \"name\": \"q\",\n",
    "                    \"type\": \"STRING\",\n",
    "                    \"description\": \"Search term\",\n",
    "                    \"default\": \"Impressionist paintings\"\n",
    "                }\n",
    "            ],\n",
    "            \"optional_parameters\": [\n",
    "                {\n",
    "                    \"name\": \"departmentId\",\n",
    "                    \"type\": \"INTEGER\",\n",
    "                    \"description\": \"ID of the department\",\n",
    "                    \"default\": \"11\"\n",
    "                }\n",
    "            ],\n",
    "            \"method\": \"GET\",\n",
    "            \"template_response\": {\n",
    "                \"total\": \"int\",\n",
    "                \"objectIDs\": [\"int\"]\n",
    "            }\n",
    "        },\n",
    "      {\n",
    "            \"category_name\": \"Art\",\n",
    "            \"tool_name\": \"artchicago\",\n",
    "            \"api_name\": \"artworks_search\",\n",
    "            \"api_description\": \"Search artworks in the Art Institute of Chicago data in the aggregator. Artworks in the groups of essentials are boosted so they'll show up higher in results.\",\n",
    "            \"required_parameters\": [\n",
    "                {\n",
    "                    \"name\": \"q\",\n",
    "                    \"type\": \"STRING\",\n",
    "                    \"description\": \"Your search query.\",\n",
    "                    \"default\": \"monet\"\n",
    "                }\n",
    "            ],\n",
    "            \"optional_parameters\": [\n",
    "                {\n",
    "                    \"name\": \"size\",\n",
    "                    \"type\": \"INTEGER\",\n",
    "                    \"description\": \"Number of results to return. Pagination via Elasticsearch conventions.\",\n",
    "                    \"default\": \"10\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"sort\",\n",
    "                    \"type\": \"STRING\",\n",
    "                    \"description\": \"Used in conjunction with query to sort results.\",\n",
    "                    \"default\": \"\"\n",
    "                }\n",
    "            ],\n",
    "            \"method\": \"GET\",\n",
    "            \"template_response\": {\n",
    "                \"pagination\": {\n",
    "                    \"total\": \"int\",\n",
    "                    \"limit\": \"int\",\n",
    "                    \"offset\": \"int\",\n",
    "                    \"total_pages\": \"int\",\n",
    "                    \"current_page\": \"int\"\n",
    "                },\n",
    "                \"data\": [\n",
    "                    {\n",
    "                        \"id\": \"int\",\n",
    "                        \"title\": \"str\",\n",
    "                        \"artist_display\": \"str\",\n",
    "                        \"place_of_origin\": \"str\",\n",
    "                        \"date_display\": \"str\",\n",
    "                        \"medium_display\": \"str\",\n",
    "                        \"dimensions\": \"str\",\n",
    "                        \"thumbnail\": {\n",
    "                            \"alt_text\": \"str\",\n",
    "                            \"width\": \"int\",\n",
    "                            \"height\": \"int\",\n",
    "                            \"iiif_url\": \"str\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"query\": \"I want to find Impressionist paintings in the European Paintings department in the Met's collection. Additionally, can you find artworks related to Monet in the Art Institute of Chicago?\",\n",
    "    \"relevant APIs\": [],\n",
    "    \"query_id\": 2\n",
    "  }\n",
    "]\n",
    "```\n",
    "'''\n",
    "\n",
    "def read_file_content(file_path):\n",
    "    \"\"\"Read and return the content of a file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except Exception as e:\n",
    "        return f\"Error reading {file_path}: {e}\"\n",
    "\n",
    "def generate_prompt(tool1, tool2, category_folder, category_path):\n",
    "    \"\"\"Generate the fstring prompt for two tools.\"\"\"\n",
    "    # Paths for Tool 1\n",
    "    tool1_json_path = os.path.join(category_path, f\"{tool1}.json\")\n",
    "    tool1_py_path = os.path.join(category_path, tool1, \"api.py\")\n",
    "    tool1_test_py_path = os.path.join(category_path, tool1, \"api_test.py\")\n",
    "\n",
    "    # Paths for Tool 2\n",
    "    tool2_json_path = os.path.join(category_path, f\"{tool2}.json\")\n",
    "    tool2_py_path = os.path.join(category_path, tool2, \"api.py\")\n",
    "    tool2_test_py_path = os.path.join(category_path, tool2, \"api_test.py\")\n",
    "\n",
    "    # Read the content of each file\n",
    "    tool1_json_content = read_file_content(tool1_json_path)\n",
    "    tool1_py_content = read_file_content(tool1_py_path)\n",
    "    tool1_test_py_content = read_file_content(tool1_test_py_path)\n",
    "\n",
    "    tool2_json_content = read_file_content(tool2_json_path)\n",
    "    tool2_py_content = read_file_content(tool2_py_path)\n",
    "    tool2_test_py_content = read_file_content(tool2_test_py_path)\n",
    "\n",
    "    # Generate the prompt\n",
    "    prompt = f'''\n",
    "Below I have attached 2 Tools \"{tool1}\", and \"{tool2}\" which are python files that make requests to endpoints, from the \"{category_folder}\" category, and their corresponding meta data json files which provides additional information about the tools, as well as unittests ran on these endpoints, as some endpoints use parameters, so you can use these for your task. \n",
    "Your task is to create a api_list-question json file which asks questions a human would ask which requires the use of at least 1 API from each tool. \n",
    "Note the questions should be independent of any other API's. \n",
    "Note: for the api_list-question json file, be sure to have the name of the api function from the python files inside in the api_list, they should be the same name and format as the function provided in the python code. \n",
    "\n",
    "\"{tool1}\" tool\n",
    "```python\n",
    "{tool1_py_content}\n",
    "```\n",
    "\n",
    "\"{tool1}\" unittest\n",
    "```python\n",
    "{tool1_test_py_content}\n",
    "```\n",
    "\n",
    "\"{tool1}\" tool metadata\n",
    "```json\n",
    "{tool1_json_content}\n",
    "```\n",
    "\n",
    "\n",
    "\"{tool2}\" tool\n",
    "```python\n",
    "{tool2_py_content}\n",
    "```\n",
    "\n",
    "\"{tool2}\" unittest\n",
    "```python\n",
    "{tool2_test_py_content}\n",
    "```\n",
    "\n",
    "\"{tool2}\" tool metadata\n",
    "```json\n",
    "{tool2_json_content}\n",
    "```\n",
    "{seed_api_question_example}\n",
    "'''\n",
    "    return prompt\n",
    "\n",
    "def save_response(category_folder, category_name, response, query_id):\n",
    "    \"\"\"Save the AI model response to the appropriate directory structure.\"\"\"\n",
    "    base_dir = os.path.join(category_name)\n",
    "    \n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "    \n",
    "    # Save raw output\n",
    "    raw_output_path = os.path.join(base_dir, f\"raw_output_{query_id}.txt\")\n",
    "    with open(raw_output_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(response)\n",
    "    \n",
    "    # Extract and save the JSON content from the AI response\n",
    "    json_content = extract_json_from_response(response)\n",
    "    if json_content:\n",
    "        json_output_path = os.path.join(base_dir, f\"independent_query_{query_id}.json\")\n",
    "        with open(json_output_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(json_content)\n",
    "\n",
    "def extract_json_from_response(response):\n",
    "    \"\"\"Extract JSON content from the response text enclosed within triple backticks.\"\"\"\n",
    "    start_idx = response.find(\"```json\")\n",
    "    end_idx = response.find(\"```\", start_idx + 7)\n",
    "    \n",
    "    if start_idx != -1 and end_idx != -1:\n",
    "        return response[start_idx + 7:end_idx].strip()\n",
    "    return \"\"\n",
    "\n",
    "def process_tool_combination(tool1, tool2, category_folder, category_path, query_id):\n",
    "    \"\"\"Process a pair of tools, generate the fstring prompt, and make the API call.\"\"\"\n",
    "    prompt = generate_prompt(tool1, tool2, category_folder, category_path)\n",
    "    \n",
    "    # Make the API call to OpenAI\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Your system prompt here\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message.content\n",
    "    \n",
    "    # Save the response\n",
    "    save_response(category_folder, category_folder, response, query_id)\n",
    "    print(f\"Saved query {query_id} for combination: {tool1} and {tool2}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "def process_category_combinations(category_path):\n",
    "    \"\"\"Process the category folder and handle all unique tool combinations.\"\"\"\n",
    "    category_folder = os.path.basename(category_path)\n",
    "    tools = [item.replace('.json', '') for item in os.listdir(category_path) if item.endswith('.json')]\n",
    "    \n",
    "    query_id = 1\n",
    "    for tool1, tool2 in itertools.combinations(tools, 2):\n",
    "        process_tool_combination(tool1, tool2, category_folder, category_path, query_id)\n",
    "        query_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved query 1 for combination: chinesecharacterweb and chinesetext\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saved query 2 for combination: chinesecharacterweb and datamuse\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saved query 3 for combination: chinesecharacterweb and freedictionary\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saved query 4 for combination: chinesecharacterweb and purgomalum\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saved query 5 for combination: chinesetext and datamuse\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saved query 6 for combination: chinesetext and freedictionary\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saved query 7 for combination: chinesetext and purgomalum\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saved query 8 for combination: datamuse and freedictionary\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saved query 9 for combination: datamuse and purgomalum\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saved query 10 for combination: freedictionary and purgomalum\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "category_path = 'D:\\Projects\\ToolsForTheJobBenchmark\\generation\\Music'\n",
    "process_category_combinations(category_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
