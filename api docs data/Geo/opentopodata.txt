Open Topo Data
Open Topo Data

Open Topo Data is an elevation API.
Host your own or use the free public API.

Open Topo Data is a REST API server for your elevation data.


curl https://api.opentopodata.org/v1/test-dataset?locations=56,123

{
    "results": [{
        "elevation": 815.0,
        "location": {
            "lat": 56.0,
            "lng": 123.0
        },
        "dataset": "test-dataset"
    }],
    "status": "OK"
}
You can self-host with your own dataset or use the free public API which is configured with a number of open elevation datasets. The API is largely compatible with the Google Maps Elevation API.

Host your own
Install docker and git then run:


git clone https://github.com/ajnisbet/opentopodata.git
cd opentopodata
make build
make run
This will start an Open Topo Data server on http://localhost:5000/.

Open Topo Data supports a wide range of raster file formats and tiling schemes, including most of those used by popular open elevation datasets.

See the server docs for more about configuration, adding datasets, and running on Windows and M1 Macs.

Usage
Open Topo Data has a single endpoint: a point query endpoint that returns the elevation at a single point or a series of points.


curl https://api.opentopodata.org/v1/test-dataset?locations=56.35,123.90

{
    "results": [{
        "elevation": 815.0,
        "location": {
            "lat": 56.0,
            "lng": 123.0
        },
        "dataset": "test-dataset"
    }],
    "status": "OK"
}
The interpolation algorithm used can be configured as a request parameter, and locations can also be provided in Google Polyline format.

See the API docs for more about request and response formats.

Public API
I'm hosting a free public API at api.opentopodata.org.

To keep the public API sustainable some limitations are applied.

Max 100 locations per request.
Max 1 call per second.
Max 1000 calls per day.
The following datasets are available on the public API, with elevation shown for downtown Denver, Colorado (39.7471, -104.9963).

Dataset name	Resolution	Extent	Source	API link (Denver, CO)
nzdem8m	8 m	New Zealand.	LINZ	Not in dataset bounds
ned10m	~10 m	Continental USA, Hawaii, parts of Alaska.	USGS	1590 m
eudem25m	25 m	Europe.	EEA	Not in dataset bounds
mapzen	~30 m	Global, inluding bathymetry.	Mapzen	1590 m
aster30m	~30 m	Global.	NASA	1591 m
srtm30m	~30 m	Latitudes -60 to 60.	USGS	1604 m
srtm90m	~90 m	Latitudes -60 to 60.	USGS	1603 m
bkg200m	200 m	Germany.	BKG	Not in dataset bounds
etopo1	~1.8 km	Global, including bathymetry and ice surface elevation near poles.	NOAA	1596 m
gebco2020	~450m	Global bathymetry and land elevation.	GEBCO	1603 m
emod2018	~100m	Bathymetry for ocean and sea in Europe.	EMODnet	Not in dataset bounds
See the API docs for more about request formats and parameters.

Support
Need some help getting Open Topo Data running? Send me an email at andrew@opentopodata.org!

Paid hosting
If you need an elevation API service with high-quality 1m lidar data, check out my sister project GPXZ.

The GPXZ Elevation API offers the following features:

Managed hosting, load balanced for redundancy
Seamless, global, hi-res elevation dataset
Drop-in replacement endpoint for the Google Maps Elevation API
Priority support
No hard usage limits
EU-only servers if needed
CORS (so you can use the API in your frontend webapp)

Open Topo Data Server Documentation
Getting started
The easiest way to run Open Topo Data is with Docker. Install docker then run the following commands:


git clone https://github.com/ajnisbet/opentopodata.git
cd opentopodata
make build
make run
This will start a server on localhost:5000 with a small demo dataset called test-dataset. Check out the API docs for info about the format of requests and responses.

Getting started on M1 / Apple Silicon Macs
On M1 Macs you'll probably need to use the alternate apple-silicon.Dockerfile docker image, which includes build dependencies for libraries that don't have binaries for M1.


git clone https://github.com/ajnisbet/opentopodata.git
cd opentopodata
make build-m1
make run
This should work without rosetta. See issue #55 for more info.

Getting started on Windows
On Windows you'll probably need to run the build and run commands without make:


git clone https://github.com/ajnisbet/opentopodata.git
cd opentopodata
docker build --tag opentopodata --file docker/Dockerfile . 
docker run --rm -it --volume C:/path/to/opentopodata/data:/app/data:ro -p 5000:5000 opentopodata sh -c "/usr/bin/supervisord -c /app/docker/supervisord.conf"
For more details see this note on windows support.

Dataset support
Open Topo Data supports all georeferenced raster formats supported by GDAL (e.g, .tiff, .hgt, .jp2).

Datasets can take one of two formats:

A single raster file.
A collection of square raster tiles which follow the SRTM naming convention: the file is named for the lower left corner. So a file named N30W120.tiff would span from 30 to 31 degrees latitude, and -120 to -119 degrees longitude. By default tiles are 1° by 1° and the coordinates are in WGS84, but this can be configured.
If your dataset consists of multiple files that aren't on a nice grid, you can create a .vrt file pointing to the files that Open Topo Data will treat as a single-file dataset. For an example of this process, see the documentation for configuring EMODnet.

Configuration
Open Topo Data is configured by a config.yaml file. If that file is missing it will look for example-config.yaml instead. You can set the CONFIG_PATH environment variable to specify a different path.

A config might look like:


max_locations_per_request: 100 
access_control_allow_origin: '*'
datasets:
- name: etopo1
  path: data/etopo1/
- name: srtm90m
  path: data/srtm-90m-v3/
  filename_epsg: 4326
  filename_tile_size: 1
corresponding to a directory structure:


opentopodata
|
└───data
    |
    ├───etopo1
    |   |
    |   └───etopo1-dem.geotiff
    |
    └───srtm-90m-v3
        |
        ├───N00E000.hgt 
        ├───N00E001.hgt 
        ├───N00E002.hgt 
        ├───etc...
which would expose localhost:5000/v1/etopo1 and localhost:5000/v1/srtm90m.

Config spec
max_locations_per_request: Requests with more than this many locations will return a 400 error. Default: 100.
access_control_allow_origin: Value for the Access-Control-Allow-Origin CORS header. Set to * or a domain to allow in-browser requests from a different origin. Set to null to send no Access-Control-Allow-Origin header. Default: null.
datasets[].name: Dataset name, used in url. Required.
datasets[].path: Path to folder containing the dataset. If the dataset is a single file it must be placed inside a folder. This path is relative to the repository directory inside docker. I suggest placing datasets inside the provided data folder, which is mounted in docker by make run. Files can be nested arbitrarily inside the dataset path. Required.
datasets[].filename_epsg: For tiled datasets, the projection of the filename coordinates. The default value is 4326, which is latitude/longitude with the WGS84 datum.
datasets[].filename_tile_size: For tiled datasets, how large each square tile is in the units of filename_epsg. For example, a lat,lon location of 38.2,121.2 would lie in the tile N38W121 for a tile size of 1, but lie in N35W120 for a tile size of 5. For non-integer tile sizes like 2.5, specify them as a string to avoid floating point parsing issues: "2.5". Default: 1.
datasets[].wgs84_bounds.left: Leftmost (westmost) longitude of the dataset, in WGS84. Used as a performance optimisation for Multi datasets. Default: -180.
datasets[].wgs84_bounds.right: Rightmost (eastmost) longitude of the dataset. Default: 180.
datasets[].wgs84_bounds.bottom: Bottommost (southmost) latitude of the dataset. Default: -90.
datasets[].wgs84_bounds.top: Topmost (northmost) latitude of the dataset. Default: 90.
datasets[].child_datasets[]: A list of names of other datasets. Querying this MultiDataset will check each dataset in child_datasets in order until a non-null elevation is found. For more information see Multi datasets.
Adding datasets
An important goal of Open Topo Data is make is easy to add new datasets. The included dataset is very low resolution (etopo1 downsampled to about 100km) and is intended only for testing.

Adding a new dataset takes two steps:

placing the dataset in the data directory
adding the path to the dataset in config.yaml.
Instructions are provided for adding the various datasets used in the public API:

ASTER
ETOPO1
EU-DEM
Mapzen
NED 10m
NZ DEM
SRTM (30m or 90m)
EMOD Bathymetry
GEBCO Bathymetry
BKG Germany (200m)

API Documentation
A public API is available for testing at api.opentopodata.org.

GET /v1/<dataset_name>
Reads the elevation from a given dataset.

The dataset name must match one of the options in config.yaml.

Multiple datasets can be provided separated by commas: in this case, for each point, each dataset is queried in order until a non-null elevation is found. For more information see Multi datasets.

Latitudes and longitudes should be in EPSG:4326 (also known as WGS-84 format), they will be converted internally to whatever the dataset uses.

Query Args
locations: Required. Either
latitutde,longitude pairs, each separated by a pipe character |. Example: locations=12.5,160.2|-10.6,130.
Google polyline format. Example: locations=gfo}EtohhU.
samples: If provided, instead of using locations directly, query elevation for sample equally-spaced points along the path specified by locations. Example: samples=5.
interpolation: How to interpolate between the points in the dataset. Options: nearest, bilinear, cubic. Default: bilinear.
nodata_value: What elevation to return if the dataset has a NODATA value at the requested location. Options: null, nan, or an integer like -9999. Default: null.
The default option null makes NODATA indistinguishable from a location outside the dataset bounds.
NaN (not a number) values aren't valid in json and will break some clients. The nan option was default before version 1.4 and is provided only for backwards compatibility.
When querying multiple datasets, this NODATA replacement only applies to the last dataset in the stack.
format: Either json or geojson. Default: json.
Response
A json object, compatible with the Google Maps Elevation API.

status: Will be OK for a successful request, INVALID_REQUEST for an input (4xx) error, and SERVER_ERROR for anything else (5xx). Required.
error: Description of what went wrong, when status isn't OK.
results: List of elevations for each location, in same order as input. Only provided for OK status.
results[].elevation: Elevation, using units and datum from the dataset. Will be null if the given location is outside the dataset bounds. May be null for NODATA values depending on the nodata_value query argument.
results[].location.lat: Latitude as parsed by Open Topo Data.
results[].location.lng: Longitude as parsed by Open Topo Data.
results[].dataset: The name of the dataset which the returned elevation is from.
Some notes about the elevation value:

If the raster has an integer data type, the interpolated elevation will be rounded to the nearest integer. This is a limitation of rasterio/gdal.
If the request location isn't covered by any raster in the dataset, Open Topo Data will return null.
Unless the nodata_value parameter is set, a null elevation could either mean the location is outside the dataset bounds, or a NODATA within the raster bounds.
Example
GET api.opentopodata.org/v1/srtm90m?locations=-43.5,172.5|27.6,1.98&interpolation=cubic


{
    "results": [
        {
            "dataset": "srtm90m",
            "elevation": 45,
            "location": {
                "lat": -43.5,
                "lng": 172.5
            }
        },
        {
            "dataset": "srtm90m",
            "elevation": 402,
            "location": {
                "lat": 27.6,
                "lng": 1.98
            }
        }
    ],
    "status": "OK"
}
GeoJSON response
If format=geojson is passed, you get a FeatureCollection of Point geometries instead. Each feature has its elevation as the z coordinate, and a dataset property specifying the source (corresponding to results[].dataset in the regular json response):

GeoJSON example
GET api.opentopodata.org/v1/srtm90m?locations=-43.5,172.5|27.6,1.98&interpolation=cubic&format=geojson


{
  "features": [
    {
      "geometry": {
        "coordinates": [
          172.5,
          -43.5,
          45
        ],
        "type": "Point"
      },
      "properties": {
        "dataset": "srtm90m"
      },
      "type": "Feature"
    },
    {
      "geometry": {
        "coordinates": [
          1.98,
          27.6,
          402
        ],
        "type": "Point"
      },
      "properties": {
        "dataset": "srtm90m"
      },
      "type": "Feature"
    }
  ],
  "type": "FeatureCollection"
}
POST /v1/<dataset_name>
When querying many locations in a single request, you can run into issues fitting them all in one url. To avoid these issues, you can also send a POST request to /v1/<dataset_name>.

The arguments are the same, but must be provided either as json-encoded data or form data instead of url query parameters.

The response is the same.

Other solutions for fitting many points in a URL are polyline encoding and rounding your coordinates.

Example
With json:


import requests

url = "https://api.opentopodata.org/v1/srtm90m"
data = {
    "locations": "-43.5,172.5|27.6,1.98",
     "interpolation": "cubic",
}
response = requests.post(url json=data)
With form data:


import requests

url = "https://api.opentopodata.org/v1/srtm90m"
data = {
    "locations": "-43.5,172.5|27.6,1.98",
     "interpolation": "cubic",
}
response = requests.post(url data=data)
The response is the same as for GET requests:


{
    "results": [
        {
            "dataset": "srtm90m",
            "elevation": 45,
            "location": {
                "lat": -43.5,
                "lng": 172.5
            }
        },
        {
            "dataset": "srtm90m",
            "elevation": 402,
            "location": {
                "lat": 27.6,
                "lng": 1.98
            }
        }
    ],
    "status": "OK"
}
GET /health
Healthcheck endpoint, for use with load balancing or monitoring.

Response
A json object.

status: Will be OK for a successful request.
The status code is 200 if healthy, otherwise 500.

Example
GET api.opentopodata.org/health


{
    "status": "OK"
}
GET /datasets
Details of the datasets available on the server.

Response
A json object.

datasets: List of datasets.
datasets[].name: Dataset name, used in the elevation query URL.
datasets[].child_datasets: If the dataset is a MultiDataset, names of the child datasets. Otherwise, an empty list [].
status: Will be OK if the server is running and the config file can be loaded. Otherwise the value will be SERVER_ERROR.
Example
GET api.opentopodata.org/datasets


{
    "results": [
        {
            "child_datasets": [],
            "name": "test-dataset"
        }
    ]
    "status": "OK"
}

ASTER
Overview
The Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) global DEM dataset is a joint effort between the Ministry of Economy, Trade, and Industry (METI) of Japan and the National Aeronautics and Space Administration (NASA) of the US.

ASTER GDEM is a 1 arc-second resolution, corresponding to a resolution of about 30m at the equator. Coverage is provided from from -83 to 83 degrees latitude.

ASTER elevation map
Render of ASTER elevation. Source.

Adding 30m ASTER to Open Topo Data
Make a new folder for the dataset:


mkdir ./data/aster30m
Download the files from USGS into ./data/aster30m . Extract the zip archives keeping the _dem.tif files and removing the _num.tif files.

To make downloading a bit easier, here's a list of the 22,912 URLs: aster30m_urls.txt.

Create a config.yaml file:


datasets:
- name: aster30m
  path: data/aster30m/
Rebuild to enable the new dataset at localhost:5000/v1/aster30m.


make build && make run
Public API
The Open Topo Data public API lets you query ASTER GDEM 30m for free:


curl https://api.opentopodata.org/v1/aster30m?locations=57.688709,11.976404

{
  "results": [
    {
      "elevation": 45.0, 
      "location": {
        "lat": 57.688709, 
        "lng": 11.976404
      },
      "dataset": "aster30m"
    }
  ], 
  "status": "OK"
}
The Public API uses version 3 of the DEM (GDEM 003).

ETOPO1
Overview
ETOPO1 is a global elevation dataset developed by NOAA. Unlike many DEM datasets, ETOPO1 contains bathymetry (water depth). There are two variants of the dataset, which vary in how elevation is calculated for the Antartic and Greenland ice sheets: an ice-surface variant, and a bedrock-level variant.

The dataset has a 1 arc-minute resolution, which corresponds to a resolution of about 1.8km at the equator.

ETOPO1 was made by aggregating many other datasets. The bulk of the land elevation comes from SRTM30, while most bathymetry is sourced from GEBCO. The comprising datasets were normalised to the same vertical datum (sea level) and horizontal datum (WGS84).

Accuracy
The accuracy of ETOPO1 varies spatially depending on the underlying source data. NOAA estimates the vertical accuracy is no better than 10m.

The quality of ETOPO1 is high: there are no missing values or holes (holes in the SRTM30 source were fixed by hand). Transitions between source datasets are smooth.

ETOPO1 elevation
Pseudocolour render of ETOPO1 elevation.

Adding ETOPO1 to Open Topo Data
Download the grid-registered .tif file from noaa.gov to the data directory and unzip.


mkdir ./data/etopo1
wget -P ./data/etopo1 https://www.ngdc.noaa.gov/mgg/global/relief/ETOPO1/data/ice_surface/grid_registered/georeferenced_tiff/ETOPO1_Ice_g_geotiff.zip
unzip ./data/etopo1/ETOPO1_Ice_g_geotiff.zip
rm ./data/etopo1/ETOPO1_Ice_g_geotiff.zip
The provided .tif file doesn't include projection information, which is needed for Open Topo Data. It can be added with GDAL:


gdal_translate -a_srs EPSG:4326 ./data/etopo1/ETOPO1_Ice_g_geotiff.tif ./data/etopo1/ETOPO1.tif
rm ./data/etopo1/ETOPO1_Ice_g_geotiff.tif
Create a file config.yaml with the following contents


datasets:
- name: etopo1
  path: data/etopo1/
Rebuild to enable the new dataset at localhost:5000/v1/etopo1?locations=27.98,86.92


make build && make run
Public API
The Open Topo Data public API lets you query ETOPO1 for free:


curl https://api.opentopodata.org/v1/etopo1?locations=39.747114,-104.996334

{
  "results": [
    {
      "elevation": 1596.0, 
      "location": {
        "lat": 39.747114, 
        "lng": -104.996334
      },
      "dataset": "etopo1"
    }
  ], 
  "status": "OK"
}
Open Topo Data hosts the ice-elevation version of the dataset (the same as seen in the image above).

Attribution

EU-DEM
EU-DEM is an elevation dataset covering Europe at a 25 metre resolution.

The dataset was created by merging elevation data from the SRTM and ASTER global datasets, as well as from Soviet topo maps at high latitudes. The datum used is EVRS2000.

Coverage
The dataset covers European Environment Agency member states, plus some countries to the east. Coverage extends to small parts of Northern Africa. Unlike SRTM, EU-DEM includes the Scandinavian regions north of 60°.

EU-DEM elevation
Render of EU-DEM elevation.

Accuracy
The stated vertical accuracy is ± 7m RMSE. Differences to SRTM and ASTER typically fall within this 7m range even with the datasets using slightly different vertical datums. Elevations for Lake Geneva, Switzerland are 370m, 374m, and 372m for SRTM, ASTER, and EU-DEM respectively.

Coastline
EU-DEM uses NODATA values for elevations over seas and oceans, where both ASTER and SRTM assign these areas an elevation of 0m. This means that Open Topo Data isn't able to interpolate elevations for locations very close to the coast and will return a value of NaN in places where SRTM and ASTER might return a 0m or 1m elevation.

The advantage of the NODATA oceans is that you cane use EU-DEM without clipping to a coastline shapefile.

Adding EU-DEM to Open Topo Data
As of Jan 2024, EU-DEM is no longer available to download via copernicus.eu.

I have uploaded my version of the dataset at https://files.gpxz.io/eudem_buffered.zip, see EUDEM download for more details.

Download and unzip the folder into:


mkdir ./data/eudem
There are 27 files.
Then create a config.yaml file:


datasets:
- name: eudem25m
  path: data/eudem
  filename_epsg: 3035
  filename_tile_size: 1000000
Finally, rebuild to enable the new dataset at localhost:5000/v1/eudem25m?locations=51.575,-3.220.


make build && make run
Avoiding gdal

If you don't have gdal installed, you can use the tiles directly. There are instructions for this here, but because the EU-DEM tiles don't come with an overlap you will get a null elevation at locations within 0.5 pixels of tile edges.

Public API
The Open Topo Data public API lets you query EU-DEM for free:


curl https://api.opentopodata.org/v1/eudem25m?locations=57.688709,11.976404

{
  "results": [
    {
      "elevation": 54.576168060302734,
      "location": {
        "lat": 57.688709,
        "lng": 11.976404
      },
      "dataset": "eudem25m"
    }
  ],
  "status": "OK"
}
Open Topo Data hosts version 1.1 of the dataset.

Attribution
Released by Copernicus under the following terms:

Access to data is based on a principle of full, open and free access as established by the Copernicus data and information policy Regulation (EU) No 1159/2013 of 12 July 2013. This regulation establishes registration and licensing conditions for GMES/Copernicus users. Free, full and open access to this data set is made on the conditions that:

When distributing or communicating Copernicus dedicated data and Copernicus service information to the public, users shall inform the public of the source of that data and information.

Users shall make sure not to convey the impression to the public that the user's activities are officially endorsed by the Union.

Where that data or information has been adapted or modified, the user shall clearly state this.

The data remain the sole property of the European Union. Any information and data produced in the framework of the action shall be the sole property of the European Union. Any communication and publication by the beneficiary shall acknowledge that the data were produced "with funding by the European Union".

Mapzen
Mapzen's terrain tiles are a global DEM dataset, including bathymetry. The dataset is an assimilation of multiple open datasets.

Coverage and resolution
Data is provided at a 1 arc-second resolution, corresponding to a resolution of about 30m at the equator. However, parts of the dataset are interpolated from lower-resolution datasets. The resolution of the source datasets is shown below:

Mapzen source datasets.
Resolution of Mapzen source datasets. Source: github.com/tilezen/joerd.

Adding Mapzen to Open Topo Data
Make a new folder for the dataset:


mkdir ./data/mapzen
Download the tiles from AWS. I found it easiest to use the aws cli:


aws s3 cp --no-sign-request --recursive s3://elevation-tiles-prod/skadi ./data/mapzen
Extract all the .hgt files. Create a config.yaml file:


datasets:
- name: mapzen
  path: data/mapzen/
Rebuild to enable the new dataset at localhost:5000/v1/mapzen.


make build && make run
Extra performance

.hgt files are extremely large. You'll get a large space reduction with little read penalty by converting to a compressed geotiff:


gdal_translate -co COMPRESS=DEFLATE -co PREDICTOR=2 {hgt_filename} {tif_filename}
Public API
The Open Topo Data public API lets you query the Mapzen dataset for free:


curl https://api.opentopodata.org/v1/mapzen?locations=57.688709,11.976404

{
  "results": [
    {
      "elevation": 55.0, 
      "location": {
        "lat": 57.688709, 
        "lng": 11.976404
      },
      "dataset": "mapzen"
    }
  ], 
  "status": "OK"
}

NED
The National Elevation Dataset (NED) is a collection of DEMs covering the USA at different resolutions.

Resolution and Coverage
NED comes in several different resolutions, each with a different coverage area.

The most commonly used resolutions are 1 arcsecond (covering North America and Mexico) and 1/3 arcsecond (covering CONUS, HI, PR, and parts of AK). The 1/3 arcsecond dataset is used in the Open Topo Data public API.

NED 1 arcsecond coverage. 1 arcsecond (30m).
NED 1/3 arcsecond coverage. 1/3 arcsecond (10m).
Two higher resolutions have partial coverage focused on more urbanised areas.

NED 1/9 arcsecond coverage. 1/9 arcsecond (3m).
NED 1 meter coverage. 1m.
And there are separate datasets with full coverage of Alaska at 2 arseconds (60m) and 5m.

NED 2 arcsecond coverage. 2 arcsecond (60m).
NED 5 meter coverage. 5m.
Coverage screenshots are from The National Map.

Adding NED 10m to Open Topo Data
Make a new folder for the dataset:


mkdir ./data/ned10m
Download the files from USGS into ./data/ned10m. You want the USGS_13_xxxxxxx.tif files.

Next, Open Topo Data needs the filenames to match the SRTM format: the filename should be the coordinates of the lower-left corner. Here's the Python code I used to do the conversion.


from glob import glob
import os
import re

old_pattern = './data/ned10m/USGS_13_*.tif'
old_paths = list(glob(old_pattern))
print('Found {} files'.format(len(old_paths)))

for old_path in old_paths:
    folder = os.path.dirname(old_path)
    old_filename = os.path.basename(old_path)

    # Extract northing.
    res = re.search(r'([ns]\d\d)', old_filename)
    old_northing = res.groups()[0]

    # Fix the NS 
    n_or_s = old_northing[0]
    ns_value = int(old_northing[1:3])
    if old_northing[:3] == 'n00':
        new_northing = 's01' + old_northing[3:]
    elif n_or_s == 'n':
        new_northing = 'n' + str(ns_value - 1).zfill(2) + old_northing[3:]
    elif n_or_s == 's':
        new_northing = 's' + str(ns_value + 1).zfill(2) + old_northing[3:]
    new_filename = old_filename.replace(old_northing, new_northing)
    assert new_northing in new_filename

    # Prevent new filename from overwriting old tiles.
    parts = new_filename.split('.')
    parts[0] = parts[0] + '_renamed'
    new_filename = '.'.join(parts)

    # Rename in place.
    new_path = os.path.join(folder, new_filename)
    os.rename(old_path, new_path)
Create a config.yaml file:


datasets:
- name: ned10m
  path: data/ned10m/
  filename_epsg: 4269
Rebuild to enable the new dataset at localhost:5000/v1/ned10m.


make build && make run
Public API
The Open Topo Data public API lets you query NED 10m for free:


curl https://api.opentopodata.org/v1/ned10m?locations=37.6535,-119.4105

{
  "results": [
    {
      "elevation": 3498.298583984375, 
      "location": {
        "lat": 37.6535, 
        "lng": -119.4105
      },
      "dataset": "ned10m"
    }
  ], 
  "status": "OK"
}
NED is still being updated by USGS. The dataset used by the public API was last updated 2020-04-23.

NZ DEM
The 8m NZ DEM is an interpolation of the 20m contours on the 1:50,000 scale LINZ topo maps.

Coverage
The dataset covers all of New Zealand except Chatham Island at an 8 metre resolution.

NZ dem coverage
NZ DEM elevation rendering.

Adding NZ DEM to Open Topo Data

mkdir ./data/nzdem8m
As of May 2020, the 8m dataset could only be painstaking downloaded a single tile at a time through the LINZ web interface. If you'd rather not do this, here are all the files as I downloaded them from LINZ on May 2020 nzdem-may-2020.zip.

Once you've obtained the 115 files, unzip the zip archives and delete anything without a .tif extension.

For Open Topo Data to understand the grid arrangement of the files, they need to be renamed to the coordinates of the lower-left corner. Here's the Python script I used, I'm also adding a buffer to help with interpolation near tile borders:


import os
from glob import glob

folder = './data/nzdem8m'


# Build vrt for all tifs.
pattern = os.path.join(folder, '*.tif')
tif_paths = list(glob(pattern))
vrt_path = os.path.join(folder, 'all.vrt')
assert not os.system('gdalbuildvrt {} {}'.format(vrt_path, ' '.join(tif_paths)))

buffer_ = 5
for tif_path in tif_paths:

    with rasterio.open(tif_path) as f:
        new_bounds = (
            f.bounds.left - buffer_ * f.res[0],
            f.bounds.bottom - buffer_ * f.res[1],
            f.bounds.right + buffer_ * f.res[0],
            f.bounds.top + buffer_ * f.res[1],
        )

        new_shape = (
            f.shape[0] + buffer_ * 2,
            f.shape[1] + buffer_ * 2,
        )

        northing = f.bounds.bottom
        easting = f.bounds.left

        filename = 'N{}E{}.tif'.format(int(northing), int(easting))
        buffer_path = os.path.join(os.path.dirname(tif_path), filename)


    te = ' '.join(str(x) for x in new_bounds)
    ts = ' '.join(str(x) for x in new_shape)

    cmd = f'gdalwarp -te {te} -ts {ts} -r near -co NUM_THREADS=ALL_CPUS -co COMPRESS=DEFLATE -co PREDICTOR=3 {vrt_path} {buffer_path}'
    assert not os.system(cmd)

assert not os.system(f'rm {vrt_path}')
Create a config.yaml file, setting the size of the tiles (65536 metres) and the projection system used (NZ tranverse mercator):


datasets:
- name: nzdem8m
  path: data/nzdem8m/
  filename_tile_size: 65536
  filename_epsg: 2193
Rebuild to enable the new dataset at localhost:5000/v1/nzdem8m.


make build && make run
Public API
The Open Topo Data public API lets you query NZ DEM 8m for free:


curl https://api.opentopodata.org/v1/nzdem8m?locations=-37.86118,174.79974

{
  "results": [
    {
      "elevation": 705.4374389648438, 
      "location": {
        "lat": -37.86118, 
        "lng": 174.79974
      },
      "dataset": "nzdem8m"
    }
  ], 
  "status": "OK"
}
The data files used in the public API were downloaded from LINZ May 2020.

SRTM
Overview
SRTM is a near-global elevation dataset, with coverage from -60 to 60 degrees latitude.

SRTM comes in multiple resolutions. The highest resolution is 1 arc-second, which corresponds to a resolution of about 30m at the equator. The 3 arc-second (90m) version is also frequently used.

Coverage
SRTM has coverage from -60 to 60 degrees latitude. The dataset is released in 1 degree tiles. Ocean areas covered by a tile have an elevation of 0m. Open Topo Data will return null for locations not covered by a tile.

SRTM coverage
SRTM coverage (green area).

Downloading 30m SRTM
Make a new folder for the dataset:


mkdir ./data/srtm30m
Download the files from USGS into ./data/srtm30m. Before downloading you'll need to register an account at earthdata.nasa.gov. Using these credentials for downloading is a little tricky, but luckily Earthdata provide download scripts in multiple different languages, the Python ones worked well for me.

You want the xxxxxxx.SRTMGL1.hgt.zip files. To make downloading a bit easier, here's a list of the 14,297 URLs: srtm30m_urls.txt.

If those scripts aren't working for you, an @SamDurand (#70) had success with logging into Earthdata in your browser, then automating the browser to download the files:


import webbrowser
import time

with open("srtm30m_urls.txt", "r") as f:
    url_list = f.read().split("\n")

for i, url in enumerate(url_list):
    webbrowser.open_new_tab(url)
    if i % 100 == 0:
        time.sleep(5) # pause 5s every 100 it to avoid rate limiting.
Adding 30m SRTM to Open Topo Data
Create a config.yaml file:


datasets:
- name: srtm30m
  path: data/srtm30m/
Rebuild to enable the new dataset at localhost:5000/v1/srtm30m.


make build && make run
Extra performance

.hgt.zip files are extremely slow for random reads. I got a 10x read speedup and a 10% size reduction from converting to a compressed geotiff:


gdal_translate -co COMPRESS=DEFLATE -co PREDICTOR=2 {hgtzip_filename} {tif_filename}
Unsupported file format

If you're leaving the tiles in .hgt.zip format, be aware that 16 of the files are not able to be read by gdal. There are instructions for fixing those zip files.

Adding 90m SRTM to Open Topo Data
The process is the same as for 30m. The dataset is hosted on USGS here, and a list of the tile urls is here: srtm90m_urls.txt.

Public API
The Open Topo Data public API lets you query SRTM 30m for free:


curl https://api.opentopodata.org/v1/srtm30m?locations=57.688709,11.976404

{
  "results": [
    {
      "elevation": 55.0, 
      "location": {
        "lat": 57.688709, 
        "lng": 11.976404
      },
      "dataset": "srtm30m"
    }
  ], 
  "status": "OK"
}
as well as SRTM 90m:


curl https://api.opentopodata.org/v1/srtm90m?locations=57.688709,11.976404

{
  "results": [
    {
      "elevation": 55.0, 
      "location": {
        "lat": 57.688709, 
        "lng": 11.976404
      },
      "dataset": "srtm90m"
    }
  ], 
  "status": "OK"
}

EMODnet 2018 Bathymetry
EMODnet maintains a number of bathymetry (sea floor depth) datasets.

There are currently two datasets with full coverage of Europe: a 1/8 arc minute (~200m) version released in 2016, and a 1/16 arc minute (~100m) version released in 2018. The datasets are a composite of bathymetric surveys, Landsat 8 imagery, and GEBCO data.

The vertical datum used is Lowest Astronomical Tide.

Coverage
The 2018 dataset covers a large area around Europe: 15° to 90° latitude, and -36° to 43° longitude. The elevation over land areas is given as NODATA values.

EMOD 2018 coverage map.
Render of EMODnet 2018 sea floor depth.

Adding EMODnet 2018 Bathymetry to Open Topo Data
Make a new folder for the dataset:


mkdir ./data/emod2018
Download the files from EMODnet into ./data/emod2018. You want the 2018 dataset, in ESRI ASCII format. Extract the zip folders, you should have 59 .asc named like A1_2018.asc.

Unlike other datasets, the EMOD tiles aren't aligned on a nice whole-number grid, so Open Topo Data can't tell from the filenames which tile covers which area. To handle this we can build a https://gdal.org/drivers/raster/vrt.html - a single raster file that links to the 59 tiles and which Open Topo Data can treat as a single-file dataset. Unfortunately you'll need to install GDAL for this.

Create a new folder for the VRT:


mkdir ./data/emod2018-vrt
Build the vrt using relative paths so the file will work inside the docker image:


cd ./data/emod2018-vrt
gdalbuildvrt -a_srs epsg:4326 emod2018.vrt ../emod2018/*.asc
cd ../
Create a config.yaml file, pointing to the VRT folder:


datasets:
- name: emod2018
  path: data/emod2018-vrt/
Rebuild to enable the new dataset at localhost:5000/v1/emod2018.


make build && make run
Extra performance

.asc files take up a lot of disk space and are slow for random reads. Consider converting to a compressed geotiff:


gdal_translate -co COMPRESS=DEFLATE -a_srs epsg:4326 {asc_filename} {tif_filename}
Public API
The Open Topo Data public API lets you query NED 10m for free:


curl https://api.opentopodata.org/v1/emod2018?locations=55.884323,2.528276

{
  "results": [
    {
      "elevation": -81.94999694824219, 
      "location": {
        "lat": 55.884323, 
        "lng": 2.528276
      },
      "dataset": "emod2018"
    }
  ], 
  "status": "OK"
}
The public API uses the 2018 version of the dataset.

GEBCO 2020 Bathymetry
GEBCO maintains a high-quality, global bathymetry (sea floor depth) dataset.

GEBCO releases a new dataset most years, the 2020 dataset (released in May 2020) covers the entire globe at a 15 arc-second resolution, corresponding to 450m resolution at the equator.

Coverage
Elevation is given for land areas, largely using a 15-degree version of SRTM.

Seafloor data comes from a variety of bathymetric sources, see GEBCO for more details.

GEBCO 2020 elevation render.
Render of GEBCO 2020 elevation.

Adding GEBCO 2020 to Open Topo Data
Instructions are given for the 2020 version of the dataset: future versions might work a bit differently.

Make a new folder for the dataset:


mkdir ./data/gebco2020
Download the dataset from GEBCO. You'll want the GEBCO_2020 Grid version, in Data GeoTiff format. Extract raster tiles from the archive and delete everything else so there are just 8 .tif files in the ./data/gebco2020 folder.

The files are given as 90 degree tiles, we need to rename them to SRTM's NxxSxx format to work with Open Topo Data:


mv gebco_2020_n0.0_s-90.0_w0.0_e90.0.tif     S90E000.tif
mv gebco_2020_n0.0_s-90.0_w-180.0_e-90.0.tif S90W180.tif
mv gebco_2020_n0.0_s-90.0_w-90.0_e0.0.tif    S90W090.tif
mv gebco_2020_n0.0_s-90.0_w90.0_e180.0.tif   S90E090.tif
mv gebco_2020_n90.0_s0.0_w0.0_e90.0.tif      N00E000.tif
mv gebco_2020_n90.0_s0.0_w-180.0_e-90.0.tif  N00W180.tif
mv gebco_2020_n90.0_s0.0_w-90.0_e0.0.tif     N00W090.tif
mv gebco_2020_n90.0_s0.0_w90.0_e180.0.tif    N00E090.tif
Create a config.yaml file:


datasets:
- name: gebco2020
  path: data/gebco2020/
  filename_tile_size: 90
Rebuild to enable the new dataset at localhost:5000/v1/gebco2020.


make build && make run
Buffering tiles
The tiles provided by GEBCO don't overlap and cover slightly less than a 90° x 90° square. This means you'll get a null result for coordinates along the tile edges (like 0,0).

For the public API I used the following code to add a 5px buffer to each tile.


from glob import glob
import os

import rasterio


old_folder = 'gebco_2020_geotiff'
new_folder = 'gebco_2020_buffer'
buffer_ = 5


old_pattern = os.path.join(old_folder, '*.tif')
old_paths = list(glob(old_pattern))

cmd = 'gdalbuildvrt {}/all.vrt'.format(old_folder) + ' '.join(old_paths)
os.system(cmd)

for path in old_paths:
    new_path = path.replace(old_folder, new_folder)

    with rasterio.open(path) as f:
        new_bounds = (
            f.bounds.left - buffer_ * f.res[0],
            f.bounds.bottom - buffer_ * f.res[1],
            f.bounds.right + buffer_ * f.res[0],
            f.bounds.top + buffer_ * f.res[1],
        )

        new_shape = (
            f.shape[0] + buffer_ * 2,
            f.shape[1] + buffer_ * 2,
        )

    te = ' '.join(str(x) for x in new_bounds)
    ts = ' '.join(str(x) for x in new_shape)

    cmd = f'gdalwarp -te {te} -ts {ts} -r near -co NUM_THREADS=ALL_CPUS -co COMPRESS=DEFLATE  -co PREDICTOR=2 -co BIGTIFF=yes {old_folder}/all.vrt {new_path}'
    os.system(cmd)
Public API
The Open Topo Data public API lets you query GEBCO 2020 for free:


curl https://api.opentopodata.org/v1/gebco2020?locations=37.6535,-119.4105

{
  "results": [
    {
      "elevation": 3405.0, 
      "location": {
        "lat": 37.6535, 
        "lng": -119.4105
      },
      "dataset": "gebco2020"
    }
  ], 
  "status": "OK"
}
The public API uses the 2020 version of the dataset.

Attribution
GEBCO released the dataset into the public domain under the following terms:

Acknowledge the source of The GEBCO Grid. A suitable form of attribution is given in the documentation that accompanies The GEBCO Grid.
Not use The GEBCO Grid in a way that suggests any official status or that GEBCO, or the IHO or IOC, endorses any particular application of The GEBCO Grid.
Not mislead others or misrepresent The GEBCO Grid or its source.

BKG
BKG (Bundesamt für Kartographie und Geodäsie) has published a number of elevation datasets for Germany. The 200m and 1000m resolutions are freely available, while resolutions up to 5m can be purchased for a fee.

EU-DEM elevation
Render of BKG 200m DTM elevation.

Adding 200m BKG Digital Terrain Model to Open Topo Data
Make a new folder for the dataset:


mkdir ./data/bkg200m
Download the dataset, the link here is for the UTM referenced dataset in .asc format. Extract the zip and copy only dgm200_utm32s.asc and dgm200_utm32s.prj into ./data/bkg200m.

Add the dataset to config.yaml:


- name: bkg200m
  path: data/bkg200m
Finally, rebuild to enable the new dataset at localhost:5000/v1/bkg200m?locations=49.427,7.753.


make build && make run
Adding 5m Germany DEM to Open Topo Data
I don't have access to the higher-resolution datasets, but one user managed to get them working with Open Topo Data in issues #22 and #24.

The files come with a projection format that isn't supported by GDAL and with non-overlapping tiles so queries near the edges will return null data. Probably the easiest way to handle these issues is to merge all the files into one big geotiff:


gdalbuildvrt -tap -a_srs epsg:3044 -o bkg-dgm5.vrt dgm5/*.asc
gdaltranslate -co COMPRESS=DEFLATE -co BIGTIFF=YES -co NUM_THREADS=ALL_CPUS bkg-dgm5.vrt bkg-dgm5.tif
You could also add a buffer to each tile, fixing the projection with -a_srs epsg:3044.

If anyone has got this working and would like to share their steps, please open an issue or pull request!

Public API
The Open Topo Data public API lets you query 200m BKG DEM over Germany for free:


curl https://api.opentopodata.org/v1/bkg200m?locations=49.427,7.753

{
  "results": [
    {
      "elevation": 269.9404602050781, 
      "location": {
        "lat": 49.427, 
        "lng": 7.753
      },
      "dataset": "bkg200m"
    }
  ], 
  "status": "OK"
}

Swisstopo
The Swisstopo Federal Office of Topography publishes a number of datasets, including very high quality elevation data for the whole of Switzerland at 0.5m and 2m resolutions under the name swissALTI. The data is regularly updated.

Adding 2m Swiss DEM to Open Topo Data
(The procedure is the same for the 0.5m product as the tiles are the same 1km extent).

Make a new folder for the dataset:


mkdir ./data/swisstopo-2m
Download the urls of each tile from swisstopo. When I did this in 2021 there were 43,579 tiles.

Download each tile. wget can do this. Consider doing the downloads sequentially with a rate-limit to avoid overloading their servers.


wget --input-file ch.swisstopo.swissalti3d-xxxxx.csv --no-clobber --limit-rate 1M
Open Topo Data needs files to be named with the lower-left corner coordinates. The files from swisstopo are named like this, but in km instead of metres. I use the following Python script to take a file named like


swissalti3d_2019_2622-1264_2_2056_5728.tif
and rename it to


swissalti3d_2019_2622-1264_2_2056_5728.N1264000E2622000.tif

from glob import glob
import os


dataset_folder = './data/swisstopo-2m/'
pattern = os.path.join(dataset_folder, '**', '*.tif')
paths = sorted(glob(pattern, recursive=True))


for old_path in paths:

    # Extract lower-left corder from filename.
    old_filename = os.path.basename(old_path)
    extent = old_filename.split('_')[2]
    northing = extent.split('-')[1]
    easting = extent.split('-')[0]

    # Convert from km to m.
    northing = int(northing) * 1000
    easting = int(easting) * 1000

    # Build new filename.
    new_filename = old_filename.rsplit('.', 1)[0]
    new_filename = new_filename + f'.N{northing}E{easting}.tif'
    new_path = os.path.join(os.path.dirname(old_path), new_filename)

    # Rename the file.
    os.rename(old_path, new_path)
The final step is adding the to config.yaml:


- name: swisstopo-2m
  path: data/swisstopo-2m/
  filename_epsg: 2056
  filename_tile_size: 1000
Public API
The Open Topo Data public server is full to the brim with elevation data at the moment! Swisstopo is first on the waiting list to be added once I upgrade the server.

2m Swiss elevation data is included in GPXZ