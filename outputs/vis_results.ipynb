{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass Rates:\n",
      "       setting_name                      model_name  pass_rate\n",
      "0          No-tools      claude3.5_sonnet_auto_eval   0.202020\n",
      "1          No-tools                gpt_4o_auto_eval   0.575758\n",
      "2          No-tools            gpt_4o_auto_eval_qaq   0.320000\n",
      "3          No-tools            llama_405B_auto_eval   0.434343\n",
      "4          No-tools             llama_70B_auto_eval   0.525253\n",
      "5   Non-replaceable      claude3.5_sonnet_auto_eval   0.085106\n",
      "6   Non-replaceable  claude3.5_sonnet_auto_eval_qaq   0.074468\n",
      "7   Non-replaceable                gpt_4o_auto_eval   0.105263\n",
      "8   Non-replaceable            gpt_4o_auto_eval_qaq   0.101266\n",
      "9   Non-replaceable            llama_405B_auto_eval   0.297872\n",
      "10  Non-replaceable        llama_405B_auto_eval_qaq   0.161290\n",
      "11  Non-replaceable             llama_70B_auto_eval   0.043011\n",
      "12  Non-replaceable         llama_70B_auto_eval_qaq   0.053191\n",
      "13         Original      claude3.5_sonnet_auto_eval   0.670213\n",
      "14         Original                gpt_4o_auto_eval   0.680412\n",
      "15         Original            llama_405B_auto_eval   0.478723\n",
      "16         Original             llama_70B_auto_eval   0.311828\n",
      "17      Replaceable      claude3.5_sonnet_auto_eval   0.412371\n",
      "18      Replaceable  claude3.5_sonnet_auto_eval_qaq   0.425532\n",
      "19      Replaceable                gpt_4o_auto_eval   0.442105\n",
      "20      Replaceable            gpt_4o_auto_eval_qaq   0.451613\n",
      "21      Replaceable            llama_405B_auto_eval   0.489362\n",
      "22      Replaceable        llama_405B_auto_eval_qaq   0.376344\n",
      "23      Replaceable             llama_70B_auto_eval   0.096774\n",
      "24      Replaceable         llama_70B_auto_eval_qaq   0.042553\n",
      "25   Underspecified      claude3.5_sonnet_auto_eval   0.305263\n",
      "26   Underspecified  claude3.5_sonnet_auto_eval_qaq   0.612903\n",
      "27   Underspecified                gpt_4o_auto_eval   0.364583\n",
      "28   Underspecified            gpt_4o_auto_eval_qaq   0.606383\n",
      "29   Underspecified            llama_405B_auto_eval   0.252632\n",
      "30   Underspecified        llama_405B_auto_eval_qaq   0.532609\n",
      "31   Underspecified             llama_70B_auto_eval   0.287234\n",
      "32   Underspecified         llama_70B_auto_eval_qaq   0.333333\n",
      "\n",
      "Tool Awareness Counts:\n",
      "tool_annotation                                 Yes  IDK  No\n",
      "setting_name    model_name                                  \n",
      "Non-replaceable claude3.5_sonnet_auto_eval       14   72   8\n",
      "                claude3.5_sonnet_auto_eval_qaq   14   71   9\n",
      "                gpt_4o_auto_eval                 86    3   6\n",
      "                gpt_4o_auto_eval_qaq             75    2   2\n",
      "                llama_405B_auto_eval             86    5   3\n",
      "                llama_405B_auto_eval_qaq         85    5   3\n",
      "                llama_70B_auto_eval              42   16  35\n",
      "                llama_70B_auto_eval_qaq          74    4  16\n",
      "Original        claude3.5_sonnet_auto_eval       88    6   0\n",
      "                gpt_4o_auto_eval                 97    0   0\n",
      "                llama_405B_auto_eval             94    0   0\n",
      "                llama_70B_auto_eval              92    0   1\n",
      "Replaceable     claude3.5_sonnet_auto_eval       44   52   1\n",
      "                claude3.5_sonnet_auto_eval_qaq   43   48   3\n",
      "                gpt_4o_auto_eval                 91    3   1\n",
      "                gpt_4o_auto_eval_qaq             89    2   2\n",
      "                llama_405B_auto_eval             92    2   0\n",
      "                llama_405B_auto_eval_qaq         90    1   2\n",
      "                llama_70B_auto_eval              59   16  18\n",
      "                llama_70B_auto_eval_qaq          85    4   5\n",
      "\n",
      "Information Awareness Counts:\n",
      "info_annotation                                Yes  IDK  No\n",
      "setting_name   model_name                                  \n",
      "Original       claude3.5_sonnet_auto_eval       88    6   0\n",
      "               gpt_4o_auto_eval                 96    1   0\n",
      "               llama_405B_auto_eval             94    0   0\n",
      "               llama_70B_auto_eval              91    1   1\n",
      "Underspecified claude3.5_sonnet_auto_eval       55   32   8\n",
      "               claude3.5_sonnet_auto_eval_qaq   46   44   3\n",
      "               gpt_4o_auto_eval                 79   12   5\n",
      "               gpt_4o_auto_eval_qaq             74   19   1\n",
      "               llama_405B_auto_eval             85    4   6\n",
      "               llama_405B_auto_eval_qaq         90    1   1\n",
      "               llama_70B_auto_eval              76    8  10\n",
      "               llama_70B_auto_eval_qaq          70   20   3\n",
      "\n",
      "Tool Validity Scores:\n",
      "       setting_name                      model_name  tool_aware_score\n",
      "0          No-tools      claude3.5_sonnet_auto_eval          0.000000\n",
      "1          No-tools                gpt_4o_auto_eval          0.000000\n",
      "2          No-tools            gpt_4o_auto_eval_qaq          0.000000\n",
      "3          No-tools            llama_405B_auto_eval          0.000000\n",
      "4          No-tools             llama_70B_auto_eval          0.000000\n",
      "5   Non-replaceable      claude3.5_sonnet_auto_eval          0.127660\n",
      "6   Non-replaceable  claude3.5_sonnet_auto_eval_qaq          0.042553\n",
      "7   Non-replaceable                gpt_4o_auto_eval          0.094737\n",
      "8   Non-replaceable            gpt_4o_auto_eval_qaq          0.000000\n",
      "9   Non-replaceable            llama_405B_auto_eval          0.010638\n",
      "10  Non-replaceable        llama_405B_auto_eval_qaq          0.010753\n",
      "11  Non-replaceable             llama_70B_auto_eval          0.505376\n",
      "12  Non-replaceable         llama_70B_auto_eval_qaq          0.000000\n",
      "13         Original      claude3.5_sonnet_auto_eval          0.989362\n",
      "14         Original                gpt_4o_auto_eval          1.000000\n",
      "15         Original            llama_405B_auto_eval          1.000000\n",
      "16         Original             llama_70B_auto_eval          0.989247\n",
      "17      Replaceable      claude3.5_sonnet_auto_eval          0.567010\n",
      "18      Replaceable  claude3.5_sonnet_auto_eval_qaq          0.585106\n",
      "19      Replaceable                gpt_4o_auto_eval          0.978947\n",
      "20      Replaceable            gpt_4o_auto_eval_qaq          0.956989\n",
      "21      Replaceable            llama_405B_auto_eval          0.978723\n",
      "22      Replaceable        llama_405B_auto_eval_qaq          0.967742\n",
      "23      Replaceable             llama_70B_auto_eval          0.645161\n",
      "24      Replaceable         llama_70B_auto_eval_qaq          0.904255\n",
      "25   Underspecified      claude3.5_sonnet_auto_eval          0.000000\n",
      "26   Underspecified  claude3.5_sonnet_auto_eval_qaq          0.000000\n",
      "27   Underspecified                gpt_4o_auto_eval          0.000000\n",
      "28   Underspecified            gpt_4o_auto_eval_qaq          0.000000\n",
      "29   Underspecified            llama_405B_auto_eval          0.000000\n",
      "30   Underspecified        llama_405B_auto_eval_qaq          0.000000\n",
      "31   Underspecified             llama_70B_auto_eval          0.000000\n",
      "32   Underspecified         llama_70B_auto_eval_qaq          0.000000\n",
      "\n",
      "Information Validity Scores:\n",
      "       setting_name                      model_name  info_aware_score\n",
      "0          No-tools      claude3.5_sonnet_auto_eval          0.000000\n",
      "1          No-tools                gpt_4o_auto_eval          0.000000\n",
      "2          No-tools            gpt_4o_auto_eval_qaq          0.000000\n",
      "3          No-tools            llama_405B_auto_eval          0.000000\n",
      "4          No-tools             llama_70B_auto_eval          0.000000\n",
      "5   Non-replaceable      claude3.5_sonnet_auto_eval          0.000000\n",
      "6   Non-replaceable  claude3.5_sonnet_auto_eval_qaq          0.000000\n",
      "7   Non-replaceable                gpt_4o_auto_eval          0.000000\n",
      "8   Non-replaceable            gpt_4o_auto_eval_qaq          0.000000\n",
      "9   Non-replaceable            llama_405B_auto_eval          0.000000\n",
      "10  Non-replaceable        llama_405B_auto_eval_qaq          0.000000\n",
      "11  Non-replaceable             llama_70B_auto_eval          0.000000\n",
      "12  Non-replaceable         llama_70B_auto_eval_qaq          0.000000\n",
      "13         Original      claude3.5_sonnet_auto_eval          0.989362\n",
      "14         Original                gpt_4o_auto_eval          1.000000\n",
      "15         Original            llama_405B_auto_eval          1.000000\n",
      "16         Original             llama_70B_auto_eval          0.978495\n",
      "17      Replaceable      claude3.5_sonnet_auto_eval          0.000000\n",
      "18      Replaceable  claude3.5_sonnet_auto_eval_qaq          0.000000\n",
      "19      Replaceable                gpt_4o_auto_eval          0.000000\n",
      "20      Replaceable            gpt_4o_auto_eval_qaq          0.000000\n",
      "21      Replaceable            llama_405B_auto_eval          0.000000\n",
      "22      Replaceable        llama_405B_auto_eval_qaq          0.000000\n",
      "23      Replaceable             llama_70B_auto_eval          0.000000\n",
      "24      Replaceable         llama_70B_auto_eval_qaq          0.000000\n",
      "25   Underspecified      claude3.5_sonnet_auto_eval          0.147368\n",
      "26   Underspecified  claude3.5_sonnet_auto_eval_qaq          0.333333\n",
      "27   Underspecified                gpt_4o_auto_eval          0.083333\n",
      "28   Underspecified            gpt_4o_auto_eval_qaq          0.148936\n",
      "29   Underspecified            llama_405B_auto_eval          0.063158\n",
      "30   Underspecified        llama_405B_auto_eval_qaq          0.010870\n",
      "31   Underspecified             llama_70B_auto_eval          0.106383\n",
      "32   Underspecified         llama_70B_auto_eval_qaq          0.129032\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def collect_data(root_dir):\n",
    "    data_list = []\n",
    "    for setting_name in os.listdir(root_dir):\n",
    "        setting_path = os.path.join(root_dir, setting_name)\n",
    "        if os.path.isdir(setting_path):\n",
    "            for model_name in os.listdir(setting_path):\n",
    "                model_path = os.path.join(setting_path, model_name)\n",
    "                if os.path.isdir(model_path):\n",
    "                    answers_file = os.path.join(model_path, 'answers.json')\n",
    "                    if os.path.exists(answers_file):\n",
    "                        with open(answers_file, 'r', encoding='utf-8') as f:\n",
    "                            data = json.load(f)\n",
    "                            for item in data:\n",
    "                                item['setting_name'] = setting_name\n",
    "                                item['model_name'] = model_name\n",
    "                                data_list.append(item)\n",
    "    return pd.DataFrame(data_list)\n",
    "\n",
    "def process_data(df):\n",
    "    # Normalize text data\n",
    "    df['tool_annotation'] = df.get('tool_annotation', '').str.strip().str.lower()\n",
    "    df['info_annotation'] = df.get('info_annotation', '').str.strip().str.lower()\n",
    "\n",
    "    # Replace 'idk' with 'IDK' for consistency\n",
    "    df['tool_annotation'] = df['tool_annotation'].replace({'idk': 'IDK', 'yes': 'Yes', 'no': 'No'})\n",
    "    df['info_annotation'] = df['info_annotation'].replace({'idk': 'IDK', 'yes': 'Yes', 'no': 'No'})\n",
    "\n",
    "    # Ensure pass_rate is numeric\n",
    "    df['pass_rate'] = pd.to_numeric(df['pass_rate'], errors='coerce').fillna(0)\n",
    "\n",
    "    # Ensure validity scores are numeric\n",
    "    df['tool_aware_score'] = pd.to_numeric(df.get('tool_aware_score', 0), errors='coerce').fillna(0)\n",
    "    df['info_aware_score'] = pd.to_numeric(df.get('info_aware_score', 0), errors='coerce').fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "def compute_metrics(df):\n",
    "    # Aggregate counts for tool awareness\n",
    "    tool_awareness_counts = df.pivot_table(index=['setting_name', 'model_name'], columns='tool_annotation', aggfunc='size', fill_value=0)\n",
    "    tool_awareness_counts = tool_awareness_counts[['Yes', 'IDK', 'No']]\n",
    "\n",
    "    # Aggregate counts for info awareness\n",
    "    info_awareness_counts = df.pivot_table(index=['setting_name', 'model_name'], columns='info_annotation', aggfunc='size', fill_value=0)\n",
    "    info_awareness_counts = info_awareness_counts[['Yes', 'IDK', 'No']]\n",
    "\n",
    "    # Compute pass rates\n",
    "    pass_rates = df.groupby(['setting_name', 'model_name'])['pass_rate'].mean().reset_index()\n",
    "\n",
    "    # Compute tool and info validity scores\n",
    "    tool_validity = df.groupby(['setting_name', 'model_name'])['tool_aware_score'].mean().reset_index()\n",
    "    info_validity = df.groupby(['setting_name', 'model_name'])['info_aware_score'].mean().reset_index()\n",
    "\n",
    "    return tool_awareness_counts, info_awareness_counts, pass_rates, tool_validity, info_validity\n",
    "\n",
    "def plot_awareness_counts(awareness_counts, awareness_type):\n",
    "    awareness_counts = awareness_counts.reset_index()\n",
    "    for (setting_name, model_name), group_df in awareness_counts.groupby(['setting_name', 'model_name']):\n",
    "        data = group_df[['Yes', 'IDK', 'No']].iloc[0]\n",
    "        data.plot(kind='bar', stacked=True, color=['green', 'orange', 'red'])\n",
    "        plt.title(f'{awareness_type} Responses for {model_name} in {setting_name} Setting')\n",
    "        plt.xlabel('Response Type')\n",
    "        plt.ylabel('Count')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{awareness_type}_{setting_name}_{model_name}.png')\n",
    "        plt.close()\n",
    "\n",
    "def plot_pass_rates(pass_rates):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=pass_rates, x='setting_name', y='pass_rate', hue='model_name')\n",
    "    plt.title('Pass Rate by Setting and Model')\n",
    "    plt.xlabel('Setting')\n",
    "    plt.ylabel('Pass Rate')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pass_rates.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_validity_scores(validity_scores, validity_type):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=validity_scores, x='setting_name', y=f'{validity_type}_aware_score', hue='model_name')\n",
    "    plt.title(f'{validity_type.capitalize()} Awareness Score by Setting and Model')\n",
    "    plt.xlabel('Setting')\n",
    "    plt.ylabel(f'{validity_type.capitalize()} Awareness Score')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{validity_type}_awareness_scores.png')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    root_dir = '.'  # Replace with your root directory\n",
    "    df = collect_data(root_dir)\n",
    "    df = process_data(df)\n",
    "\n",
    "    tool_awareness_counts, info_awareness_counts, pass_rates, tool_validity, info_validity = compute_metrics(df)\n",
    "\n",
    "    # Plotting\n",
    "    plot_awareness_counts(tool_awareness_counts, 'Tool Awareness')\n",
    "    plot_awareness_counts(info_awareness_counts, 'Information Awareness')\n",
    "    plot_pass_rates(pass_rates)\n",
    "    plot_validity_scores(tool_validity, 'tool')\n",
    "    plot_validity_scores(info_validity, 'info')\n",
    "\n",
    "    # Optionally, print out the computed metrics\n",
    "    print(\"Pass Rates:\")\n",
    "    print(pass_rates)\n",
    "    print(\"\\nTool Awareness Counts:\")\n",
    "    print(tool_awareness_counts)\n",
    "    print(\"\\nInformation Awareness Counts:\")\n",
    "    print(info_awareness_counts)\n",
    "    print(\"\\nTool Validity Scores:\")\n",
    "    print(tool_validity)\n",
    "    print(\"\\nInformation Validity Scores:\")\n",
    "    print(info_validity)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toolsforjob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
