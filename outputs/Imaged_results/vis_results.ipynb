{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass Rates:\n",
      "       setting_name                  model_name  pass_rate\n",
      "0           No-tool  claude3.5_sonnet_auto_eval   0.202020\n",
      "1           No-tool            gpt_4o_auto_eval   0.575758\n",
      "2           No-tool        llama_405B_auto_eval   0.400000\n",
      "3           No-tool         llama_70B_auto_eval   0.512500\n",
      "4   Non-replaceable  claude3.5_sonnet_auto_eval   0.085106\n",
      "5   Non-replaceable            gpt_4o_auto_eval   0.105263\n",
      "6   Non-replaceable        llama_405B_auto_eval   0.321429\n",
      "7   Non-replaceable         llama_70B_auto_eval   0.032258\n",
      "8          Original  claude3.5_sonnet_auto_eval   0.670213\n",
      "9          Original            gpt_4o_auto_eval   0.680412\n",
      "10         Original        llama_405B_auto_eval   0.277778\n",
      "11         Original         llama_70B_auto_eval   0.333333\n",
      "12      Replaceable  claude3.5_sonnet_auto_eval   0.412371\n",
      "13      Replaceable            gpt_4o_auto_eval   0.442105\n",
      "14      Replaceable        llama_405B_auto_eval   0.666667\n",
      "15      Replaceable         llama_70B_auto_eval   0.114754\n",
      "16   Underspecified  claude3.5_sonnet_auto_eval   0.305263\n",
      "17   Underspecified            gpt_4o_auto_eval   0.364583\n",
      "18   Underspecified        llama_405B_auto_eval   0.125000\n",
      "19   Underspecified         llama_70B_auto_eval   0.375000\n",
      "\n",
      "Tool Awareness Counts:\n",
      "tool_annotation                             Yes  IDK  No\n",
      "setting_name    model_name                              \n",
      "Non-replaceable claude3.5_sonnet_auto_eval   14   72   8\n",
      "                gpt_4o_auto_eval             86    3   6\n",
      "                llama_405B_auto_eval         49    4   3\n",
      "                llama_70B_auto_eval          42   16  35\n",
      "Original        claude3.5_sonnet_auto_eval   88    6   0\n",
      "                gpt_4o_auto_eval             97    0   0\n",
      "                llama_405B_auto_eval         36    0   0\n",
      "                llama_70B_auto_eval          57    0   0\n",
      "Replaceable     claude3.5_sonnet_auto_eval   44   52   1\n",
      "                gpt_4o_auto_eval             91    3   1\n",
      "                llama_405B_auto_eval         24    0   0\n",
      "                llama_70B_auto_eval          39    9  13\n",
      "\n",
      "Information Awareness Counts:\n",
      "info_annotation                            Yes  IDK  No\n",
      "setting_name   model_name                              \n",
      "Original       claude3.5_sonnet_auto_eval   88    6   0\n",
      "               gpt_4o_auto_eval             96    1   0\n",
      "               llama_405B_auto_eval         36    0   0\n",
      "               llama_70B_auto_eval          57    0   0\n",
      "Underspecified claude3.5_sonnet_auto_eval   55   32   8\n",
      "               gpt_4o_auto_eval             79   12   5\n",
      "               llama_405B_auto_eval         22    2   0\n",
      "               llama_70B_auto_eval          22    1   1\n",
      "\n",
      "Tool Validity Scores:\n",
      "       setting_name                  model_name  tool_aware_score\n",
      "0           No-tool  claude3.5_sonnet_auto_eval          0.000000\n",
      "1           No-tool            gpt_4o_auto_eval          0.000000\n",
      "2           No-tool        llama_405B_auto_eval          0.000000\n",
      "3           No-tool         llama_70B_auto_eval          0.000000\n",
      "4   Non-replaceable  claude3.5_sonnet_auto_eval          0.042553\n",
      "5   Non-replaceable            gpt_4o_auto_eval          0.010526\n",
      "6   Non-replaceable        llama_405B_auto_eval          0.000000\n",
      "7   Non-replaceable         llama_70B_auto_eval          0.129032\n",
      "8          Original  claude3.5_sonnet_auto_eval          0.989362\n",
      "9          Original            gpt_4o_auto_eval          1.000000\n",
      "10         Original        llama_405B_auto_eval          1.000000\n",
      "11         Original         llama_70B_auto_eval          1.000000\n",
      "12      Replaceable  claude3.5_sonnet_auto_eval          0.567010\n",
      "13      Replaceable            gpt_4o_auto_eval          0.978947\n",
      "14      Replaceable        llama_405B_auto_eval          1.000000\n",
      "15      Replaceable         llama_70B_auto_eval          0.655738\n",
      "16   Underspecified  claude3.5_sonnet_auto_eval          0.000000\n",
      "17   Underspecified            gpt_4o_auto_eval          0.000000\n",
      "18   Underspecified        llama_405B_auto_eval          0.000000\n",
      "19   Underspecified         llama_70B_auto_eval          0.000000\n",
      "\n",
      "Information Validity Scores:\n",
      "       setting_name                  model_name  info_aware_score\n",
      "0           No-tool  claude3.5_sonnet_auto_eval          0.000000\n",
      "1           No-tool            gpt_4o_auto_eval          0.000000\n",
      "2           No-tool        llama_405B_auto_eval          0.000000\n",
      "3           No-tool         llama_70B_auto_eval          0.000000\n",
      "4   Non-replaceable  claude3.5_sonnet_auto_eval          0.000000\n",
      "5   Non-replaceable            gpt_4o_auto_eval          0.000000\n",
      "6   Non-replaceable        llama_405B_auto_eval          0.000000\n",
      "7   Non-replaceable         llama_70B_auto_eval          0.000000\n",
      "8          Original  claude3.5_sonnet_auto_eval          0.989362\n",
      "9          Original            gpt_4o_auto_eval          1.000000\n",
      "10         Original        llama_405B_auto_eval          1.000000\n",
      "11         Original         llama_70B_auto_eval          1.000000\n",
      "12      Replaceable  claude3.5_sonnet_auto_eval          0.000000\n",
      "13      Replaceable            gpt_4o_auto_eval          0.000000\n",
      "14      Replaceable        llama_405B_auto_eval          0.000000\n",
      "15      Replaceable         llama_70B_auto_eval          0.000000\n",
      "16   Underspecified  claude3.5_sonnet_auto_eval          0.147368\n",
      "17   Underspecified            gpt_4o_auto_eval          0.083333\n",
      "18   Underspecified        llama_405B_auto_eval          0.000000\n",
      "19   Underspecified         llama_70B_auto_eval          0.041667\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def collect_data(root_dir):\n",
    "    data_list = []\n",
    "    for setting_name in os.listdir(root_dir):\n",
    "        setting_path = os.path.join(root_dir, setting_name)\n",
    "        if os.path.isdir(setting_path):\n",
    "            for model_name in os.listdir(setting_path):\n",
    "                model_path = os.path.join(setting_path, model_name)\n",
    "                if os.path.isdir(model_path):\n",
    "                    answers_file = os.path.join(model_path, 'answers.json')\n",
    "                    if os.path.exists(answers_file):\n",
    "                        with open(answers_file, 'r', encoding='utf-8') as f:\n",
    "                            data = json.load(f)\n",
    "                            for item in data:\n",
    "                                item['setting_name'] = setting_name\n",
    "                                item['model_name'] = model_name\n",
    "                                data_list.append(item)\n",
    "    return pd.DataFrame(data_list)\n",
    "\n",
    "def process_data(df):\n",
    "    # Normalize text data\n",
    "    df['tool_annotation'] = df.get('tool_annotation', '').str.strip().str.lower()\n",
    "    df['info_annotation'] = df.get('info_annotation', '').str.strip().str.lower()\n",
    "\n",
    "    # Replace 'idk' with 'IDK' for consistency\n",
    "    df['tool_annotation'] = df['tool_annotation'].replace({'idk': 'IDK', 'yes': 'Yes', 'no': 'No'})\n",
    "    df['info_annotation'] = df['info_annotation'].replace({'idk': 'IDK', 'yes': 'Yes', 'no': 'No'})\n",
    "\n",
    "    # Ensure pass_rate is numeric\n",
    "    df['pass_rate'] = pd.to_numeric(df['pass_rate'], errors='coerce').fillna(0)\n",
    "\n",
    "    # Ensure validity scores are numeric\n",
    "    df['tool_aware_score'] = pd.to_numeric(df.get('tool_aware_score', 0), errors='coerce').fillna(0)\n",
    "    df['info_aware_score'] = pd.to_numeric(df.get('info_aware_score', 0), errors='coerce').fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "def compute_metrics(df):\n",
    "    # Aggregate counts for tool awareness\n",
    "    tool_awareness_counts = df.pivot_table(index=['setting_name', 'model_name'], columns='tool_annotation', aggfunc='size', fill_value=0)\n",
    "    tool_awareness_counts = tool_awareness_counts[['Yes', 'IDK', 'No']]\n",
    "\n",
    "    # Aggregate counts for info awareness\n",
    "    info_awareness_counts = df.pivot_table(index=['setting_name', 'model_name'], columns='info_annotation', aggfunc='size', fill_value=0)\n",
    "    info_awareness_counts = info_awareness_counts[['Yes', 'IDK', 'No']]\n",
    "\n",
    "    # Compute pass rates\n",
    "    pass_rates = df.groupby(['setting_name', 'model_name'])['pass_rate'].mean().reset_index()\n",
    "\n",
    "    # Compute tool and info validity scores\n",
    "    tool_validity = df.groupby(['setting_name', 'model_name'])['tool_aware_score'].mean().reset_index()\n",
    "    info_validity = df.groupby(['setting_name', 'model_name'])['info_aware_score'].mean().reset_index()\n",
    "\n",
    "    return tool_awareness_counts, info_awareness_counts, pass_rates, tool_validity, info_validity\n",
    "\n",
    "def plot_awareness_counts(awareness_counts, awareness_type):\n",
    "    awareness_counts = awareness_counts.reset_index()\n",
    "    for (setting_name, model_name), group_df in awareness_counts.groupby(['setting_name', 'model_name']):\n",
    "        data = group_df[['Yes', 'IDK', 'No']].iloc[0]\n",
    "        data.plot(kind='bar', stacked=True, color=['green', 'orange', 'red'])\n",
    "        plt.title(f'{awareness_type} Responses for {model_name} in {setting_name} Setting')\n",
    "        plt.xlabel('Response Type')\n",
    "        plt.ylabel('Count')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{awareness_type}_{setting_name}_{model_name}.png')\n",
    "        plt.close()\n",
    "\n",
    "def plot_pass_rates(pass_rates):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=pass_rates, x='setting_name', y='pass_rate', hue='model_name')\n",
    "    plt.title('Pass Rate by Setting and Model')\n",
    "    plt.xlabel('Setting')\n",
    "    plt.ylabel('Pass Rate')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pass_rates.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_validity_scores(validity_scores, validity_type):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=validity_scores, x='setting_name', y=f'{validity_type}_aware_score', hue='model_name')\n",
    "    plt.title(f'{validity_type.capitalize()} Awareness Score by Setting and Model')\n",
    "    plt.xlabel('Setting')\n",
    "    plt.ylabel(f'{validity_type.capitalize()} Awareness Score')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{validity_type}_awareness_scores.png')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    root_dir = '.'  # Replace with your root directory\n",
    "    df = collect_data(root_dir)\n",
    "    df = process_data(df)\n",
    "\n",
    "    tool_awareness_counts, info_awareness_counts, pass_rates, tool_validity, info_validity = compute_metrics(df)\n",
    "\n",
    "    # Plotting\n",
    "    plot_awareness_counts(tool_awareness_counts, 'Tool Awareness')\n",
    "    plot_awareness_counts(info_awareness_counts, 'Information Awareness')\n",
    "    plot_pass_rates(pass_rates)\n",
    "    plot_validity_scores(tool_validity, 'tool')\n",
    "    plot_validity_scores(info_validity, 'info')\n",
    "\n",
    "    # Optionally, print out the computed metrics\n",
    "    print(\"Pass Rates:\")\n",
    "    print(pass_rates)\n",
    "    print(\"\\nTool Awareness Counts:\")\n",
    "    print(tool_awareness_counts)\n",
    "    print(\"\\nInformation Awareness Counts:\")\n",
    "    print(info_awareness_counts)\n",
    "    print(\"\\nTool Validity Scores:\")\n",
    "    print(tool_validity)\n",
    "    print(\"\\nInformation Validity Scores:\")\n",
    "    print(info_validity)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toolsforjob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
